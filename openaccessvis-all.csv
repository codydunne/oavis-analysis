Source.Name,ReviewVenue,PublicationVenue,Title,delete,Authors,AuthorPDF,Abstract,ExplanationPage,SourceMaterials,Data,Preregistered,Video,DOI,PublicationYear,ConferenceYear,ConferenceTrack,ConferenceRoom,ConferenceDay,ConferenceSession,date,ConferenceTimeStart,ConferenceTimeEnd
openaccessvis.csv,TVCG,TVCG,Timelines Revisited: A Design Space and Considerations for Expressive Storytelling,,"Matthew Brehmer, Bongshin Lee, Benjamin Bach, Nathalie Henry Riche, Tamara Munzner",http://www.aviz.fr/~bbach/timelines/Brehmer2016timelines.pdf,"There are many ways to visualize event sequences as timelines. In a storytelling context where the intent is to convey multiple narrative points, a richer set of timeline designs may be more appropriate than the narrow range that has been used for exploratory data analysis by the research community. Informed by a survey of 263 timelines, we present a design space for storytelling with timelines that balances expressiveness and effectiveness, identifying 14 design choices characterized by three dimensions: representation, scale, and layout. Twenty combinations of these choices are viable timeline designs that can be matched to different narrative points, while smooth animated transitions between narrative points allow for the presentation of a cohesive story, an important aspect of both interactive storytelling and data videos. We further validate this design space by realizing the full set of viable timeline designs and transitions in a proof-of-concept sandbox implementation that we used to produce seven example timeline stories. Ultimately, this work is intended to inform and inspire the design of future tools for storytelling with timelines.",https://timelinesrevisited.github.io/,http://timelinesrevisited.github.io/supplemental/,,,video http://timelinesrevisited.github.io/supplemental/stories/routines.mp4,10.1109/TVCG.2016.2614803,2016,2017,InfoVis,301-D,Tuesday,Time and Space,,5:15:00 PM,5:35:00 PM
openaccessvis.csv,TVCG,TVCG,A Survey on Visual Approaches for Analyzing Scientific Literature and Patents,,"Paolo Federico, Florian Heimerl, Steffen Koch, Silvia Miksch",https://publik.tuwien.ac.at/files/PubDat_251231.pdf,"The increasingly large number of available writings describing technical and scientific progress, calls for advanced analytic tools for their efficient analysis. This is true for many application scenarios in science and industry and for different types of writings, comprising patents and scientific articles. Despite important differences between patents and scientific articles, both have a variety of common characteristics that lead to similar search and analysis tasks. However, the analysis and visualization of these documents is not a trivial task due to the complexity of the documents as well as the large number of possible relations between their multivariate attributes. In this survey, we review interactive analysis and visualization approaches of patents and scientific articles, ranging from exploration tools to sophisticated mining methods. In a bottom-up approach, we categorize them according to two aspects: (a) data type (text, citations, authors, metadata, and combinations thereof), and (b) task (finding and comparing single entities, seeking elementary relations, finding complex patterns, and in particular temporal patterns, and investigating connections between multiple behaviours). Finally, we identify challenges and research directions in this area that ask for future investigations.",http://ieg.ifs.tuwien.ac.at/~federico/LiPatVis/,,,,vimeo 230834614,10.1109/TVCG.2016.2610422,2016,2017,VAST,207,Wednesday,Text Analytics,,10:30:00 AM,10:50:00 AM
openaccessvis.csv,TVCG,TVCG,Uncertainty Visualization by Representative Sampling from Prediction Ensembles,,"Le Liu, Alexander Boone, Ian Ruginski, Lace Padilla, Mary Hegarty, Sarah H. Creem-Regehr, William B. Thompson, Cem Yuksel, Donald H. House",,,,,,,,10.1109/TVCG.2016.2607204,2016,2017,InfoVis,301-D,Tuesday,Techniques,,3:20:00 PM,3:40:00 PM
openaccessvis.csv,TVCG,TVCG,Revealing Patterns and Trends of Mass Mobility through Spatial and Temporal Abstraction of Origin-Destination Movement Data,,"Gennady Andrienko, Natalia Andrienko, Georg Fuchs, Jo Wood",http://openaccess.city.ac.uk/15488/1/andrienko_revealing_2016_AuthorCopy.pdf,"Origin-destination (OD) movement data describe moves or trips between spatial locations by specifying the origins, destinations, start, and end times, but not the routes travelled. For studying the spatio-temporal patterns and trends of mass mobility, individual OD moves of many people are aggregated into flows (collective moves) by time intervals. Time-variant flow data pose two difficult challenges for visualization and analysis. First, flows may connect arbitrary locations (not only neighbors), thus making a graph with numerous edge intersections, which is hard to visualize in a comprehensible way. Even a single spatial situation consisting of flows in one time step is hard to explore. The second challenge is the need to analyze long time series consisting of numerous spatial situations. We present an approach facilitating exploration of long-term flow data by means of spatial and temporal abstraction. It involves a special way of data aggregation, which allows representing spatial situations by diagram maps instead of flow maps, thus reducing the intersections and occlusions pertaining to flow maps. The aggregated data are used for clustering of time intervals by similarity of the spatial situations. Temporal and spatial displays of the clustering results facilitate the discovery of periodic patterns and longer-term trends in the mass mobility behavior.",,,,,vimeo 230834183,10.1109/TVCG.2016.2616404,2016,2017,VAST,301-C,Tuesday,"Space, Time, Movement",,3:00:00 PM,3:20:00 PM
openaccessvis.csv,TVCG,TVCG,An Exploratory Study of Word-Scale Graphics in Data-Rich Text Documents,,"Pascal Goffin, Jeremy Boy, Wesley Willett, Petra Isenberg",https://hal.archives-ouvertes.fr/hal-01389998/document,"We contribute an investigation of the design and function of word-scale graphics and visualizations embedded in text documents. Word-scale graphics include both data-driven representations such as word-scale visualizations and sparklines, and non-data-driven visual marks. Their design, function, and use has so far received little research attention. We present the results of an open ended exploratory study with 9 graphic designers. The study resulted in a rich collection of different types of graphics, data provenance, and relationships between text, graphics, and data. Based on this corpus, we present a systematic overview of word-scale graphic designs, and examine how designers used them. We also discuss the designers? goals in creating their graphics, and characterize how they used word-scale graphics to visualize data, add emphasis, and create alternative narratives. Building on these examples, we discuss implications for the design of authoring tools for word-scale graphics and visualizations, and explore how new authoring environments could make it easier for designers to integrate them into documents",,,,,vimeo 230834366,10.1109/TVCG.2016.2618797,2016,2017,InfoVis,301-D,Thursday,Text and Machine Learning,,9:10:00 AM,9:30:00 AM
openaccessvis.csv,TVCG,TVCG,vispubdata.org: A Metadata Collection about IEEE Visualization (VIS) Publications,,"Petra Isenberg, Florian Heimerl, Steffen Koch, Tobias Isenberg, Panpan Xu, Charles Stolper, Michael Sedlmair, Jian Chen, Torsten Moller, John T. Stasko",https://hal.inria.fr/hal-01376597/file/Isenberg_2017_VMC.pdf,"We have created and made available to all a dataset with information about every paper that has appeared at the IEEE Visualization (VIS) set of conferences: InfoVis, SciVis, VAST, and Vis. The information about each paper includes its title, abstract, authors, and citations to other papers in the conference series, among many other attributes. This article describes the motivation for creating the dataset, as well as our process of coalescing and cleaning the data, and a set of three visualizations we created to facilitate exploration of the data. This data is meant to be useful to the broad data visualization community to help understand the evolution of the field and as an example document collection for text data visualization research.",http://vispubdata.org,https://docs.google.com/spreadsheets/d/1xgoOPu28dQSSGPIp_HHQs0uvvcyLNdkMF9XtRajhhxU/edit?usp=sharing,,,vimeo 230834115,10.1109/TVCG.2016.2615308,2016,2017,VAST,207,Wednesday,Text Analytics,,10:50:00 AM,11:10:00 AM
openaccessvis.csv,TVCG,TVCG,A Systematic Review of Experimental Studies on Data Glyphs,,"Johannes Fuchs, Petra Isenberg, Anastasia Bezerianos, Daniel Keim",https://hal.inria.fr/hal-01378429/document,"We systematically reviewed 64 user-study papers on data glyphs to help researchers and practitioners gain an informed understanding of tradeoffs in the glyph design space. The glyphs we consider are individual representations of multi-dimensional data points, often meant to be shown in small-multiple settings. Over the past 60 years many different glyph designs were proposed and many of these designs have been subjected to perceptual or comparative evaluations. Yet, a systematic overview of the types of glyphs and design variations tested, the tasks under which they were analyzed, or even the study goals and results does not yet exist. In this paper we provide such an overview by systematically sampling and tabulating the literature on data glyph studies, listing their designs, questions, data, and tasks. In addition we present a concise overview of the types of glyphs and their design characteristics analyzed by researchers in the past, and a synthesis of the study results. Based on our meta analysis of all results we further contribute a set of design implications and a discussion on open research directions.",,,,,vimeo 230834154,10.1109/TVCG.2016.2549018,2017,2017,InfoVis,105-ABC,Friday,Evaluation,,8:50:00 AM,9:10:00 AM
openaccessvis.csv,TVCG,TVCG,Evaluating Cartogram Effectiveness,,"Sabrina Nusrat, Muhammad Jawaherul Alam, Stephen Kobourov",https://arxiv.org/pdf/1504.02218.pdf,"Cartograms are maps in which areas of geographic regions, such as countries and states, appear in proportion to some variable of interest, such as population or income. Cartograms are popular visualizations for geo-referenced data that have been used for over a century to illustrate patterns and trends in the world around us. Despite the popularity of cartograms, and the large number of cartogram types, there are few studies evaluating the effectiveness of cartograms in conveying information. Based on a recent task taxonomy for cartograms, we evaluate four major types of cartograms: contiguous, non-contiguous, rectangular, and Dorling cartograms. We first evaluate the effectiveness of these cartogram types by quantitative performance analysis (time and error). Second, we collect qualitative data with an attitude study and by analyzing subjective preferences. Third, we compare the quantitative and qualitative results with the results of a metrics-based cartogram evaluation. Fourth, we analyze the results of our study in the context of cartography, geography, visual perception, and demography. Finally, we consider implications for design and possible improvements.",,,,,vimeo 230834493,10.1109/TVCG.2016.2642109,2016,2017,InfoVis,105-ABC,Friday,Evaluation,,9:30:00 AM,9:50:00 AM
openaccessvis.csv,TVCG,TVCG,A Statistical Direct Volume Rendering Framework for Visualization of Uncertain Data,,"Elham Sakhaee, Alireza Entezari",https://www.cise.ufl.edu/~esakhaee/papers/VIS/uncertaintyDVR.pdf,"With uncertainty present in almost all modalities of data acquisition, reduction, transformation, and representation, there is a growing demand for mathematical analysis of uncertainty propagation in data processing pipelines. In this paper, we present a statistical framework for quantification of uncertainty and its propagation in the main stages of the visualization pipeline. We propose a novel generalization of Irwin-Hall distributions from the statistical viewpoint of splines and box-splines, that enables interpolation of random variables. Moreover, we introduce a probabilistic transfer function classification model that allows for incorporating probability density functions into the volume rendering integral. Our statistical framework allows for incorporating distributions from various sources of uncertainty which makes it suitable in a wide range of visualization applications. We demonstrate effectiveness of our approach in visualization of ensemble data, visualizing large datasets at reduced scale, iso-surface extraction, and visualization of noisy data.",,,,,vimeo 230834547,10.1109/TVCG.2016.2637333,2016,2017,SciVis,207,Tuesday,Volume Rendering,,4:35:00 PM,4:55:00 PM
openaccessvis.csv,TVCG,TVCG,The Subspace Voyager: Exploring High-Dimensional Data along a Continuum of Salient 3D Subspaces,,"Bing Wang, Klaus Mueller",https://arxiv.org/ftp/arxiv/papers/1603/1603.04781.pdf,"Analyzing high-dimensional data and finding hidden patterns is a difficult problem and has attracted numerous research efforts. Automated methods can be useful to some extent but bringing the data analyst into the loop via interactive visual tools can help the discovery process tremendously. An inherent problem in this effort is that humans lack the mental capacity to truly understand spaces exceeding three spatial dimensions. To keep within this limitation, we describe a framework that decomposes a high-dimensional data space into a continuum of generalized 3D subspaces. Analysts can then explore these 3D subspaces individually via the familiar trackball interface while using additional facilities to smoothly transition to adjacent subspaces for expanded space comprehension. Since the number of such subspaces suffers from combinatorial explosion, we provide a set of data-driven subspace selection and navigation tools which can guide users to interesting subspaces and views. A subspace trail map allows users to manage the explored subspaces, keep their bearings, and return to interesting subspaces and views. Both trackball and trail map are each embedded into a word cloud of attribute labels which aid in navigation. We demonstrate our system via several use cases in a diverse set of application areas ? cluster analysis and refinement, information discovery, and supervised training of classifiers. We also report on a user study that evaluates the usability of the various interactions our system provides.",,,,,youtube c-yKtajfGQE,10.1109/TVCG.2017.2672987,2016,2017,VAST,301-C,Wednesday,High-dimensional Data,,9:50:00 AM,10:10:00 AM
openaccessvis.csv,TVCG,TVCG,TopKube: A Rank-Aware Data Cube for Real-Time Exploration of Spatiotemporal Data,,"Fabio Miranda, Lauro Lins, James Klosowski, Claudio Silva",https://vgc.poly.edu/~fmiranda/topkube/tvcg-2017-topkube.pdf,"From economics to sports to entertainment and social media, ranking objects according to some notion of importance is a fundamental tool we humans use all the time to better understand our world. With the ever-increasing amount of user-generated content found online, ?what?s trending? is now a commonplace phrase that tries to capture the zeitgeist of the world by ranking the most popular microblogging hashtags in a given region and time. However, before we can understand what these rankings tell us about the world, we need to be able to more easily create and explore them, given the significant scale of today?s data. In this paper, we describe the computational challenges in building a real-time visual exploratory tool for finding top-ranked objects; build on the recent work involving in-memory and rank-aware data cubes to propose TOPKUBE: a data structure that answers top-k queries up to one order of magnitude faster than the previous state of the art; demonstrate the usefulness of our methods using a set of real-world, publicly available datasets; and provide a new set of benchmarks for other researchers to validate their methods and compare to our own.",,,,,,10.1109/TVCG.2017.2671341,2017,2017,InfoVis,301-D,Tuesday,Time and Space,,5:35:00 PM,5:55:00 PM
openaccessvis.csv,TVCG,TVCG,Perceptual Biases in Font Size as a Data Encoding,,"Eric Carlson Alexander, Chih-Ching Chang, Mariana Shimabukuro, Steve Franconeri, Christopher Collins, Michael Gleicher",,"Many visualizations, including word clouds, cartographic labels, and word trees, encode data within the sizes of fonts. While font size can be an intuitive dimension for the viewer, using it as an encoding can introduce factors that may bias the perception of the underlying values. Viewers might conflate the size of a word?s font with a word?s length, the number of letters it contains, or with the larger or smaller heights of particular characters (?o? vs. ?p? vs. ?b?). We present a collection of empirical studies showing that such factors?which are irrelevant to the encoded values?can indeed influence comparative judgements of font size, though less than conventional wisdom might suggest. We highlight the largest potential biases, and describe a strategy to mitigate them.",,,,,vimeo 230834531,10.1109/TVCG.2017.2723397,2017,2017,InfoVis,301-D,Wednesday,Perception,,9:10:00 AM,9:30:00 AM
openaccessvis.csv,TVCG,TVCG,Data Flow Analysis and Visualization for Spatiotemporal Statistical Data without Trajectory Information,,"Seokyeon Kim, Seongmin Jeong, Insoo Woo, Yun Jang, Ross Maciejewski, David Ebert",http://rmaciejewski.faculty.asu.edu/papers/2017/Yun-Flow.pdf,"Geographic visualization research has focused on a variety of techniques to represent and explore spatiotemporal data. The goal of those techniques is to enable users to explore events and interactions over space and time in order to facilitate the discovery of patterns, anomalies and relationships within the data. However, it is difficult to extract and visualize data flow patterns over time for non-directional statistical data without trajectory information. In this work, we develop a novel flow analysis technique to extract, represent, and analyze flow maps of non-directional spatiotemporal data unaccompanied by trajectory information. We estimate a continuous distribution of these events over space and time, and extract flow fields for spatial and temporal changes utilizing a gravity model. Then, we effectively visualize the spatiotemporal patterns in the data by employing flow visualization techniques. The user is presented with temporal trends of geo-referenced discrete events on a map. As such, overall spatiotemporal data flow patterns help users analyze geo-referenced temporal events, such as disease outbreaks, crime patterns, etc. To validate our model, we discard the trajectory information in an origin-destination dataset and apply our technique to the data and compare the derived trajectories and the original. Finally, we present spatiotemporal trend analysis for statistical datasets including twitter data, maritime search and rescue events, and syndromic surveillance",,,,,vimeo 230834322,10.1109/TVCG.2017.2666146,2017,2017,VAST,301-C,Tuesday,"Space, Time, Movement",,3:20:00 PM,3:40:00 PM
openaccessvis.csv,TVCG,TVCG,Evaluating Interactive Graphical Encodings for Data Visualization,,"Bahador Saket, Arjun Srinivasan, Eric D. Ragan, Alex Endert",http://bahadorsaket.com/publication/encodingsPaper.pdf,"User interfaces for data visualization often consist of two main components: control panels for user interaction and visual representation. A recent trend in visualization is directly embedding user interaction into the visual representations. For example, instead of using control panels to adjust visualization parameters, users can directly adjust basic graphical encodings (e.g., changing distances between points in a scatterplot) to perform similar parameterizations. However, enabling embedded interactions for data visualization requires a strong understanding of how user interactions influence the ability to accurately control and perceive graphical encodings. In this paper, we study the effectiveness of these graphical encodings when serving as the method for interaction. Our user study includes 12 interactive graphical encodings. We discuss the results in terms of task performance and interaction effectiveness metrics.",https://medium.com/@GT_Vis/evaluating-interactive-graphical-encodings-for-data-visualization-b9b8b4bf47f8,https://github.com/gtvalab/interactive-graphical-encodings,https://github.com/gtvalab/interactive-graphical-encodings/tree/master/Supplementary%20Materials/Raw%20Data,,vimeo 230834446,10.1109/TVCG.2017.2680452,2017,2017,InfoVis,301-D,Wednesday,Perception,,9:50:00 AM,10:10:00 AM
openaccessvis.csv,TVCG,TVCG,PETMiner - A Visual Analysis Tool for Petrophysical Properties of Core Sample Data,,"Dave G. Harrison, Nick D. Efford, Quentin J. Fisher, Roy A. Ruddle",http://eprints.whiterose.ac.uk/113580/1/harrison-ieee-tvcg-2017.pdf,"The aim of the PETMiner software is to reduce the time and monetary cost of analysing petrophysical data that is obtained from reservoir sample cores. Analysis of these data requires tacit knowledge to fill ?gaps? so that predictions can be made for incomplete data. Through discussions with 30 industry and academic specialists, we identified three analysis use cases that exemplified the limitations of current petrophysics analysis tools. We used those use cases to develop nine core requirements for PETMiner, which is innovative because of its ability to display detailed images of the samples as data points, directly plot multiple sample properties and derived measures for comparison, and substantially reduce interaction cost. An 11-month evaluation demonstrated benefits across all three use cases by allowing a consultant to: (1) generate more accurate reservoir flow models, (2) discover a previously unknown relationship between one easy-to-measure property and another that is costly, and (3) make a 100-fold reduction in the time required to produce plots for a report.",,,,,vimeo 230834380,10.1109/TVCG.2017.2682865,2017,2017,SciVis,106-ABC,Friday,Applications and Visual analysis,,9:10:00 AM,9:30:00 AM
openaccessvis.csv,TVCG,TVCG,Indexed-Points Parallel Coordinates Visualization of Multivariate Correlations,,"Liang Zhou, Daniel Weiskopf",,"We address the problem of visualizing multivariate correlations in parallel coordinates. We focus on multivariate correlation in the form of linear relationships between multiple variables. Traditional parallel coordinates are well prepared to show negative correlations between two attributes by distinct visual patterns. However, it is difficult to recognize positive correlations in parallel coordinates. Furthermore, there is no support to highlight multivariate correlations in parallel coordinates. In this paper, we exploit the indexed point representation of p-flats (planes in multidimensional data) to visualize local multivariate correlations in parallel coordinates. Our method yields clear visual signatures for negative and positive correlations alike, and it supports large datasets. All information is shown in a unified parallel coordinates framework, which leads to easy and familiar user interactions for analysts who have experience with traditional parallel coordinates. The usefulness of our method is demonstrated through examples of typical multidimensional datasets.",,,,,vimeo 230834568,10.1109/TVCG.2017.2698041,2017,2017,InfoVis,301-D,Wednesday,Multidimensional Data,,3:20:00 PM,3:40:00 PM
openaccessvis.csv,TVCG,TVCG,Visual Analysis of Inclusion Dynamics in Two-Phase Flow,,"Grzegorz Karch, Fabian Beck, Moritz Ertl, Christian Meister, Kathrin Schulte, Bernhard Weigand, Thomas Ertl, Filip Sadlo",,,,,,,vimeo 230834468,10.1109/TVCG.2017.2692781,2017,2017,SciVis,207,Wednesday,Flow Visualization,,8:50:00 AM,9:10:00 AM
openaccessvis.csv,TVCG,TVCG,A Combined Eulerian-Lagrangian Data Representation for Large-scale Applications,,"Franz Sauer, Jinrong Xie, Kwan-Liu Ma",,"The Eulerian and Lagrangian reference frames each provide a unique perspective when studying and visualizing results from scientific systems. As a result, many large-scale simulations produce data in both formats, and analysis tasks that simultaneously utilize information from both representations are becoming increasingly popular. However, due to their fundamentally different nature, drawing correlations between these data formats is a computationally difficult task, especially in a large-scale setting. In this work, we present a new data representation which combines both reference frames into a joint Eulerian-Lagrangian format. By reorganizing Lagrangian information according to the Eulerian simulation grid into a ?unit cell? based approach, we can provide an efficient out-of-core means of sampling, querying, and operating with both representations simultaneously. We also extend this design to generate multi-resolution subsets of the full data to suit the viewer?s needs and provide a fast flow-aware trajectory construction scheme. We demonstrate the effectiveness of our method using three large-scale real world scientific datasets and provide insight into the types of performance gains that can be achieved.",,,,,vimeo 230834211,10.1109/TVCG.2016.2620975,2016,2017,SciVis,207,Wednesday,Flow Visualization,,9:10:00 AM,9:30:00 AM
openaccessvis.csv,TVCG,TVCG,Keshif: Rapid and Expressive Tabular Data Exploration for Novices,,"Mehmet Adil Yalcin, Niklas Elmqvist, Benjamin B Bederson",http://www.umiacs.umd.edu/~elm/projects/keshif/keshif.pdf,"General purpose graphical interfaces for data exploration are typically based on manual visualization and interaction specifications. While designing manual specification can be very expressive, it demands high efforts to make effective decisions, therefore reducing exploratory speed. Instead, principled automated designs can increase exploratory speed, decrease learning efforts, help avoid ineffective decisions, and therefore better support data analytics novices. Towards these goals, we present Keshif, a new systematic design for tabular data exploration. To summarize a given dataset, Keshif aggregates records by value within attribute summaries, and visualizes aggregate characteristics using a consistent design based on data types. To reveal data distribution details, Keshif features three complementary linked selections: highlighting, filtering, and comparison. Keshif further increases expressiveness through aggregate metrics, absolute/part-of scale modes, calculated attributes, and saved selections, all working in synchrony. Its automated design approach also simplifies authoring of dashboards composed of summaries and individual records from raw data using fluid interaction. We show examples selected from 160+ datasets from diverse domains. Our study with novices shows that after exploring raw data for 15 minutes, our participants reached close to 30 data insights on average, comparable to other studies with skilled users using more complex tools.",https://www.keshif.me/,https://github.com/adilyalcin/Keshif,,,youtube 3Hmvms-1grU,10.1109/TVCG.2017.2723393,2017,2017,InfoVis,301-D,Wednesday,Multidimensional Data,,2:40:00 PM,3:00:00 PM
openaccessvis.csv,TVCG,TVCG,DSPCP: A Data Scalable Approach for Identifying Relationships in Parallel Coordinates,,"Hoa Nguyen, Paul Rosen",http://www.cspaul.com/publications/Nguyen.2017.TVCG.pdf,"Parallel coordinates plots (PCPs) are a well-studied technique for exploring multi-attribute datasets. In many situations, users find them a flexible method to analyze and interact with data. Unfortunately, using PCPs becomes challenging as the number of data items grows large or multiple trends within the data mix in the visualization. The resulting overdraw can obscure important features. A number of modifications to PCPs have been proposed, including using color, opacity, smooth curves, frequency, density, and animation to mitigate this problem. However, these modified PCPs tend to have their own limitations in the kinds of relationships they emphasize. We propose a new data scalable design for representing and exploring data relationships in PCPs. The approach exploits the point/line duality property of PCPs and a local linear assumption of data to extract and represent relationship summarizations. This approach simultaneously shows relationships in the data and the consistency of those relationships. Our approach supports various visualization tasks, including mixed linear and nonlinear pattern identification, noise detection, and outlier detection, all in large data. We demonstrate these tasks on multiple synthetic and real-world datasets.",,,,,youtube OApngoT5kbg,10.1109/TVCG.2017.2661309,2017,2017,SciVis,106-ABC,Friday,Applications and Visual analysis,,8:50:00 AM,9:10:00 AM
openaccessvis.csv,TVCG,TVCG,RCLens: Interactive Rare Category Exploration and Identification,,"Hanfei Lin, Siyuan Gao, David Gotz, Fan Du, Jingrui He, Nan Cao",http://frankdu.org/papers/lin2017tvcg.pdf,"Rare category identification is an important task in many application domains, ranging from network security, to financial fraud detection, to personalized medicine. These are all applications which require the discovery and characterization of sets of rare but structurally-similar data entities which are obscured within a larger but structurally different dataset. This paper introduces RCLens, a visual analytics system designed to support user-guided rare category exploration and identification. RCLens adopts a novel active learning-based algorithm to iteratively identify more accurate rare categories in response to user-provided feedback. The algorithm is tightly integrated with an interactive visualization-based interface which supports a novel and effective workflow for rare category identification. This paper (1) defines RCLens? underlying active-learning algorithm; (2) describes the visualization and interaction designs, including a discussion of how the designs support user-guided rare category identification; and (3) presents results from an evaluation demonstrating RCLens? ability to support the rare category identification process",,,,,vimeo 230834420,10.1109/TVCG.2017.2711030,2017,2017,VAST,207,Thursday,Sensemaking,,4:15:00 PM,4:35:00 PM
openaccessvis.csv,CG&A,CGA,ARIES: Enabling Visual Exploration and Organization of Art Image Collections,,"Lhaylla Crissaff, Louisa Wood Ruby, Samantha Deutch, R. Luke DuBois, Jean-Daniel Fekete, Juliana Freire, Claudio Silva",,,,,,,vimeo 230841414,,2017,2017,Other,101-ABC,Wednesday,Spatiotemporal Applications,,10:30:00 AM,10:50:00 AM
openaccessvis.csv,CG&A,CGA,BKViz: A Basketball Visual Analysis Tool,,"Antonio G. Losada, Roberto Theron, Alejandro Benito",,"The amount of data available nowadays in the sports field is hard to comprehend using classic analytic methods. This calls for the development of systems such as the prototype discussed here, which makes it possible to manipulate chunks of data to then portray them in visual ways, easing their understanding. Based on basketball, this tool helps users in reaching conclusions regarding performances during individual matches. This enables them to gather knowledge about play sequences, the events occurring at different moments, and the style of play teams employ based on player chemistry. Using multiple visualizations in an integrated system, data can be manipulated to vary how they are shown and change their analytic power as needed. With interaction and sim- ple comprehension based on visualization being the two cornerstones, the challenge was to provide a tool able to showcase patterns and study actions in an innovative and combined way not yet exploited.",http://vis.usal.es/bkviz/,,,,youtube Q6QGP6TaIQM,10.1109/MCG.2016.124,2016,2017,Other,101-ABC,Thursday,Sports Data Visual Analytics,,10:30:00 AM,10:50:00 AM
openaccessvis.csv,CG&A,CGA,Director's Cut: Analysis and Annotation of Soccer Matches,,"Manuel Stein, Halld¢r Janetzko, Thorsten Breitkreutz, Daniel Seebacher, Tobias Schreck, Michael Grossniklaus, Iain Couzin, Daniel Keim",https://kops.uni-konstanz.de/bitstream/handle/123456789/35829/Stein_0-371514.pdf,"For development and alignment of tactics and strategies, professional soccer analysts spend up to three working days manually analyzing and annotating professional soccer matches. In an effort to improve soccer player and match analysis, a visual-interactive and data-analysis support system focuses on key situations by using rule-based filtering and automatically annotating key types of soccer match elements. The authors evaluate the proposed approach by analyzing real-world soccer matches and several expert studies. Quantitative measures show the proposed methods can significantly outperform naive solutions.",,,,,vimeo 230841435,10.1109/MCG.2016.102,2016,2017,Other,101-ABC,Thursday,Sports Data Visual Analytics,,10:50:00 AM,11:10:00 AM
openaccessvis.csv,CG&A,CGA,Using Gap Charts to Visualize the Temporal Evolution of Ranks and Scores,,"Charles Perin, Jeremy Boy, Frederic Vernier",http://charles.perin.free.fr/data/pub/gapchart.pdf,"We present Gap Charts, a novel class of line charts designed for visualizing the evolution of rankings over time, with a particular focus on sports data. Gap Charts show entries, e. g., teams participating in a competition, that are ranked over time according to a performance metric like a growing number of points or a score. The main advantages of Gap Charts are that 1) tied entries never overlap?only changes in rank generate limited overlap between time-steps; and 2) gaps between entries show the magnitude of their score difference. We evaluate the effectiveness of Gap Charts for performing different types of tasks, and find that they outperform standard time-dependent ranking visualizations for tasks that involve identifying and understanding evolutions in both ranks and scores. Finally, we show that Gap Charts are a generic and scalable class of line charts by applying them to a variety of different datasets.",,,,,vimeo 230841502,10.1109/MCG.2016.100,2016,2017,Other,101-ABC,Thursday,Sports Data Visual Analytics,,11:10:00 AM,11:30:00 AM
openaccessvis.csv,CG&A,CGA,Glyph Visualization: A Fail-Safe Design Scheme Based on Quasi-Hamming Distances,,"Philip A. Legg, Eamonn Maguire, Simon Walton, Min Chen",http://eprints.uwe.ac.uk/28652/1/CG_CG%26A-2015-11-0124.R2_Legg.pdf,"In many applications of spatial or temporal visualization, glyphs provide an effective means for encoding multivariate data. However, because glyphs are typically small, they are vulnerable to various perceptual errors. In information theory and communication, the concept of Hamming distance underpins the study of codes that support error detection and correction by the receiver without the need for corroboration from the sender. In this work, we propose the novel concept of quasi-Hamming distance in the context of glyph design. We examine the feasibility of estimating quasi-Hamming distance between a pair of glyphs, and the minimal Hamming distance for a glyph set. This measurement enables glyph designers to determine the differentiability between glyphs, facilitating design optimization by maximizing distances between glyphs under various design constraints. We demonstrate this concept with a case study of visualizing file system events for multiple users. Our evaluation shows that the concept of quasi-Hamming distance facilitates separability in glyph design and helps to reduce the vulnerability of glyph-based visualization.",,,,,vimeo 230841589,10.1109/MCG.2016.66,2017,2017,Other,101-ABC,Wednesday,Spatiotemporal Applications,,10:50:00 AM,11:10:00 AM
openaccessvis.csv,CG&A,CGA,Sport Tournament Predictions by Direct Manipulation,,"Romain Vuillemot, Charles Perin",http://romain.vuillemot.net/publis/cga16-sports-tournament-predictions-using-direct-manipulation.pdf,"We present an advanced interface for predicting sport tournaments by direct manipulation. The interface allows users to focus on their prediction tasks, by dragging and dropping teams to their final outcome in the competition, e. g., as winner or semi-finalist. This interface allows predictions to be made non-linearly, such as prediction winner first and filling up the other games. This better matches the way people actually make predictions, while the current interfaces can only be filled linearly, with text fields widgets as input. We released a first version of the interface for the 2014 FIFA soccer World Cup that validated the use of direct manipulation as alternative to widgets. We released an improved version a year later for the 2015/2016 UEFA soccer Champions League, which included a tracking system to understand users interactions. We recorded a total of 504, 307 interaction logs from 3, 029 unique visitors, among them 198 fully completed the prediction from scratch. From our analysis of logs, we provide a list of strategies that people employ to perform predictions, and which will help inform the design of further prediction interfaces that preserve the flow and concentration of users",,,,,vimeo 230841474,,2016,2017,Other,101-ABC,Thursday,Sports Data Visual Analytics,,11:30:00 AM,11:50:00 AM
openaccessvis.csv,CG&A,CGA,StatCast Dashboard: Exploration of Spatiotemporal Baseball Data,,"Marcos Lage, Jorge Henrique Ono, Daniel Cervone, Justin Chiang, Carlos Dietrich, Claudio Silva",,,,,,,youtube 3t9PBDg4ato,10.1109/MCG.2016.101,2016,2017,Other,101-ABC,Wednesday,Spatiotemporal Applications,,11:10:00 AM,11:30:00 AM
openaccessvis.csv,CG&A,CGA,VisAdapt: A Visualization Tool to Support Climate Change Adaptation,,"Jimmy Johansson, Tomasz Opach, Erik Glaas, Tina-Simone Neset, Carlo Navarra, Bjorn-Ola Linner, Jan Ketil Rod",http://webstaff.itn.liu.se/~jimjo94/papers/CG_and_A-2015-06-Johansson.pdf,"In this article we present the design and implementation of the web-based visualization tool VisAdapt, developed to support homeowners in the Nordic countries to assess anticipated climate change risks, which are expected to negatively impact their living conditions and to identify possible adaptation measures. The tool guides the user through a three-step visual exploration process to facilitate the exploration of risks and adaptive action, specifically modified to the users? location and house type. We have developed VisAdapt over the course of three years in close collaboration with domain experts and end users to ensure the validity of the included data and the efficiency of the visual interface. Although Nordic homeowners are the targeted end-users of VisAdapt, the insights gained from the development process and the lessons learned from the project could be valuable for researchers in a wide area of application domains. These include how to make global changes tangible on the local level, how to develop easily accessible flow of information and how to incorporate end-user evaluations in the development process.",,,,,vimeo 230841562,10.1109/MCG.2016.49,2017,2017,Other,101-ABC,Wednesday,Spatiotemporal Applications,,11:30:00 AM,11:50:00 AM
openaccessvis.csv,InfoVis,TVCG,Active Reading of Visualizations,,"Jagoda Walny, Samuel Huron, Charles Perin, Tiffany Wun, Richard Pusch, Sheelagh Carpendale",http://charles.perin.free.fr/data/pub/activeReading.pdf,"We investigate whether the notion of active reading for text might be usefully applied to visualizations. Through a qualitative study we explored whether people apply observable active reading techniques when reading paper-based visualizations. Participants used a range of physical actions while reading, and from these we synthesized an initial set of active reading techniques for visualizations. To learn more about the potential impact such techniques may have on visualization reading, we implemented support for one type of physical action from our observations (making freeform marks) in an interactive graph visualization. Results from our quantitative study of this implementation show that interactive support for active reading techniques can improve the accuracy of performing low-level visualization tasks. Together, our studies suggest that the active reading space is ripe for research exploration within visualization and can lead to new interactions that make for a more flexible and effective visualization reading experience.",,,http://innovis.cpsc.ucalgary.ca/supplemental/Active-Reading-of-Visualizations/#S21,,youtube pj0g8_Kcq9A,,2018,2017,InfoVis,301-D,Thursday,Understanding Visualization,,2:40:00 PM,3:00:00 PM
openaccessvis.csv,InfoVis,TVCG,Assessing the Graphical Perception of Time and Speed on 2D + Time Trajectories,,"Charles Perin, Tiffany Wun, Richard Pusch, Sheelagh Carpendale",http://innovis.cpsc.ucalgary.ca/supplemental/2DTimeTrajectories/2018_VIS_assessing_graphical_perception.pdf,"We empirically evaluate the extent to which people perceive non-constant time and speed encoded on 2D paths. In our graphical perception study, we evaluate nine encodings from the literature for both straight and curved paths. Visualizing time and speed information is a challenge when the x and y axes already encode other data dimensions, for example when plotting a trip on a map. This is particularly true in disciplines such as time-geography and movement analytics that often require visualizing spatio-temporal trajectories. A common approach is to use 2D+time trajectories, which are 2D paths for which time is an additional dimension. However, there are currently no guidelines regarding how to represent time and speed on such paths. Our study results provide InfoVis designers with clear guidance regarding which encodings to use and which ones to avoid; in particular, we suggest using color value to encode speed and segment length to encode time whenever possible.",,,http://innovis.cpsc.ucalgary.ca/supplemental/2DTimeTrajectories/#study,,youtube OGccwtpg8JI,,2018,2017,InfoVis,301-D,Tuesday,Time and Space,,4:55:00 PM,5:15:00 PM
openaccessvis.csv,InfoVis,TVCG,Blinded with Science or Informed by Charts? A Replication Study,,"Pierre Dragicevic, Yvonne Jansen",http://hal.upmc.fr/hal-01580259/document,"We provide a reappraisal of Tal and Wansink?s study <em>?Blinded with Science?</em>, where seemingly trivial charts were shown to increase belief in drug efficacy, presumably because charts are associated with science. Through a series of four replications conducted on two crowdsourcing platforms, we investigate an alternative explanation, namely, that the charts allowed participants to better assess the drug?s efficacy. Considered together, our experiments suggest that the chart seems to have indeed promoted understanding, although the effect is likely very small. Meanwhile, we were unable to replicate the original study?s findings, as text with chart appeared to be no more persuasive ? and sometimes less persuasive ? than text alone. This suggests that the effect may not be as robust as claimed and may need specific conditions to be reproduced. Regardless, within our experimental settings and considering our study as a whole (N = 623), the chart?s contribution to understanding was clearly larger than its contribution to persuasion.",,,http://www.aviz.fr/blinded,,vimeo 230841144,10.1109/TVCG.2017.2744298,2018,2017,InfoVis,301-D,Thursday,Understanding Visualization,,3:00:00 PM,3:20:00 PM
openaccessvis.csv,InfoVis,TVCG,Bridging From Goals to Tasks with Design Study Analysis Reports,,"Heidi Lam, Melanie Tory, Tamara Munzner",https://research.tableau.com/sites/default/files/GoalsToTasks.pdf,"Visualization researchers and practitioners engaged in generating or evaluating designs are faced with the difficult problem of transforming the questions asked and actions taken by target users from domain-specific language and context into more abstract forms. Existing abstract task classifications aim to provide support for this endeavour by providing a carefully delineated suite of actions. Our experience is that this bottom-up approach is part of the challenge: low-level actions are difficult to interpret without a higher-level context of analysis goals and the analysis process. To bridge this gap, we propose a framework based on analysis reports derived from open-coding 20 design study papers published at IEEE InfoVis 2009-2015, to build on the previous work of abstractions that collectively encompass a broad variety of domains. The framework is organized in two axes illustrated by nine analysis goals. It helps situate the analysis goals by placing each goal under axes of specificity (Explore, Describe, Explain, Confirm) and number of data populations (Single, Multiple). The single-population types are Discover Observation, Describe Observation, Identify Main Cause, and Collect Evidence. The multiple-population types are Compare Entities, Explain Differences, and Evaluate Hypothesis. Each analysis goal is scoped by an input and an output and is characterized by analysis steps reported in the design study papers. We provide examples of how we and others have used the framework in a top-down approach to abstracting domain problems: visualization designers or researchers first identify the analysis goals of each unit of analysis in an analysis stream, and then encode the individual steps using existing task classifications with the context of the goal, the level of specificity, and the number of populations involved in the analysis.",,http://tinyurl.com/gt27fau,,,vimeo 230841235,,2018,2017,InfoVis,301-D,Wednesday,Design,,11:30:00 AM,11:50:00 AM
openaccessvis.csv,InfoVis,TVCG,Bubble Treemaps for Uncertainty Visualization,,"Jochen G”rtler, Christoph Schulz, Daniel Weiskopf, Oliver Deussen",http://graphics.uni-konstanz.de/publikationen/Goertler2018BubbleTreemapsUncertainty/bubble-treemaps.pdf,"We present a novel type of circular treemap, where we intentionally allocate extra space for additional visual variables. With this extended visual design space, we encode hierarchically structured data along with their uncertainties in a combined diagram. We introduce a hierarchical and force-based circle-packing algorithm to compute Bubble Treemaps, where each node is visualized using nested contour arcs. Bubble Treemaps do not require any color or shading, which offers unrestricted design choices. We explore uncertainty visualization as an application of our treemaps using standard error and Monte Carlo-based statistical models. To this end, we discuss how uncertainty propagates within hierarchies. Furthermore, we show the effectiveness of our visualization using three different examples: the package structure of Flare, the S&P 500 index, and the US consumer expenditure survey.",,,,,vimeo 230840520,,2018,2017,InfoVis,301-D,Thursday,Trees and Table Tennis,,10:50:00 AM,11:10:00 AM
openaccessvis.csv,InfoVis,TVCG,CasCADe: A Novel 4D Visualization System for Virtual Construction Planning,,"Paulo Ivson, Daniel Nascimento, Waldemar Celes, Simone Barbosa",,"Building Information Modeling (BIM) provides an integrated 3D environment to manage large-scale engineering projects. The Architecture, Engineering and Construction (AEC) industry explores 4D visualizations over these datasets for virtual construction planning. However, existing solutions lack adequate visual mechanisms to inspect the underlying schedule and make inconsistencies readily apparent. The goal of this paper is to apply best practices of information visualization to improve 4D analysis of construction plans. We first present an extensive review of previous work that identifies common use cases and limitations. We then consulted with AEC professionals to specify the main design requirements for such applications. These guided the development of CasCADe, a novel 4D visualization system where task sequencing and spatio-temporal simultaneity are immediately evident. This unique framework enables the combination of diverse analytical features to create an information-rich analysis environment. We also describe how engineering collaborators used CasCADe to review the real-world construction plans of an Oil & Gas process plant. The system brought forth schedule uncertainties, helped identifying work-space conflicts and other constructability issues. The results and contributions of this paper suggest new avenues for future research in information visualization for the AEC industry.",,,,,,,2018,2017,InfoVis,301-D,Tuesday,Time and Space,,4:35:00 PM,4:55:00 PM
openaccessvis.csv,InfoVis,TVCG,Conceptual and Methodological Issues in Evaluating Multidimensional Visualizations for Decision Support,,"Evanthia Dimara, Anastasia Bezerianos, Pierre Dragicevic",https://hal.inria.fr/hal-01584729/document,"We explore how to rigorously evaluate multidimensional visualizations for their ability to support decision making. We first define multi-attribute choice tasks, a type of decision task commonly performed with such visualizations. We then identify which of the existing multidimensional visualizations are compatible with such tasks, and set out to evaluate three elementary visualizations: parallel coordinates, scatterplot matrices and tabular visualizations. Our method consists in first giving participants low-level analytic tasks, in order to ensure that they properly understood the visualizations and their interactions. Participants are then given multi-attribute choice tasks consisting of choosing holiday packages. We assess decision support through multiple objective and subjective metrics, including a decision accuracy metric based on the consistency between the choice made and self-reported preferences for attributes. We found the three visualizations to be comparable on most metrics, with a slight advantage for tabular visualizations. In particular, tabular visualizations allow participants to reach decisions faster. Thus, although decision time is typically not central in assessing decision support, it can be used as a tie-breaker when visualizations achieve similar decision accuracy. Our results also suggest that indirect methods for assessing choice confidence may allow to better distinguish between visualizations than direct ones. We finally discuss the limitations of our methods and directions for future work, such as the need for more sensitive metrics of decision support.",,,,,vimeo 230840695,10.1109/TVCG.2017.2745138,2018,2017,InfoVis,301-D,Thursday,Understanding Visualization,,2:00:00 PM,2:20:00 PM
openaccessvis.csv,InfoVis,TVCG,Considerations for Visualizing Comparison,,Michael Gleicher,http://graphics.cs.wisc.edu/Papers/2018/Gle18/viscomp.pdf,"Supporting comparison is a common and diverse challenge in visualization. Such support is difficult to design because solutions must address both the specifics of their scenario as well as the general issues of comparison. This paper aids designers by providing a strategy for considering those general issues. It presents four considerations that abstract comparison. These considerations identify issues and categorize solutions in a domain independent manner. The first considers how the common elements of comparison?a target set of items that are related and an action the user wants to perform on that relationship?are present in an analysis problem. The second considers why these elements lead to challenges because of their scale, in number of items, complexity of items, or complexity of relationship. The third considers what strategies address the identified scaling challenges, grouping solutions into three broad categories. The fourth considers which visual designs map to these strategies to provide solutions for a comparison analysis problem. In sequence, these considerations provide a process for developers to consider support for comparison in the design of visualization tools. Case studies show how these considerations can help in the design and evaluation of visualization solutions for comparison problems.",,,,,vimeo 230841111,,2018,2017,InfoVis,301-D,Wednesday,Design,,10:50:00 AM,11:10:00 AM
openaccessvis.csv,InfoVis,TVCG,CyteGuide: Visual Guidance for Hierarchical Single-Cell Analysis,,"Thomas H”llt, Nicola Pezzotti, Vincent van Unen, Frits Koning, Boudewijn P. F. Lelieveldt, Anna Vilanova",https://cyteguide.cytosplore.org/assets/files/vis2017_hollt_cyteguide.pdf,"Single-cell analysis through mass cytometry has become an increasingly important tool for immunologists to study the immune system in health and disease. Mass cytometry creates a high-dimensional description vector for single cells by time-of-flight measurement. Recently, t-Distributed Stochastic Neighborhood Embedding (t-SNE) has emerged as one of the state-of-the-art techniques for the visualization and exploration of single-cell data. Ever increasing amounts of data lead to the adoption of Hierarchical Stochastic Neighborhood Embedding (HSNE), enabling the hierarchical representation of the data. Here, the hierarchy is explored selectively by the analyst, who can request more and more detail in areas of interest. Such hierarchies are usually explored by visualizing disconnected plots of selections in different levels of the hierarchy. This poses problems for navigation, by imposing a high cognitive load on the analyst. In this work, we present an interactive summary-visualization to tackle this problem. CyteGuide guides the analyst through the exploration of hierarchically represented single-cell data, and provides a complete overview of the current state of the analysis. We conducted a two-phase user study with domain experts that use HSNE for data exploration. We first studied their problems with their current workflow using HSNE and the requirements to ease this workflow in a field study. These requirements have been the basis for our visual design. In the second phase, we verified our proposed solution in a user evaluation.",https://cyteguide.cytosplore.org/,,https://cyteguide.cytosplore.org/assets/files/raw_timings.csv,,vimeo 223373844,,2018,2017,InfoVis,301-D,Thursday,Trees and Table Tennis,,11:30:00 AM,11:50:00 AM
openaccessvis.csv,InfoVis,TVCG,Data Through Others' Eyes: The Impact of Visualizing Others' Expectations on Visualization Interpretation,,"Yea-Seul Kim, Katharina Reinecke, Jessica Hullman",http://faculty.washington.edu/jhullman/VIS17_Expectations_SocialVis.pdf,"In addition to visualizing input data, interactive visualizations have the potential to be social artifacts that reveal other people?s perspectives on the data. However, how such social information embedded in a visualization impacts a viewer?s interpretation of the data remains unknown. Inspired by recent interactive visualizations that display people?s expectations of data against the data, we conducted a controlled experiment to evaluate the effect of showing social information in the form of other people?s expectations on people?s ability to recall the data, the degree to which they adjust their expectations to align with the data, and their trust in the accuracy of the data. We found that social information that exhibits a high degree of consensus lead participants to recall the data more accurately relative to participants who were exposed to the data alone. Additionally, participants trusted the accuracy of the data less and were more likely to maintain their initial expectations when other people?s expectations aligned with their own initial expectations but not with the data. We conclude by characterizing the design space for visualizing others? expectations alongside data.",,,,,vimeo 230840801,,2018,2017,InfoVis,301-D,Thursday,Understanding Visualization,,2:20:00 PM,2:40:00 PM
openaccessvis.csv,InfoVis,TVCG,Data Visualization Saliency Model: A Tool for Evaluating Abstract Data Visualizations,,"Laura Matzen, Michael Haass, Kristin Divis, Zhiyuan Wang, Andrew Wilson",,,,,,,vimeo 230840505,10.1109/TVCG.2017.2743939,2018,2017,InfoVis,301-D,Wednesday,Perception,,8:30:00 AM,8:50:00 AM
openaccessvis.csv,InfoVis,TVCG,EdWordle: Consistency-preserving Word Cloud Editing,,"Yunhai Wang, Xiaowei Chu, Chen Bao, Lifeng Zhu, Oliver Deussen, Baoquan Chen, Michael Sedlmair",http://graphics.uni-konstanz.de/publikationen/Wang2018EdWordleConsistencypreserving/Edwordle.pdf,"We present EdWordle, a method for consistently editing word clouds. At its heart, EdWordle allows users to move and edit words while preserving the neighborhoods of other words. To do so, we combine a constrained rigid body simulation with a neighborhood-aware local Wordle algorithm to update the cloud and to create very compact layouts. The consistent and stable behavior of EdWordle enables users to create new forms of word clouds such as storytelling clouds in which the position of words is carefully edited. We compare our approach with state-of-the-art methods and show that we can improve user performance, user satisfaction, as well as the layout itself.",http://www.edwordle.net,,,,vimeo 230840872,,2018,2017,InfoVis,301-D,Thursday,Text and Machine Learning,,8:50:00 AM,9:10:00 AM
openaccessvis.csv,InfoVis,TVCG,"Exploring Multivariate Event Sequences using Rules, Aggregations, and Selections",,"Bram Cappers, Jarke van Wijk",http://www.bramcappers.nl/files/papers/eventPad.pdf,"Multivariate event sequences are ubiquitous: travel history, telecommunication conversations, and server logs are some examples. Besides standard properties such as type and timestamp, events often have other associated multivariate data. Current exploration and analysis methods either focus on the temporal analysis of a single attribute or the structural analysis of the multivariate data only. We present an approach where users can explore event sequences at multivariate and sequential level simultaneously by interactively defining a set of rewrite rules using multivariate regular expressions. Users can store resulting patterns as new types of events or attributes to interactively enrich or simplify event sequences for further investigation. In Eventpad we provide a bottom-up glyph-oriented approach for multivariate event sequence analysis by searching, clustering, and aligning them according to newly defined domain specific properties. We illustrate the effectiveness of our approach with real-world data sets including telecommunication traffic and hospital treatments",,,,,youtube 2DWVW-vLN8Q,,2018,2017,InfoVis,301-D,Wednesday,Multidimensional Data,,2:00:00 PM,2:20:00 PM
openaccessvis.csv,InfoVis,TVCG,Extracting and Retargeting Color Mappings from Bitmap Images of Visualizations,,"Jorge Poco, Angela Mayhua, Jeffrey Heer",https://idl.cs.washington.edu/files/2018-ExtractingColorMappings-InfoVis.pdf,"Visualization designers regularly use color to encode quantitative or categorical data. However, visualizations ""in the wild"" often violate perceptual color design principles and may only be available as bitmap images. In this work, we contribute a method to semi-automatically extract color encodings from a bitmap visualization image. Given an image and a legend location, we classify the legend as describing either a discrete or continuous color encoding, identify the colors used, and extract legend text using OCR methods. We then combine this information to recover the specific color mapping. Users can also correct interpretation errors using an annotation interface. We evaluate our techniques using a corpus of images extracted from scientific papers and demonstrate accurate automatic inference of color mappings across a variety of chart types. In addition, we present two applications of our method: automatic recoloring to improve perceptual effectiveness, and interactive overlays to enable improved reading of static visualizations.",,,,,vimeo 230841267,,2018,2017,InfoVis,301-D,Thursday,Text and Machine Learning,,8:30:00 AM,8:50:00 AM
openaccessvis.csv,InfoVis,TVCG,Functional Decomposition for Bundled Simpli?cation of Trail Sets,,"Christophe Hurter, Stephane Puechmorel, Florence Nicol, Alex Telea",http://www.cs.rug.nl/~alext/PAPERS/InfoVis17/paper1.pdf,"Bundling visually aggregates curves to reduce clutter and help finding important patterns in trail-sets or graph drawings. We propose a new approach to bundling based on functional decomposition of the underling dataset. We recover the functional nature of the curves by representing them as linear combinations of piecewise-polynomial basis functions with associated expansion coefficients. Next, we express all curves in a given cluster in terms of a centroid curve and a complementary term, via a set of so-called principal component functions. Based on the above, we propose a two-fold contribution: First, we use cluster centroids to design a new bundling method for 2D and 3D curve-sets. Secondly, we deform the cluster centroids and generate new curves along them, which enables us to modify the underlying data in a statistically-controlled way via its simplified (bundled) view. We demonstrate our method by applications on real-world 2D and 3D datasets for graph bundling, trajectory analysis, and vector field and tensor field visualization",,,,,vimeo 230841191,,2018,2017,InfoVis,301-D,Thursday,Graphs and Paths,,4:55:00 PM,5:15:00 PM
openaccessvis.csv,InfoVis,TVCG,HiPiler: Visual Exploration of Large Genome Interaction Matrices with Interactive Small Multiples,,"Fritz Lekschas, Benjamin Bach, Peter Kerpedjiev, Nils Gehlenborg, Hanspeter Pfister",http://www.biorxiv.org/content/early/2017/07/09/123588.full.pdf,"This paper presents an interactive visualization interface - HiPiler - for the exploration and visualization of regions-of-interest in large genome interaction matrices. Genome interaction matrices approximate the physical distance of pairs of genomic regions to each other and can contain up to 3 million rows and columns with many sparse regions. Traditional matrix aggregation or pan-and-zoom interfaces largely fail in supporting search, inspection, and comparison of local regions-of-interest (ROIs). ROIs can be defined, e.g., by sets of adjacent rows and columns, or by specific visual patterns in the matrix. ROIs are first-class objects in HiPiler, which represents them as thumbnail-like ?snippets?. Snippets can be laid out automatically based on their data and meta attributes. They are linked back to the matrix and can be explored interactively. The design of HiPiler is based on a series of semi-structured interviews with 10 domain experts involved in the analysis and interpretation of genome interaction matrices. We describe six exploration tasks that are crucial for analysis of interaction matrices and demonstrate how HiPiler supports these tasks. We report on a user study with a series of data exploration sessions with domain experts to assess the usability of HiPiler as well as to demonstrate respective findings in the data.",http://hipiler.higlass.io/,https://github.com/flekschas/hipiler,,,youtube qoLqje5OYKg,,2018,2017,InfoVis,301-D,Thursday,Graphs and Paths,,5:35:00 PM,5:55:00 PM
openaccessvis.csv,InfoVis,TVCG,Imagining Replications: Graphical Prediction & Discrete Visualizations Improve Recall & Estimation of Effect Uncertainty,,"Jessica Hullman, Matthew Kay, Yea-Seul Kim, Samana Shrestha",http://faculty.washington.edu/jhullman/imagining_replications_cr.pdf,"People often have erroneous intuitions about the results of uncertain processes, such as scientific experiments. Many uncertainty visualizations assume considerable statistical knowledge, but have been shown to prompt erroneous conclusions even when users possess this knowledge. Active learning approaches been shown to improve statistical reasoning, but are rarely applied in visualizing uncertainty in scientific reports. We present a controlled study to evaluate the impact of an interactive, graphical uncertainty prediction technique for communicating uncertainty in experiment results. Using our technique, users sketch their prediction of the uncertainty in experimental effects prior to viewing the true sampling distribution from an experiment. We find that having a user graphically predict the possible effects from experiment replications is an effective way to improve one?s ability to make predictions about replications of new experiments. Additionally, visualizing uncertainty as a set of discrete outcomes, as opposed to a continuous probability distribution, can improve recall of a sampling distribution from a single experiment. Our work has implications for various applications where it is important to elicit peoples? estimates of probability distributions and to communicate uncertainty effectively",,,,,,,2018,2017,InfoVis,301-D,Friday,Evaluation,,8:30:00 AM,8:50:00 AM
openaccessvis.csv,InfoVis,TVCG,iTTVis: Interactive Visualization of Table Tennis Data,,"Yingcai Wu, Ji Lan, Xinhuan Shu, Chenyang Ji, Kejian Zhao, Jiachen Wang, Hui Zhang",,"The rapid development of information technology paved the way for the recording of fine-grained data, such as stroke techniques and stroke placements, during a table tennis match. This data recording creates opportunities to analyze and evaluate matches from new perspectives. Nevertheless, the increasingly complex data poses a significant challenge to make sense of and gain insights into. Analysts usually employ tedious and cumbersome methods which are limited to watching videos and reading statistical tables. However, existing sports visualization methods cannot be applied to visualizing table tennis competitions due to different competition rules and particular data attributes. In this work, we collaborate with data analysts to understand and characterize the sophisticated domain problem of analysis of table tennis data. We propose iTTVis, a novel interactive table tennis visualization system, which to our knowledge, is the first visual analysis system for analyzing and exploring table tennis data. iTTVis provides a holistic visualization of an entire match from three main perspectives, namely, time-oriented, statistical, and tactical analyses. The proposed system with several well-coordinated views not only supports correlation identification through statistics and pattern detection of tactics with a score timeline but also allows cross analysis to gain insights. Data analysts have obtained several new insights by using iTTVis. The effectiveness and usability of the proposed system are demonstrated with four case studies.",,,,,video http://www.cad.zju.edu.cn/home/ycwu/Files/iTTVis.mp4,,2018,2017,InfoVis,301-D,Thursday,Trees and Table Tennis,,10:30:00 AM,10:50:00 AM
openaccessvis.csv,InfoVis,TVCG,"Keeping Multiple Views Consistent: Constraints, Validations and Exceptions in Visualization Authoring",,"Zening Qu, Jessica Hullman",http://faculty.washington.edu/jhullman/VIS17_Consistency_CR.pdf,"Visualizations often appear in multiples, either in a single display (e.g., small multiples, dashboard) or across time or space (e.g., slideshow, set of dashboards). However, existing visualization design guidelines typically focus on single rather than multiple views. Solely following these guidelines can lead to effective yet inconsistent views (e.g., the same field has different axes domains across charts), making interpretation slow and error-prone. Moreover, little is known how consistency balances with other design considerations, making it difficult to incorporate consistency mechanisms in visualization authoring software. We present a wizard-of-oz study in which we observed how Tableau users achieve and sacrifice consistency in an exploration-to-presentation visualization design scenario. We extend (from our prior work) a set of encoding-specific constraints defining consistency across multiple views. Using the constraints as a checklist in our study, we observed cases where participants spontaneously maintained consistent encodings and warned cases where consistency was overlooked. In response to the warnings, participants either revised views for consistency or stated why they thought consistency should be overwritten. We categorize participants? actions and responses as constraint validations and exceptions, depicting the relative importance of consistency and other design considerations under various circumstances (e.g., data cardinality, available encoding resources, chart layout). We discuss automatic consistency checking as a constraint-satisfaction problem and provide design implications for communicating inconsistencies to users.",,,,,vimeo 230841093,,2018,2017,InfoVis,301-D,Friday,Evaluation,,9:50:00 AM,10:10:00 AM
openaccessvis.csv,InfoVis,TVCG,LSTMVis: A Tool for Visual Analysis of Hidden State Dynamics in Recurrent Neural Networks,,"Hendrik Strobelt, Sebastian Gehrmann, Hanspeter Pfister, Alexander Rush",https://arxiv.org/pdf/1606.07461.pdf,"Recurrent neural networks, and in particular long short-term memory networks (LSTMs), are a remarkably effective tool for sequence modeling that learn a dense black-box hidden representation of their sequential input. Researchers interested in better understanding these models have studied the changes in hidden state representations over time and noticed some interpretable patterns but also significant noise. In this work, we present LSTMVis a visual analysis tool for recurrent neural networks with a focus on understanding these hidden state dynamics. The tool allows a user to select a hypothesis input range to focus on local state changes, to match these states changes to similar patterns in a large data set, and to align these results with domain specific structural annotations. We further show several use cases of the tool for analyzing specific hidden state properties on datasets containing nesting, phrase structure, and chord progressions, and demonstrate how the tool can be used to isolate patterns for further statistical analysis.",http://lstm.seas.harvard.edu/,https://github.com/HendrikStrobelt/LSTMVis,,,vimeo 172145096,,2018,2017,InfoVis,301-D,Thursday,Text and Machine Learning,,9:50:00 AM,10:10:00 AM
openaccessvis.csv,InfoVis,TVCG,Modeling Color Difference for Visualization Design,,Danielle Albers Szafir,http://danielleszafir.com/colordiff_vis2017.pdf,"Color is frequently used to encode values in visualizations. For color encodings to be effective, the mapping between colors and values must preserve important differences in the data. However, most guidelines for effective color choice in visualization are based on either color perceptions measured using large, uniform fields in optimal viewing environments or on qualitative intuitions. These limitations may cause data misinterpretation in visualizations, which frequently use small, elongated marks. Our goal is to develop quantitative metrics to help people use color more effectively in visualizations. We present a series of crowdsourced studies measuring color difference perceptions for three common mark types: points, bars, and lines. Our results indicate that peoples? abilities to perceive color differences varies significantly across mark types. Probabilistic models constructed from the resulting data can provide objective guidance for designers, allowing them to anticipate viewer perceptions in order to inform effective encoding design.",,,,,video http://cmci.colorado.edu/visualab/papers/infovis_paper-333.m4v,,2018,2017,Other,301-CD,Tuesday,VIS Awards & Best Papers,,9:25:00 AM,9:45:00 AM
openaccessvis.csv,InfoVis,TVCG,MyBrush: Brushing and Linking with Personal Agency,,"Philipp Koytek, Charles Perin, Jo Vermeulen, Elisabeth Andr‚, Sheelagh Carpendale",http://innovis.cpsc.ucalgary.ca/supplemental/MyBrush/2018_VIS_mybrush.pdf,"We extend the popular brushing and linking technique by incorporating personal agency in the interaction. We map existing research related to brushing and linking into a design space that deconstructs the interaction technique into three components: source (what is being brushed), link (the expression of relationship between source and target), and target (what is revealed as related to the source). Using this design space, we created MyBrush, a unified interface that offers personal agency over brushing and linking by giving people the flexibility to configure the source, link, and target of multiple brushes. The results of three focus groups demonstrate that people with different backgrounds leveraged personal agency in different ways, including performing complex tasks and showing links explicitly. We reflect on these results, paving the way for future research on the role of personal agency in information visualization.",http://innovis.cpsc.ucalgary.ca/supplemental/MyBrush/demo/,https://github.com/philippkoytek/mybrush,,,youtube 1iAtPhWEV9I,,2018,2017,InfoVis,301-D,Tuesday,Techniques,,2:20:00 PM,2:40:00 PM
openaccessvis.csv,InfoVis,TVCG,Nonlinear Dot Plots,,"Nils Rodrigues, Daniel Weiskopf",,,,,,,,,2018,2017,InfoVis,301-D,Tuesday,Techniques,,2:40:00 PM,3:00:00 PM
openaccessvis.csv,InfoVis,TVCG,Open vs Closed Shapes: New Perceptual Categories?,,"David Burlinson, Kalpathi Subramanian, Paula Goolkasian",,,,,,,,,2018,2017,InfoVis,301-D,Wednesday,Perception,,8:50:00 AM,9:10:00 AM
openaccessvis.csv,InfoVis,TVCG,Orko: Facilitating Multimodal Interaction for Visual Exploration and Analysis of Networks,,"Arjun Srinivasan, John Stasko",http://arjun010.github.io/static/papers/orko-infovis-17.pdf,"Data visualization systems have predominantly been developed for WIMP-based direct manipulation interfaces. Only recently have other forms of interaction begun to appear, such as natural language or touch-based interaction, though usually operating only independently. Prior evaluations of natural language interfaces for visualization have indicated potential value in combining direct manipulation and natural language as complementary interaction techniques. We hypothesize that truly multimodal interfaces for visualization, those providing users with freedom of expression via both natural language and touch-based direct manipulation input, may provide an effective and engaging user experience. Unfortunately, however, little work has been done in exploring such multimodal visualization interfaces. To address this gap, we have created an architecture and a prototype visualization system called Orko that facilitates both natural language and direct manipulation input. Specifically, Orko focuses on the domain of network visualization, one that has largely relied on WIMP-based interfaces and direct manipulation interaction, and has little or no prior research exploring natural language interaction. We report results from an initial evaluation study of Orko, and use our observations to discuss opportunities and challenges for future work in multimodal network visualization interfaces.",,,,,vimeo 230840776,,2018,2017,InfoVis,301-D,Thursday,Graphs and Paths,,5:15:00 PM,5:35:00 PM
openaccessvis.csv,InfoVis,TVCG,Priming and Anchoring Effects in Visualizations,,"Andr‚ Calero Valdez, Martina Ziefle, Michael Sedlmair",http://homepage.univie.ac.at/michael.sedlmair/papers/calero-valdez2017priming.pdf,"We investigate priming and anchoring effects on perceptual tasks in visualization. Priming or anchoring effects depict the phenomena that a stimulus might influence subsequent human judgments on a perceptual level, or on a cognitive level by providing a frame of reference. Using visual class separability in scatterplots as an example task, we performed a set of five studies to investigate the potential existence of priming and anchoring effects. Our findings show that?under certain circumstances?such effects indeed exist. In other words, humans judge class separability of the same scatterplot differently depending on the scatterplot(s) they have seen before. These findings inform future work on better understanding and more accurately modeling human perception of visual patterns.",,,,,youtube ynD_mbygJdU,,2018,2017,InfoVis,301-D,Wednesday,Perception,,9:30:00 AM,9:50:00 AM
openaccessvis.csv,InfoVis,TVCG,Revisiting Stress Majorization as a Unified Framework for Interactive Constrained Graph Visualization,,"Yunhai Wang, Yanyan Wang, Yingqi Sun, Lifeng Zhu, Chi-Wing Fu, Michael Sedlmair, Oliver Deussen, Baoquan Chen, Kecheng Lu",http://graphics.uni-konstanz.de/publikationen/Wang2018RevisitingStressMajorization/constrained-graph.pdf,"We present an improved stress majorization method that incorporates various constraints, including directional constraints without the necessity of solving a constraint optimization problem. This is achieved by reformulating the stress function to impose constraints on both the edge vectors and lengths instead of just on the edge lengths (node distances). This is a unified framework for both constrained and unconstrained graph visualizations, where we can model most existing layout constraints, as well as develop new ones such as the star shapes and cluster separation constraints within stress majorization. This improvement also allows us to parallelize computation with an efficient GPU conjugant gradient solver, which yields fast and stable solutions, even for large graphs. As a result, we allow the constraint-based exploration of large graphs with 10K nodes ? an approach which previous methods cannot support.",,,,,vimeo 230840913,,2018,2017,InfoVis,301-D,Thursday,Graphs and Paths,,4:35:00 PM,4:55:00 PM
openaccessvis.csv,InfoVis,TVCG,"Scatterplots: Tasks, Data, and Designs",,"Alper Sarikaya, Michael Gleicher",http://graphics.cs.wisc.edu/Papers/2018/SG18/scatterplots-preprint.pdf,"Traditional scatterplots fail to scale as the complexity and amount of data increases. In response, there exist many design options that modify or expand the traditional scatterplot design to meet these larger scales. This breadth of design options creates challenges for designers and practitioners who must select appropriate designs for particular analysis goals. In this paper, we help designers in making design choices for scatterplot visualizations. We survey the literature to catalog scatterplot-specific analysis tasks. We look at how data characteristics influence design decisions. We then survey scatterplot-like designs to understand the range of design options. Building upon these three organizations, we connect data characteristics, analysis tasks, and design choices in order to generate challenges, open questions, and example best practices for the effective design of scatterplots",,,,,video https://graphics.cs.wisc.edu/Papers/2018/SG18/scatterplot-paper-ff.mp4,,2018,2017,InfoVis,301-D,Wednesday,Design,,10:30:00 AM,10:50:00 AM
openaccessvis.csv,InfoVis,TVCG,Skeleton-based Scagnostics,,"Jos‚ Matute, Alex Telea, Lars Linsen",http://www.cs.rug.nl/~alext/PAPERS/InfoVis17/paper2.pdf,"Scatterplot matrices (SPLOMs) are widely used for exploring multidimensional data. Scatterplot diagnostics (scagnostics) approaches measure characteristics of scatterplots to automatically find potentially interesting plots, thereby making SPLOMs more scalable with the dimension count. While statistical measures such as regression lines can capture orientation, and graph-theoretic scagnostics measures can capture shape, there is no scatterplot characterization measure that uses both descriptors. Based on well-known results in shape analysis, we propose a scagnostics approach that captures both scatterplot shape and orientation using skeletons (or medial axes). Our representation can handle complex spatial distributions, helps discovery of principal trends in a multiscale way, scales visually well with the number of samples, is robust to noise, and is automatic and fast to compute. We define skeleton-based similarity metrics for the visual exploration and analysis of SPLOMs. We perform a user study to measure the human perception of scatterplot similarity and compare the outcome to our results as well as to graph-based scagnostics and other visual quality metrics. Our skeleton-based metrics outperform previously defined measures both in terms of closeness to perceptually-based similarity and computation time efficiency.",,,,,vimeo 230841215,,2018,2017,InfoVis,301-D,Wednesday,Multidimensional Data,,2:20:00 PM,2:40:00 PM
openaccessvis.csv,InfoVis,TVCG,Stable Treemaps via Local Moves,,"Max Sondag, Bettina Speckmann, Kevin Verbeek",,,,,,,,,2018,2017,InfoVis,301-D,Thursday,Trees and Table Tennis,,11:10:00 AM,11:30:00 AM
openaccessvis.csv,InfoVis,TVCG,Structuring Visualization Mock-Ups at the Graphical Level by Dividing the Display Space,,"Romain Vuillemot, Jeremy Boy",http://romain.vuillemot.net/publis/infovis17-visualization-mockups.pdf,"Mock-ups are rapid, low fidelity prototypes, that are used in many design-related fields to generate and share ideas. While their creation is supported by many mature methods and tools, surprisingly little are suited for the needs of information visualization. In this article, we introduce a novel approach to creating visualizations mock-ups, based on a dialogue between graphic design and parametric toolkit explorations. Our approach consists in iteratively subdividing the display space, while progressively informing each division with realistic data. We show that a wealth of mock-ups can easily be created using only temporary data attributes, as we wait for more realistic data to become available. We describe the implementation of this approach in a D3-based toolkit, which we use to highlight its generative power, and we discuss the potential for transitioning towards higher fidelity prototypes",,https://github.com/romsson/d3-gridding,,,vimeo 230840552,,2018,2017,InfoVis,301-D,Wednesday,Design,,11:10:00 AM,11:30:00 AM
openaccessvis.csv,InfoVis,TVCG,TACO: Visualizing Changes in Tables Over Time,,"Christina Niederer, Holger Stitz, Reem Hourieh, Florian Grassinger, Wolfgang Aigner, Marc Streit",http://data.caleydo.org/papers/2017_infovis_taco.pdf,"Multivariate, tabular data is one of the most common data structures used in many different domains. Over time, tables can undergo changes in both structure and content, which results in multiple versions of the same table. A challenging task when working with such derived tables is to understand what exactly has changed between versions in terms of additions/deletions, reorder, merge/split, and content changes. For textual data, a variety of commonplace ""diff"" tools exist that support the task of investigating changes between revisions of a text. Although there are some comparison tools which assist users in inspecting differences between multiple table instances, the resulting visualizations are often difficult to interpret or do not scale to large tables with thousands of rows and columns. To address these challenges, we developed TACO, an interactive comparison tool that visualizes effectively the differences between multiple tables at various levels of detail. With TACO we show (1) the aggregated differences between multiple table versions over time, (2) the aggregated changes between two selected table versions, and (3) detailed changes between the selection. To demonstrate the effectiveness of our approach, we show its application by means of two usage scenarios.",,https://github.com/Caleydo/taco/,,,vimeo 230840851,,2018,2017,InfoVis,301-D,Tuesday,Time and Space,,4:15:00 PM,4:35:00 PM
openaccessvis.csv,InfoVis,TVCG,Taking Word Clouds Apart: An Empirical Investigation of the Design Space for Keyword Summaries,,"Cristian Felix, Steven Franconeri, Enrico Bertini",http://enrico.bertini.io/s/infovis17-word-clouds-apart.pdf,"In this paper we present a set of four user studies aimed at exploring the visual design space of what we call keyword summaries: lists of words with associated quantitative values used to help people derive an intuition of what information a given document collection (or part of it) may contain. We seek to systematically study how different visual representations may affect people?s performance in extracting information out of keyword summaries. To this purpose, we first create a design space of possible visual representations and compare the possible solutions in this design space through a variety of representative tasks and performance metrics. Other researchers have, in the past, studied some aspects of effectiveness with word clouds, however, the existing literature is somewhat scattered and do not seem to address the problem in a sufficiently systematic and holistic manner. The results of our studies showed a strong dependency on the tasks users are performing. In this paper we present details of our methodology, the results, as well as, guidelines on how to design effective keyword summaries based in our discoveries.",,,,,vimeo 230840786,,2018,2017,InfoVis,301-D,Thursday,Text and Machine Learning,,9:30:00 AM,9:50:00 AM
openaccessvis.csv,InfoVis,TVCG,The explanatory visualization framework: An active learning framework for teaching creative computing using explanatory visualizations,,"Jonathan Roberts, Panagiotis Ritsos, James Jackson, Christopher Headleand",http://pdritsos.com/files/Roberts-et-al-TVCG-2018.pdf,"Visualizations are nowadays appearing in popular media and are used everyday in the workplace. This democratisation of visualization challenges educators to develop effective learning strategies, in order to train the next generation of creative visualization specialists. There is high demand for skilled individuals who can analyse a problem, consider alternative designs, develop new visualizations, and be creative and innovative. Our three-stage framework, leads the learner through a series of tasks, each designed to develop different skills necessary for coming up with creative, innovative, effective, and purposeful visualizations. For that, we get the learners to create an explanatory visualization of an algorithm of their choice. By making an algorithm choice, and by following an active-learning and project-based strategy, the learners take ownership of a particular visualization challenge. They become enthusiastic to develop good results and learn different creative skills on their learning journey.",,,,,vimeo 230840888,,2018,2017,InfoVis,301-D,Thursday,Understanding Visualization,,3:20:00 PM,3:40:00 PM
openaccessvis.csv,InfoVis,TVCG,The Hologram in My Hand: How Effective is Interactive Exploration of 3D Visualizations in Immersive Tangible Augmented Reality?,,"Benjamin Bach, Ronell Sicat, Maxime Cordeil, Johanna Beyer, Hanspeter Pfister",http://www.aviz.fr/~bbach/hololens/Bach2018holostudy.pdf,"We report on a controlled user study comparing three visualization environments for common 3D exploration. Our environments differ in how they exploit natural human perception and interaction capabilities. We compare an augmented-reality head-mounted display (Microsoft HoloLens), a handheld tablet, and a desktop setup. The novel head-mounted HoloLens display projects stereoscopic images of virtual content into a user?s real world and allows for interaction in-situ at the spatial position of the 3D hologram. The tablet is able to interact with 3D content through touch, spatial positioning, and tangible markers, however, 3D content is still presented on a 2D surface. Our hypothesis is that visualization environments that match human perceptual and interaction capabilities better to the task at hand improve understanding of 3D visualizations. To better understand the space of display and interaction modalities in visualization environments, we first propose a classification based on three dimensions: perception, interaction, and the spatial and cognitive proximity of the two. Each technique in our study is located at a different position along these three dimensions. We asked 15 participants to perform four tasks, each task having different levels of difficulty for both spatial perception and degrees of freedom for interaction. Our results show that each of the tested environments is more effective for certain tasks, but that generally the desktop environment is still fastest and most precise in almost all cases.",,,,,vimeo 230840940,,2018,2017,InfoVis,301-D,Friday,Evaluation,,9:10:00 AM,9:30:00 AM
openaccessvis.csv,InfoVis,TVCG,VisTiles: Coordinating and Combining Co-located Mobile Devices for Visual Data Exploration,,"Ricardo Langner, Tom Horak, Raimund Dachselt",https://imld.de/cnt/uploads/Langner_VisTiles_InfoVis17.pdf,"We present VISTILES, a conceptual framework that uses a set of mobile devices to distribute and coordinate visualization views for the exploration of multivariate data. In contrast to desktop-based interfaces for information visualization, mobile devices offer the potential to provide a dynamic and user-defined interface supporting co-located collaborative data exploration with different individual workflows. As part of our framework, we contribute concepts that enable users to interact with coordinated & multiple views (CMV) that are distributed across several mobile devices. The major components of the framework are: (i) dynamic and flexible layouts for CMV focusing on the distribution of views and (ii) an interaction concept for smart adaptations and combinations of visualizations utilizing explicit side-by-side arrangements of devices. As a result, users can benefit from the possibility to combine devices and organize them in meaningful spatial layouts. Furthermore, we present a web-based prototype implementation as a specific instance of our concepts. This implementation provides a practical application case enabling users to explore a multivariate data collection. We also illustrate the design process including feedback from a preliminary user study, which informed the design of both the concepts and the final prototype",,,,,youtube Xj-AEmUwsvQ,,2018,2017,InfoVis,301-D,Tuesday,Techniques,,3:00:00 PM,3:20:00 PM
openaccessvis.csv,InfoVis,TVCG,Visual Exploration of Semantic Relationships in Neural Word Embeddings,,"Shusen Liu, Peer-Timo Bremer, Jayaraman J. Thiagarajan, Vivek Srikumar, Bei Wang, Yarden Livnat, Valerio Pascucci",http://www.sci.utah.edu/~shusenl/publications/paper157.pdf,"Constructing distributed representations for words through neural language models and using the resulting vector spaces for analysis has become a crucial component of natural language processing (NLP). However, despite their widespread application, little is known about the structure and properties of these spaces. To gain insights into the relationship between words, the NLP community has begun to adapt high-dimensional visualization techniques. In particular, researchers commonly use t-distributed stochastic neighbor embeddings (t-SNE) and principal component analysis (PCA) to create two-dimensional embeddings for assessing the overall structure and exploring linear relationships (e.g., word analogies), respectively. Unfortunately, these techniques often produce mediocre or even misleading results and cannot address domain-specific visualization challenges that are crucial for understanding semantic relationships in word embeddings. Here, we introduce new embedding techniques for visualizing semantic and syntactic analogies, and the corresponding tests to determine whether the resulting views capture salient structures. Additionally, we introduce two novel views for a comprehensive study of analogy relationships. Finally, we augment t-SNE embeddings to convey uncertainty information in order to allow a reliable interpretation. Combined, the different views address a number of domain-specific tasks difficult to solve with existing tools.",,,,,vimeo 230840739,,2018,2017,InfoVis,301-D,Wednesday,Multidimensional Data,,3:00:00 PM,3:20:00 PM
openaccessvis.csv,InfoVis,TVCG,Visualizing Nonlinear Narratives with Story Curves,,"Nam Wook Kim, Benjamin Bach, Hyejin Im, Sasha Schriber, Markus Gross, Hanspeter Pfister",https://vcg.seas.harvard.edu/content/3-publications/20180101-visualizing-nonlinear-narratives-with-story-curves/paper.pdf,"In this paper, we present story curves, a visualization technique for exploring and communicating nonlinear narratives in movies. A nonlinear narrative is a storytelling device that portrays events of a story out of chronological order, e.g., in reverse order or going back and forth between past and future events. Many acclaimed movies employ unique narrative patterns which in turn have inspired other movies and contributed to the broader analysis of narrative patterns in movies. However, understanding and communicating nonlinear narratives is a difficult task due to complex temporal disruptions in the order of events as well as no explicit records specifying the actual temporal order of the underlying story. Story curves visualize the nonlinear narrative of a movie by showing the order in which events are told in the movie and comparing them to their actual chronological order, resulting in possibly meandering visual patterns in the curve. We also present Story Explorer, an interactive tool that visualizes a story curve together with complementary information such as characters and settings. Story Explorer further provides a script curation interface that allows users to specify the chronological order of events in movies. We used Story Explorer to analyze 10 popular nonlinear movies and describe the spectrum of narrative patterns that we discovered, including some novel patterns not previously described in the literature. Feedback from experts highlights potential use cases in screenplay writing and analysis, education and film production. A controlled user study shows that users with no expertise are able to understand visual patterns of nonlinear narratives using story curves.",,,,,youtube XQ6xPkAZsPU,,2018,2017,InfoVis,301-D,Tuesday,Techniques,,2:00:00 PM,2:20:00 PM
openaccessvis.csv,InfoVis,TVCG,What Would a Graph Look Like in This Layout? A Machine Learning Approach to Large Graph Visualization,,"Oh-Hyun Kwon, Tarik Crnovrsanin, Kwan-Liu Ma",http://vis.cs.ucdavis.edu/papers/kwon_infovis17.pdf,"Using different methods for laying out a graph can lead to very different visual appearances, with which the viewer perceives different information. Selecting a ?good? layout method is thus important for visualizing a graph. The selection can be highly subjective and dependent on the given task. A common approach to selecting a good layout is to use aesthetic criteria and visual inspection. However, fully calculating various layouts and their associated aesthetic metrics is computationally expensive. In this paper, we present a machine learning approach to large graph visualization based on computing the topological similarity of graphs using graph kernels. For a given graph, our approach can show what the graph would look like in different layouts and estimate their corresponding aesthetic metrics. An important contribution of our work is the development of a new framework to design graph kernels. Our experimental study shows that our estimation calculation is considerably faster than computing the actual layouts and their aesthetic metrics. Also, our graph kernels outperform the state-of-the-art ones in both time and accuracy. In addition, we conducted a user study to demonstrate that the topological similarity computed with our graph kernel matches perceptual similarity assessed by human users.",http://graphvis.net/wgl,,,,vimeo 230840405,,2018,2017,InfoVis,301-D,Thursday,Graphs and Paths,,4:15:00 PM,4:35:00 PM
openaccessvis.csv,VAST,TVCG,A Utility-aware Visual Approach for Anonymizing Multi-attribute Tabular Data,,"Xumeng Wang, Jia-Kai Chou, Wei Chen, Huihua Guan, Wenlong Chen, Tianyi Lao, Kwan-Liu Ma",,"Sharing data for public usage requires sanitization to prevent sensitive information from leaking. Previous studies have presented methods for creating privacy preserving visualizations. However, few of them provide sufficient feedback to users on how much utility is reduced (or preserved) during such a process. To address this, we design a visual interface along with a data manipulation pipeline that allows users to gauge utility loss while interactively and iteratively handling privacy issues in their data. Widely known and discussed types of privacy models, i.e., syntactic anonymity and differential privacy, are integrated and compared under different use case scenarios. Case study results on a variety of examples demonstrate the effectiveness of our approach.",,,,,vimeo 230830747,,2018,2017,VAST,301-C,Thursday,Visual Representation and Design Study,,9:30:00 AM,9:50:00 AM
openaccessvis.csv,VAST,TVCG,ActiVis: Visual Exploration of Industry-Scale Deep Neural Network Models,,"Minsuk Kahng, Pierre Andrews, Aditya Kalro, Duen Horng Chau",https://arxiv.org/pdf/1704.01942.pdf,"While deep learning models have achieved state-of-the-art accuracies for many prediction tasks, understanding these models remains a challenge. Despite the recent interest in developing visual tools to help users interpret deep learning models, the complexity and wide variety of models deployed in industry, and the large-scale datasets that they used, pose unique design challenges that are inadequately addressed by existing work. Through participatory design sessions with over 15 researchers and engineers at Facebook, we have developed, deployed, and iteratively improved ACTIVIS, an interactive visualization system for interpreting large-scale deep learning models and results. By tightly integrating multiple coordinated views, such as a computation graph overview of the model architecture, and a neuron activation view for pattern discovery and comparison, users can explore complex deep neural network models at both the instance- and subset-level. ACTIVIS has been deployed on Facebook?s machine learning platform. We present case studies with Facebook researchers and engineers, and usage scenarios of how ACTIVIS may work with different models.",,,,,vimeo 230829900,,2018,2017,VAST,301-C,Wednesday,ML1: Deep Learning,,11:10:00 AM,11:30:00 AM
openaccessvis.csv,VAST,TVCG,Analyzing the Training Processes of Deep Generative Models,,"Mengchen Liu, Jiaxin Shi, Kelei Cao, Jun Zhu, Shixia Liu",http://shixialiu.com/publications/dgmtracker/paper.pdf,"Among the many types of deep models, deep generative models (DGMs) provide a solution to the important problem of unsupervised and semi-supervised learning. However, training DGMs requires more skill, experience, and know-how because their training is more complex than other types of deep models such as convolutional neural networks (CNNs). We develop a visual analytics approach for better understanding and diagnosing the training process of a DGM. To help experts understand the overall training process, we first extract a large amount of time series data that represents training dynamics (e.g., activation changes over time). A blue-noise polyline sampling scheme is then introduced to select time series samples, which can both preserve outliers and reduce visual clutter. To further investigate the root cause of a failed training process, we propose a credit assignment algorithm that indicates how other neurons contribute to the output of the neuron causing the training failure. Two case studies are conducted with machine learning experts to demonstrate how our approach helps understand and diagnose the training processes of DGMs. We also show how our approach can be directly used to analyze other types of deep models, such as CNNs.",,,,,video http://shixialiu.com/publications/dgmtracker/video.mp4,,2018,2017,VAST,301-C,Wednesday,ML1: Deep Learning,,10:30:00 AM,10:50:00 AM
openaccessvis.csv,VAST,TVCG,Applying Pragmatics Principles for Interaction with Visual Analytics,,"Enamul Hoque, Vidya Setlur, Melanie Tory, Isaac Dykeman",https://research.tableau.com/sites/default/files/VAST2017_105.pdf,"Interactive visual data analysis is most productive when users can focus on answering the questions they have about their data, rather than focusing on how to operate the interface to the analysis tool. One viable approach to engaging users in interactive conversations with their data is a natural language interface to visualizations. These interfaces have the potential to be both more expressive and more accessible than other interaction paradigms. We explore how principles from language pragmatics can be applied to the flow of visual analytical conversations, using natural language as an input modality. We evaluate the effectiveness of pragmatics support in our system Evizeon, and present design considerations for conversation interfaces to visual analytics tools.",,,,,vimeo 230831885,,2018,2017,VAST,301-C,Thursday,Interaction in the Analysis Process,,2:40:00 PM,3:00:00 PM
openaccessvis.csv,VAST,TVCG,Beyond Tasks: An Activity Typology for Visual Analytics,,"Darren Edge, Nathalie Henry Riche, Jonathan Larson, Christopher White",,,,,,,,,2018,2017,VAST,301-C,Thursday,Theory and Analysis Process,,10:30:00 AM,10:50:00 AM
openaccessvis.csv,VAST,TVCG,BiDots: Visual Exploration of Weighted Biclusters,,"Jian Zhao, Maoyuan Sun, Francine Chen, Patrick Chiu",http://www.cs.toronto.edu/~jianzhao/papers/bidots.pdf,"Discovering and analyzing biclusters, i.e., two sets of related entities with close relationships, is a critical task in many real-world applications, such as exploring entity co-occurrences in intelligence analysis, and studying gene expression in bio-informatics. While the output of biclustering techniques can offer some initial low-level insights, visual approaches are required on top of that due to the algorithmic output complexity.This paper proposes a visualization technique, called BiDots, that allows analysts to interactively explore biclusters over multiple domains. BiDots overcomes several limitations of existing bicluster visualizations by encoding biclusters in a more compact and cluster-driven manner. A set of handy interactions is incorporated to support flexible analysis of biclustering results. More importantly, BiDots addresses the cases of weighted biclusters, which has been underexploited in the literature. The design of BiDots is grounded by a set of analytical tasks derived from previous work. We demonstrate its usefulness and effectiveness for exploring computed biclusters with an investigative document analysis task, in which suspicious people and activities are identified from a text corpus.",,,,,youtube 79VSgVIl11M,,2018,2017,VAST,301-C,Tuesday,Graphs and Trees,,4:35:00 PM,4:55:00 PM
openaccessvis.csv,VAST,TVCG,Bring it to the Pitch: Combining Video and Movement Data to Enhance Team Sport Analysis,,"Manuel Stein, Halld¢r Janetzko, Andreas Lamprecht, Thorsten Breitkreutz, Philipp Zimmermann, Bastian Goldlcke, Tobias Schreck, Gennady Andrienko, Michael Grossniklaus, Daniel Keim",,,,,,,vimeo 230830922,,2018,2017,VAST,301-C,Tuesday,"Space, Time, Movement",,2:00:00 PM,2:20:00 PM
openaccessvis.csv,VAST,TVCG,Clustering Trajectories by Relevant Parts for Air Traffic Analysis,,"Gennady Andrienko, Natalia Andrienko, Georg Fuchs, Jose Manuel Cordero Garcia",http://openaccess.city.ac.uk/18119/1/main-reducedSize.pdf,"Clustering of trajectories of moving objects by similarity is an important technique in movement analysis. Existing distance functions assess the similarity between trajectories based on properties of the trajectory points or segments. The properties may include the spatial positions, times, and thematic attributes. There may be a need to focus the analysis on certain parts of trajectories, i.e., points and segments that have particular properties. According to the analysis focus, the analyst may need to cluster trajectories by similarity of their relevant parts only. Throughout the analysis process, the focus may change, and different parts of trajectories may become relevant. We propose an analytical workflow in which interactive filtering tools are used to attach relevance flags to elements of trajectories, clustering is done using a distance function that ignores irrelevant elements, and the resulting clusters are summarized for further analysis. We demonstrate how this workflow can be useful for different analysis tasks in three case studies with real data from the domain of air traffic. We propose a suite of generic techniques and visualization guidelines to support movement data analysis by means of relevance-aware trajectory clustering.",,,,,vimeo 227918021,,2018,2017,VAST,301-C,Tuesday,"Space, Time, Movement",,2:40:00 PM,3:00:00 PM
openaccessvis.csv,VAST,TVCG,Clustervision: Visual Supervision of Unsupervised Clustering,,"Bum Chul Kwon, Ben Eysenbach, Janu Verma, Kenney Ng, Christopher deFilippi, Walter Stewart, Adam Perer",http://perer.org/papers/adamPerer-Clustervision-VAST2017.pdf,"Clustering, the process of grouping together similar items into distinct partitions, is a common type of unsupervised machine learning that can be useful for summarizing and aggregating complex multi-dimensional data. However, data can be clustered in many ways, and there exist a large body of algorithms designed to reveal different patterns. While having access to a wide variety of algorithms is helpful, in practice, it is quite difficult for data scientists to choose and parameterize algorithms to get the clustering results relevant for their dataset and analytical tasks. To alleviate this problem, we built <em>Clustervision</em>, a visual analytics tool that helps ensure data scientists find the right clustering among the large amount of techniques and parameters available. Our system clusters data using a variety of clustering techniques and parameters and then ranks clustering results utilizing five quality metrics. In addition, users can guide the system to produce more relevant results by providing task-relevant constraints on the data. Our visual user interface allows users to find high quality clustering results, explore the clusters using several coordinated visualization techniques, and select the cluster result that best suits their task. We demonstrate this novel approach using a case study with a team of researchers in the medical domain and showcase that our system empowers users to choose an effective representation of their complex data.",,,,,vimeo 232177941,,2018,2017,VAST,301-C,Thursday,ML2: Cluster Analysis,,5:15:00 PM,5:35:00 PM
openaccessvis.csv,VAST,TVCG,Comparing Visual-Interactive Labeling with Active Learning: An Experimental Study,,"Jrgen Bernard, Marco Hutter, Matthias Zeppelzauer, Dieter Fellner, Michael Sedlmair",http://homepage.univie.ac.at/michael.sedlmair/papers/bernard2017labeling.pdf,"Labeling data instances is an important task in machine learning and visual analytics. Both fields provide a broad set of labeling strategies, whereby machine learning (and in particular active learning) follows a rather model-centered approach and visual analytics employs rather user-centered approaches (visual-interactive labeling). Both approaches have individual strengths and weaknesses. In this work, we conduct an experiment with three parts to assess and compare the performance of these different labeling strategies. In our study, we (1) identify different visual labeling strategies for user-centered labeling, (2) investigate strengths and weaknesses of labeling strategies for different labeling tasks and task complexities, and (3) shed light on the effect of using different visual encodings to guide the visual-interactive labeling process. We further compare labeling of single versus multiple instances at a time, and quantify the impact on efficiency. We systematically compare the performance of visual interactive labeling with that of active learning. Our main findings are that visual-interactive labeling can outperform active learning, given the condition that dimension reduction separates well the class distributions. Moreover, using dimension reduction in combination with additional visual encodings that expose the internal state of the learning model turns out to improve the performance of visual-interactive labeling.",,,,,video http://homepage.univie.ac.at/michael.sedlmair/papers/bernard2017labeling.mp4,,2018,2017,VAST,301-C,Thursday,Interaction in the Analysis Process,,2:20:00 PM,2:40:00 PM
openaccessvis.csv,VAST,TVCG,ConceptVector: Text Visual Analytics via Interactive Lexicon Building using Word Embedding,,"Deokgun Park, Seungyeon Kim, Jurim Lee, Jaegul Choo, Nicholas Diakopoulos, Niklas Elmqvist",http://www.umiacs.umd.edu/~elm/projects/conceptvector/conceptvector.pdf,"Central to many text analysis methods is the notion of a concept: a set of semantically related keywords characterizing a specific object, phenomenon, or theme. Advances in word embedding allow building such concepts from a small set of seed terms. However, naive application of such techniques may result in false positive errors because of the polysemy of human language. To mitigate this problem, we present a visual analytics system called ConceptVector that guides the user in building such concepts and then using them to analyze documents. Document-analysis case studies with real-world datasets demonstrate the fine-grained analysis provided by ConceptVector. To support the elaborate modeling of concepts using user seed terms, we introduce a bipolar concept model and support for irrelevant words. We validate the interactive lexicon building interface via a user study and expert reviews. The quantitative evaluation shows that the bipolar lexicon generated with our methods is comparable to human-generated ones.",,,,,youtube -_gANFu-ulY,,2018,2017,VAST,207,Wednesday,Text Analytics,,11:10:00 AM,11:30:00 AM
openaccessvis.csv,VAST,TVCG,DeepEyes: Progressive Visual Analytics for Designing Deep Neural Networks,,"Nicola Pezzotti, Thomas H”llt, Jan van Gemert, Boudewijn P. F. Lelieveldt, Elmar Eisemann, Anna Vilanova",https://graphics.tudelft.nl/Publications-new/2018/PHVLEV18/paper216.pdf,"Deep neural networks are now rivaling human accuracy in several pattern recognition problems. Compared to traditional classifiers, where features are handcrafted, neural networks learn increasingly complex features directly from the data. Instead of handcrafting the features, it is now the network architecture that is manually engineered. The network architecture parameters such as the number of layers or the number of filters per layer and their interconnections are essential for good performance. Even though basic design guidelines exist, designing a neural network is an iterative trial-and-error process that takes days or even weeks to perform due to the large datasets used for training. In this paper, we present DeepEyes, a Progressive Visual Analytics system that supports the design of neural networks during training. We present novel visualizations, supporting the identification of layers that learned a stable set of patterns and, therefore, are of interest for a detailed analysis. The system facilitates the identification of problems, such as superfluous filters or layers, and information that is not being captured by the network. We demonstrate the effectiveness of our system through multiple use cases, showing how a trained network can be compressed, reshaped and adapted to different problems.",,,,,vimeo 230830385,,2018,2017,VAST,301-C,Wednesday,ML1: Deep Learning,,11:30:00 AM,11:50:00 AM
openaccessvis.csv,VAST,TVCG,Do Convolutional Neural Networks learn Class Hierarchy?,,"Bilal Alsallakh, Amin Jourabloo, Mao Ye, Xiaoming Liu, Liu Ren",http://cvlab.cse.msu.edu/pdfs/DoConvolutionalNeuralNetworksLearnClassHierarchy.pdf,"Convolutional Neural Networks (CNNs) currently achieve state-of-the-art accuracy in image classification. With a growing number of classes, the accuracy usually drops as the possibilities of confusion increase. Interestingly, the class confusion patterns follow a hierarchical structure over the classes. We present visual-analytics methods to reveal and analyze this hierarchy of similar classes in relation with CNN-internal data. We found that this hierarchy not only dictates the confusion patterns between the classes, it furthermore dictates the learning behavior of CNNs. In particular, the early layers in these networks develop feature detectors that can separate high-level groups of classes quite well, even after a few training epochs. In contrast, the latter layers require substantially more epochs to develop specialized feature detectors that can separate individual classes. We demonstrate how these insights are key to significant improvement in accuracy by designing hierarchy-aware CNNs that accelerate model convergence and alleviate overfitting. We further demonstrate how our methods help in identifying various quality issues in the training data.",,,,,vimeo 230831852,,2018,2017,VAST,102-ABC,Friday,ML3: Classification,,8:30:00 AM,8:50:00 AM
openaccessvis.csv,VAST,TVCG,Dynamic Influence Networks for Rule-based Models,,"Angus Forbes, Andrew Burks, Kristine Lee, Xing Li, Pierre Boutillier, Jean Krivine, Walter Fontana",https://osf.io/ayb3u/,"We introduce the Dynamic Influence Network (DIN), a novel visual analytics technique for representing and analyzing rule-based models of protein-protein interaction networks. Rule-based modeling has proved instrumental in developing biological modelsthat are concise, comprehensible, easily extensible, and that mitigate the combinatorial complexity of multi-state and multi-componentbiological molecules.  Our technique visualizes the dynamics of these rules as they evolve over time.  Using the data produced byKaSim, an open source stochastic simulator of rule-based models written in theKappalanguage, DINs provide a node-link diagramthat represents the influence that each rule has on the other rules. That is, rather than representing individual biological components ortypes, we instead represent the rules about them (as nodes) and the current influence of these rules (as links). Using our interactiveDIN-Vizsoftware tool, researchers are able to query this dynamic network to find meaningful patterns about biological processes, andto identify salient aspects of complex rule-based models. To evaluate the effectiveness of our approach, we investigate a simulation ofa circadian clock model that illustrates the oscillatory behavior of the KaiC protein phosphorylation cycle.",https://creativecodinglab.github.io/DynamicInfluenceNetworks/,https://osf.io/ba62x/,,,vimeo 195336381,,2018,2017,VAST,301-C,Tuesday,Graphs and Trees,,4:15:00 PM,4:35:00 PM
openaccessvis.csv,VAST,TVCG,EVA: Visual Analytics to Identify Fraudulent Events,,"Roger Leite, Theresia Gschwandtner, Silvia Miksch, Simone Kriglstein, Margit Pohl, Erich Gstrein, Johannes Kuntner",,,,,,,,,2018,2017,VAST,207,Thursday,Sensemaking,,4:35:00 PM,4:55:00 PM
openaccessvis.csv,VAST,TVCG,EventThread: Visual Summarization and Stage Analysis of Event Sequence Data,,"Shunan Guo, Ke Xu, Rongwen Zhao, David Gotz, Hongyuan Zha, Nan Cao",http://gotz.web.unc.edu/files/2013/10/PREPRINT-Guo-VIS-2017-EventThread-Preprint.pdf,"Event sequence data such as electronic health records, a person?s academic records, or car service records, are ordered series of events which have occurred over a period of time. Analyzing collections of event sequences can reveal common or semantically important sequential patterns. For example, event sequence analysis might reveal frequently used care plans for treating a disease, typical publishing patterns of professors, and the patterns of service that result in a well-maintained car. It is challenging, however, to visually explore large numbers of event sequences, or sequences with large numbers of event types. Existing methods focus on extracting explicitly matching patterns of events using statistical analysis to create stages of event progression over time. However, these methods fail to capture latent clusters of similar but not identical evolutions of event sequences. In this paper, we introduce a novel visualization system named EventThread which clusters event sequences into threads based on tensor analysis and visualizes the latent stage categories and evolution patterns by interactively grouping the threads by similarity into time-specific clusters. We demonstrate the effectiveness of EventThread through usage scenarios in three different application domains and via interviews with an expert user.",,,,,vimeo 230831051,,2018,2017,VAST,301-C,Wednesday,Sequences and Events,,2:20:00 PM,2:40:00 PM
openaccessvis.csv,VAST,TVCG,Graphiti: Interactive Specification of Attribute-based Edges for Network Modeling and Visualization,,"Arjun Srinivasan, Hyunwoo Park, Alex Endert, Rahul Basole",http://arjun010.github.io/static/papers/graphiti-vast-17.pdf,"Network visualizations, often in the form of node-link diagrams, are an effective means to understand relationships between entities, discover entities with interesting characteristics, and to identify clusters. While several existing tools allow users to visualize pre-defined networks, creating these networks from raw data remains a challenging task, often requiring users to program custom scripts or write complex SQL commands. Some existing tools also allow users to both visualize and model networks. Interaction techniques adopted by these tools often assume users know the exact conditions for defining edges in the resulting networks. This assumption may not always hold true, however. In cases where users do not know much about attributes in the dataset or when there are several attributes to choose from, users may not know which attributes they could use to formulate linking conditions. We propose an alternate interaction technique to model networks that allows users to demonstrate to the system a subset of nodes and links they wish to see in the resulting network. The system, in response, recommends conditions that can be used to model networks based on the specified nodes and links. In this paper, we show how such a demonstration-based interaction technique can be used to model networks by employing it in a prototype tool, Graphiti. Through multiple usage scenarios, we show how Graphiti not only allows users to model networks from a tabular dataset but also facilitates updating a pre-defined network with additional edge types.",,,,,vimeo 230830104,,2018,2017,VAST,301-C,Tuesday,Graphs and Trees,,5:35:00 PM,5:55:00 PM
openaccessvis.csv,VAST,TVCG,How Do Ancestral Traits Shape Family Trees over Generations?,,"Siwei Fu, Hao Dong, Weiwei Cui, Jian Zhao, Huamin Qu",,"Whether and how does the structure of family trees differ by ancestral traits over generations? This is a fundamental question regarding the structural heterogeneity of family trees for the multi-generational transmission research. However, previous work mostly focuses on parent-child scenarios due to the lack of proper tools to handle the complexity of extending the research to multi-generational processes. Through an iterative design study with social scientists and historians, we develop TreeEvo that assists users to generate and test empirical hypotheses for multi-generational research. TreeEvo summarizes and organizes family trees by structural features in a dynamic manner based on a traditional Sankey diagram. A pixel-based technique is further proposed to compactly encode trees with complex structures in each Sankey Node. Detailed information of trees is accessible through a space-efficient visualization with semantic zooming. Moreover, TreeEvo embeds Multinomial Logit Model (MLM) to examine statistical associations between tree structure and ancestral traits. We demonstrate the effectiveness and usefulness of TreeEvo through an in-depth case-study with domain experts using a real-world dataset (containing 54,128 family trees of 126,196 individuals).",,,,,youtube 7MqeoD49wVg,,2018,2017,VAST,301-C,Tuesday,Graphs and Trees,,4:55:00 PM,5:15:00 PM
openaccessvis.csv,VAST,TVCG,LDSScanner: Exploratory Analysis of Low-Dimensional Structures in High-Dimensional Datasets,,"Jiazhi Xia, Fenjin Ye, Wei Chen, Yusi Wang, Weifeng Chen, Yuxin Ma, Anthony K. H. Tung",,"Many approaches for analyzing a high-dimensional dataset assume that the dataset contains specific structures, e.g., clusters in linear subspaces or non-linear manifolds. This yields a trial-and-error process to verify the appropriate model and parameters. This paper contributes an exploratory interface that supports visual identification of low-dimensional structures in a high-dimensional dataset, and facilitates the optimized selection of data models and configurations. Our key idea is to abstract a set of global and local feature descriptors from the neighborhood graph-based representation of the latent low-dimensional structure, such as pairwise geodesic distance (GD) among points and pairwise local tangent space divergence (LTSD) among pointwise local tangent spaces (LTS). We propose a new LTSD-GD view, which is constructed by mapping LTSD and GD to the x axis and y axis using 1D multidimensional scaling, respectively. Unlike traditional dimensionality reduction methods that preserve various kinds of distances among points, the LTSD-GD view presents the distribution of pointwise LTS (x axis) and the variation of LTS in structures (the combination of x axis and y axis). We design and implement a suite of visual tools for navigating and reasoning about intrinsic structures of a high-dimensional dataset. Three case studies verify the effectiveness of our approach.",,,,,vimeo 230830366,,2018,2017,VAST,301-C,Wednesday,High-dimensional Data,,8:30:00 AM,8:50:00 AM
openaccessvis.csv,VAST,TVCG,PhenoLines: Phenotype Comparison Visualizations for Disease Subtyping via Topic Models,,"Michael Glueck, Mahdi Pakdaman Naeini, Finale Doshi-Velez, Fanny Chevalier, Azam Khan, Daniel Wigdor, Michael Brudno",,,,,,,,,2018,2017,VAST,207,Wednesday,Text Analytics,,11:30:00 AM,11:50:00 AM
openaccessvis.csv,VAST,TVCG,Podium: Ranking Data Using Mixed-Initiative Visual Analytics,,"Emily Wall, Subhajit Das, Ravish Chawla, Bharath Kalidindi, Eli T. Brown, Alex Endert",https://www.cc.gatech.edu/~ewall9/media/papers/PodiumVAST17.pdf,"People often rank and order data points as a vital part of making decisions. Multi-attribute ranking systems are a common tool used to make these data-driven decisions. Such systems often take the form of a table-based visualization in which users assign weights to the attributes representing the quantifiable importance of each attribute to a decision, which the system then uses to compute a ranking of the data. However, these systems assume that users are able to quantify their conceptual understanding of how important particular attributes are to a decision. This is not always easy or even possible for users to do. Rather, people often have a more holistic understanding of the data. They form opinions that data point A is better than data point B but do not necessarily know which attributes are important. To address these challenges, we present a visual analytic application to help people rank multi-variate data points. We developed a prototype system, Podium, that allows users to drag rows in the table to rank order data points based on their perception of the relative value of the data. Podium then infers a weighting model using Ranking SVM that satisfies the user?s data preferences as closely as possible. Whereas past systems help users understand the relationships between data points based on changes to attribute weights, our approach helps users to understand the attributes that might inform their understanding of the data. We present two usage scenarios to describe some of the potential uses of our proposed technique: (1) understanding which attributes contribute to a user?s subjective preferences for data, and (2) deconstructing attributes of importance for existing rankings.Our proposed approach makes powerful machine learning techniques more usable to those who may not have expertise in these areas",,,,,youtube Z4N9wKxK2i4,,2018,2017,VAST,301-C,Thursday,Interaction in the Analysis Process,,2:00:00 PM,2:20:00 PM
openaccessvis.csv,VAST,TVCG,Progressive Learning of Topic Modeling Parameters: A Visual Analytics Framework,,"Mennatallah El-Assady, Rita Sevastjanova, Fabian Sperrle, Daniel Keim, Christopher Collins",https://bib.dbvis.de/uploadedFiles/progressivelearningtopic.pdf,"Topic modeling algorithms are widely used to analyze the thematic composition of text corpora but remain difficult to interpret and adjust. Addressing these limitations, we present a modular visual analytics framework, tackling the understandability and adaptability of topic models through a user-driven reinforcement learning process which does not require a deep understanding of the underlying topic modeling algorithms. Given a document corpus, our approach initializes two algorithm configurations based on a parameter space analysis that enhances document separability. We abstract the model complexity in an interactive visual workspace for exploring the automatic matching results of two models, investigating topic summaries, analyzing parameter distributions, and reviewing documents. The main contribution of our work is an iterative decision-making technique in which users provide a document-based relevance feedback that allows the framework to converge to a user-endorsed topic distribution. We also report feedback from a two-stage study which shows that our technique results in topic model quality improvements on two independent measures.",,,,,vimeo 230830619,,2018,2017,VAST,207,Wednesday,Text Analytics,,11:50:00 AM,12:10:00 PM
openaccessvis.csv,VAST,TVCG,Sequence Synopsis: Optimize Visual Summary of Temporal Event Data,,"Yuanzhe Chen, Panpan Xu, Liu Ren",http://lliquid.github.io/homepage/files/ss_vast17.pdf,"Event sequences analysis plays an important role in many application domains such as customer behavior analysis, electronic health record analysis and vehicle fault diagnosis. Real-world event sequence data is often noisy and complex with high event cardinality, making it a challenging task to construct concise yet comprehensive overviews for such data. In this paper, we propose a novel visualization technique based on the minimum description length (MDL) principle to construct a coarse-level overview of event sequence data while balancing the information loss in it. The method addresses a fundamental trade-off in visualization design: reducing visual clutter vs. increasing the information content in a visualization. The method enables simultaneous sequence clustering and pattern extraction and is highly tolerant to noises such as missing or additional events in the data. Based on this approach we propose a visual analytics framework with multiple levels-of-detail to facilitate interactive data exploration. We demonstrate the usability and effectiveness of our approach through case studies with two real-world datasets. One dataset showcases a new application domain for event sequence visualization, i.e., fault development path analysis in vehicles for predictive maintenance. We also discuss the strengths and limitations of the proposed method based on user feedback.",,,,,vimeo 230830645,,2018,2017,VAST,301-C,Wednesday,Sequences and Events,,2:00:00 PM,2:20:00 PM
openaccessvis.csv,VAST,TVCG,SkyLens: Visual Analysis of Skyline on Multi-dimensional Data,,"Xun Zhao, Yanhong Wu, Weiwei Cui, Xinnan Du, Yuan Chen, Yong Wang, Dik-Lun Lee, Huamin Qu",http://yhwu.me/publications/skylens_vast17.pdf,"Skyline queries have wide-ranging applications in fields that involve multi-criteria decision making, including tourism, retail industry, and human resources. By automatically removing incompetent candidates, skyline queries allow users to focus on a subset of superior data items (i.e., the skyline), thus reducing the decision-making overhead. However, users are still required to interpret and compare these superior items manually before making a successful choice. This task is challenging because of two issues. First, people usually have fuzzy, unstable, and inconsistent preferences when presented with multiple candidates. Second, skyline queries do not reveal the reasons for the superiority of certain skyline points in a multi-dimensional space. To address these issues, we propose SkyLens, a visual analytic system aiming at revealing the superiority of skyline points from different perspectives and at different scales to aid users in their decision making. Two scenarios demonstrate the usefulness of SkyLens on two datasets with a dozen of attributes. A qualitative study is also conducted to show that users can efficiently accomplish skyline understanding and comparison tasks with SkyLens.",,,,,vimeo 230829927,,2018,2017,VAST,301-C,Wednesday,High-dimensional Data,,9:10:00 AM,9:30:00 AM
openaccessvis.csv,VAST,TVCG,SOMFlow: Guided Exploratory Cluster Analysis with Self-Organizing Maps and Analytic Provenance,,"Dominik Sacha, Matthias Kraus, Jrgen Bernard, Michael Behrisch, Tobias Schreck, Yuki Asano, Daniel Keim",,,,,,,,,2018,2017,VAST,301-C,Thursday,ML2: Cluster Analysis,,4:35:00 PM,4:55:00 PM
openaccessvis.csv,VAST,TVCG,Supporting Handoff in Asynchronous Collaborative Sensemaking Using Knowledge-Transfer Graphs,,"Jian Zhao, Michael Glueck, Petra Isenberg, Fanny Chevalier, Azam Khan",,"During asynchronous collaborative analysis, handoff of partial findings is challenging because externalizations produced by analysts may not adequately communicate their investigative process. To address this challenge, we developed techniques to automatically capture and help encode tacit aspects of the investigative process based on an analyst?s interactions, and streamline explicit authoring of handoff annotations. We designed our techniques to mediate awareness of analysis coverage, support explicit communication of progress and uncertainty with annotation, and implicit communication through playback of investigation histories. To evaluate our techniques, we developed an interactive visual analysis system, KTGraph, that supports an asynchronous investigative document analysis task. We conducted a two-phase user study to characterize a set of handoff strategies and to compare investigative performance with and without our techniques. The results suggest that our techniques promote the use of more effective handoff strategies, help increase an awareness of prior investigative process and insights, as well as improve final investigative outcomes.",,,,,youtube 5iEyczTOvxQ,10.1109/TVCG.2017.2745279,2018,2017,VAST,207,Thursday,Sensemaking,,4:55:00 PM,5:15:00 PM
openaccessvis.csv,VAST,TVCG,The Interactive Visualization Gap in Initial Exploratory Data Analysis,,"Andrea Batch, Niklas Elmqvist",http://www.umiacs.umd.edu/~elm/projects/visgap/visgap.pdf,"Data scientists and other analytic professionals often use interactive visualization in the dissemination phase at the end of a workflow during which findings are communicated to a wider audience. Visualization scientists, however, hold that interactive representation of data can also be used during exploratory analysis itself. Since the use of interactive visualization is optional rather than mandatory, this leaves a ?visualization gap? during initial exploratory analysis that is the onus of visualization researchers to fill. In this paper, we explore areas where visualization would be beneficial in applied research by conducting a design study using a novel variation on contextual inquiry conducted with professional data analysts. Based on these interviews and experiments, we propose a set of interactive initial exploratory visualization guidelines which we believe will promote adoption by this type of user.",,,,,vimeo 230830233,10.1109/TVCG.2017.2743990,2018,2017,VAST,301-C,Thursday,Theory and Analysis Process,,11:50:00 AM,12:10:00 PM
openaccessvis.csv,VAST,TVCG,Towards a Systematic Combination of Dimension Reduction and Clustering in Visual Analytics,,"John Wenskovitch, Ian Crandell, Naren Ramakrishnan, Leanna House, Scotland Leman, Chris North",https://infovis.cs.vt.edu/sites/default/files/systematic-combination-dimension.pdf,"Dimension reduction algorithms and clustering algorithms are both frequently used techniques in visual analytics. Both families of algorithms assist analysts in performing related tasks regarding the similarity of observations and finding groups in datasets. Though initially used independently, recent works have incorporated algorithms from each family into the same visualization systems. However, these algorithmic combinations are often ad hoc or disconnected, working independently and in parallel rather than integrating some degree of interdependence. A number of design decisions must be addressed when employing dimension reduction and clustering algorithms concurrently in a visualization system, including the selection of each algorithm, the order in which they are processed, and how to present and interact with the resulting projection. This paper contributes an overview of combining dimension reduction and clustering into a visualization system, discussing the challenges inherent in developing a visualization system that makes use of both families of algorithms.",,,,,vimeo 230830954,,2018,2017,VAST,301-C,Thursday,ML2: Cluster Analysis,,4:55:00 PM,5:15:00 PM
openaccessvis.csv,VAST,TVCG,TreePOD: Sensitivity-Aware Selection of Pareto-Optimal Decision Trees,,"Thomas Mhlbacher, Lorenz Linhardt, Torsten M”ller, Harald Piringer",http://eprints.cs.univie.ac.at/5263/1/treepod.pdf,"Balancing accuracy gains with other objectives such as interpretability is a key challenge when building decision trees. However, this process is difficult to automate because it involves know-how about the domain as well as the purpose of the model. This paper presents TreePOD, a new approach for sensitivity-aware model selection along trade-offs. TreePOD is based on exploring a large set of candidate trees generated by sampling the parameters of tree construction algorithms. Based on this set, visualizations of quantitative and qualitative tree aspects provide a comprehensive overview of possible tree characteristics. Along trade-offs between two objectives, TreePOD provides efficient selection guidance by focusing on Pareto-optimal tree candidates. TreePOD also conveys the sensitivities of tree characteristics on variations of selected parameters by extending the tree generation process with a full-factorial sampling. We demonstrate how TreePOD supports a variety of tasks involved in decision tree selection and describe its integration in a holistic workflow for building and selecting decision trees. For evaluation, we illustrate a case study for predicting critical power grid states, and we report qualitative feedback from domain experts in the energy sector. This feedback suggests that TreePOD enables users with and without statistical background a confident and efficient identification of suitable decision trees.",,,,,youtube a3QC3crIsxc,,2018,2017,VAST,102-ABC,Friday,ML3: Classification,,9:30:00 AM,9:50:00 AM
openaccessvis.csv,VAST,TVCG,Understanding a sequence of sequences: Visual exploration of categorical states in lake sediment cores,,"Andrea Unger, Nadine Dr„ger, Mike Sips, Dirk Lehmann",http://46.38.235.241/webpage/dirkfiles/publications/Lehmann_2017_TVCG2_VAST.pdf,"This design study focuses on the analysis of a time sequence of categorical sequences. Such data is relevant for the geoscientific research field of landscape and climate development. It results from microscopic analysis of lake sediment cores. The goal is to gain hypotheses about landscape evolution and climate conditions in the past. To this end, geoscientists identify which categorical sequences are similar in the sense that they indicate similar conditions. Categorical sequences are similar if they have similar meaning (semantic similarity) and appear in similar time periods (temporal similarity). For data sets with many different categorical sequences, the task to identify similar sequences becomes a challenge. Our contribution is a tailored visual analysis concept that effectively supports the analytical process. Our visual interface comprises coupled visualizations of semantics and temporal context for the exploration and assessment of the similarity of categorical sequences. Integrated automatic methods reduce the analytical effort substantially. They (1) extract unique sequences in the data and (2) rank sequences by a similarity measure during the search for similar sequences. We evaluated our concept by demonstrations of our prototype to a larger audience and hands-on analysis sessions for two different lakes. According to geoscientists, our approach fills an important methodological gap in the application domain",,,,,youtube upjkAJTgVXI,,2018,2017,VAST,301-C,Wednesday,Sequences and Events,,3:20:00 PM,3:40:00 PM
openaccessvis.csv,VAST,TVCG,Understanding the Relationship between Interactive Optimisation and Visual Analytics in the Context of Prostate Brachytherapy,,"Jie Liu, Tim Dwyer, Kim Marriott, Jeremy Millar, Annette Haworth",,"The fields of operations research and computer science have long sought to find automatic solver techniques that can find high-quality solutions to difficult real-world optimisation problems. The traditional workflow is to exactly model the problem and then enter this model into a general-purpose &#x201C;black-box&#x201D; solver. In practice, however, many problems cannot be solved completely automatically, but require a &#x201C;human-in-the-loop&#x201D; to iteratively refine the model and give hints to the solver. In this paper, we explore the parallels between this interactive optimisation workflow and the visual analytics sense-making loop. We assert that interactive optimisation is essentially a visual analytics task and propose a problem-solving loop analogous to the sense-making loop. We explore these ideas through an in-depth analysis of a use-case in prostate brachytherapy, an application where interactive optimisation may be able to provide significant assistance to practitioners in creating prostate cancer treatment plans customised to each patient&#x0027;s tumour characteristics. However, current brachytherapy treatment planning is usually a careful, mostly manual process involving multiple professionals. We developed a prototype interactive optimisation tool for brachytherapy that goes beyond current practice in supporting focal therapy - targeting tumour cells directly rather than simply seeking coverage of the whole prostate gland. We conducted semi-structured interviews, in two stages, with seven radiation oncology professionals in order to establish whether they would prefer to use interactive optimisation for treatment planning and whether such a tool could improve their trust in the novel focal therapy approach and in machine generated solutions to the problem.",,,,,,10.1109/TVCG.2017.2744418,2018,2017,VAST,301-C,Thursday,Interaction in the Analysis Process,,3:00:00 PM,3:20:00 PM
openaccessvis.csv,VAST,TVCG,VIGOR: Interactive Visual Exploration of Graph Query Results,,"Robert Pienta, Fred Hohman, Alex Endert, Acar Tamersoy, Kevin Roundy, Chris Gates, Shamkant Navathe, Duen Horng Chau",https://www.cc.gatech.edu/~dchau/papers/17-vast-vigor.pdf,"Finding patterns in graphs has become a vital challenge in many domains from biological systems, network security, to finance (e.g., finding money laundering rings of bankers and business owners). While there is significant interest in graph databases and querying techniques, less research has focused on helping analysts make sense of underlying patterns within a group of subgraph results. Visualizing graph query results is challenging, requiring effective summarization of a large number of subgraphs, each having potentially shared node-values, rich node features, and flexible structure across queries. We present VIGOR, a novel interactive visual analytics system, for exploring and making sense of query results. VIGOR uses multiple coordinated views, leveraging different data representations and organizations to streamline analysts sensemaking process. VIGOR contributes: (1) an exemplar-based interaction technique, where an analyst starts with a specific result and relaxes constraints to find other similar results or starts with only the structure (i.e., without node value constraints), and adds constraints to narrow in on specific results; and (2) a novel feature-aware subgraph result summarization. Through a collaboration with Symantec, we demonstrate how VIGOR helps tackle real-world problems through the discovery of security blindspots in a cybersecurity dataset with over 11,000 incidents. We also evaluate VIGOR with a within-subjects study, demonstrating VIGOR?s ease of use over a leading graph database management system, and its ability to help analysts understand their results at higher speed and make fewer errors.",,,,,youtube -jeck0yrT_Q,,2018,2017,VAST,301-C,Tuesday,Graphs and Trees,,5:15:00 PM,5:35:00 PM
openaccessvis.csv,VAST,TVCG,Visual Diagnosis of Tree Boosting Methods,,"Jiannan Xiao, Junlin Liu, Xiting Wang, Jing Wu, Jun Zhu, Shixia Liu",http://shixialiu.com/publications/boostvis/paper.pdf,"Tree boosting, which combines weak learners (typically decision trees) to generate a strong learner, is a highly effective and widely used machine learning method. However, the development of a high performance tree boosting model is a time-consuming process that requires numerous trial-and-error experiments. To tackle this issue, we have developed a visual diagnosis tool, BOOSTVis, to help experts quickly analyze and diagnose the training process of tree boosting. In particular, we have designed a temporal confusion matrix visualization, and combined it with a t-SNE projection and a tree visualization. These visualization components work together to provide a comprehensive overview of a tree boosting model, and enable an effective diagnosis of an unsatisfactory training process. Two case studies that were conducted on the Otto Group Product Classification Challenge dataset demonstrate that BOOSTVis can provide informative feedback and guidance to improve understanding and diagnosis of tree boosting algorithms.",,,,,video http://shixialiu.com/publications/boostvis/video.mp4,,2018,2017,VAST,102-ABC,Friday,ML3: Classification,,8:50:00 AM,9:10:00 AM
openaccessvis.csv,VAST,TVCG,Visualizing Big Data Outliers through Distributed Aggregation,,Leland Wilkinson,,,,,,,,,2018,2017,VAST,301-C,Wednesday,High-dimensional Data,,9:30:00 AM,9:50:00 AM
openaccessvis.csv,VAST,TVCG,Visualizing Confidence in Cluster-based Ensemble Weather Forecast Analyses,,"Alexander Kumpf, Bianca Tost, Marlene Baumgart, Michael Riemer, Rdiger Westermann, Marc Rautenhaus",https://wwwcg.in.tum.de/fileadmin/user_upload/Lehrstuehle/Lehrstuhl_XV/Research/Publications/2017/Cluster_Confidence/kumpf_etal_clustering_2017.pdf,"In meteorology, cluster analysis is frequently used to determine representative trends in ensemble weather predictions in a selected spatio-temporal region, e.g., to reduce a set of ensemble members to simplify and improve their analysis. Identified clusters (i.e., groups of similar members), however, can be very sensitive to small changes of the selected region, so that clustering results can be misleading and bias subsequent analyses. In this article, we ?a team of visualization scientists and meteorologists? deliver visual analytics solutions to analyze the sensitivity of clustering results with respect to changes of a selected region. We propose an interactive visual interface that enables simultaneous visualization of a) the variation in composition of identified clusters (i.e., their robustness), b) the variability in cluster membership for individual ensemble members, and c) the uncertainty in the spatial locations of identified trends. We demonstrate that our solution shows meteorologists how representative a clustering result is, and with respect to which changes in the selected region it becomes unstable. Furthermore, our solution helps to identify those ensemble members which stably belong to a given cluster and can thus be considered similar. In a real-world application case we show how our approach is used to analyze the clustering behavior of different regions in a forecast of ?Tropical Cyclone Karl?, guiding the user towards the cluster robustness information required for subsequent ensemble analysis",,,,,vimeo 230830865,,2018,2017,VAST,301-C,Thursday,ML2: Cluster Analysis,,4:15:00 PM,4:35:00 PM
openaccessvis.csv,VAST,TVCG,Visualizing Dataflow Graphs of Deep Learning Models in TensorFlow,,"Kanit Wongsuphasawat, Daniel Smilkov, James Wexler, Jimbo Wilson, Dandelion Man‚, Doug Fritz, Dilip Krishnan, Fernanda B. Vi‚gas, Martin Wattenberg",https://idl.cs.washington.edu/files/2018-TensorFlowGraph-VAST.pdf,"We present a design study of the TensorFlow Graph Visualizer, part of the TensorFlow machine intelligence platform. This tool helps users understand complex machine learning architectures by visualizing their underlying dataflow graphs. The tool works by applying a series of graph transformations that enable standard layout techniques to produce a legible interactive diagram. To declutter the graph, we decouple non-critical nodes from the layout. To provide an overview, we build a clustered graph using the hierarchical structure annotated in the source code. To support exploration of nested structure on demand, we perform edge bundling to enable stable and responsive cluster expansion. Finally, we detect and highlight repeated structures to emphasize a model?s modular composition. To demonstrate the utility of the visualizer, we describe example usage scenarios and report user feedback. Overall, users find the visualizer useful for understanding, debugging, and sharing the structures of their models.",,,,,vimeo 232930758,,2018,2017,Other,301-CD,Tuesday,VIS Awards & Best Papers,,9:05:00 AM,9:25:00 AM
openaccessvis.csv,VAST,TVCG,Voila: Visual Anomaly Detection and Monitoring with Streaming Spatiotemporal Data,,"Nan Cao, Chaoguang Lin, Qiuhan Zhu, Yu-Ru Lin, Xian Teng, Xidao Wen",,,,,,,,,2018,2017,VAST,301-C,Tuesday,"Space, Time, Movement",,2:20:00 PM,2:40:00 PM
openaccessvis.csv,VAST,VAST,A Visual Analytics System for Optimizing Communications in Massively Parallel Applications,,"Takanori Fujiwara, Preeti Malakar, Khairi Reda, Venkatram Vishwanath, Michael Papka, Kwan-Liu Ma",,,,,,,youtube RzXfxXjAoYk,,2017,2017,VAST,301-C,Thursday,Visual Representation and Design Study,,8:50:00 AM,9:10:00 AM
openaccessvis.csv,VAST,VAST,A Workflow for Visual Diagnostics of Binary Classifiers using Instance-Level Explanations,,"Josua Krause, Aritra Dasgupta, Jordan Swartz, Yindalon Aphinyanaphongs, Enrico Bertini",https://arxiv.org/pdf/1705.01968.pdf,"Human-in-the-loop data analysis applications necessitate greater transparency in machine learning models for experts to understand and trust their decisions. To this end, we propose a visual analytics workflow to help data scientists and domain experts explore, diagnose, and understand the decisions made by a binary classifier. The approach leverages ?instance-level explanations?, measures of local feature relevance that explain single instances, and uses them to build a set of visual representations that guide the users in their investigation. The workflow is based on three main visual representations and steps: one based on aggregate statistics to see how data distributes across correct / incorrect decisions; one based on explanations to understand which features are used to make these decisions; and one based on raw data, to derive insights on potential root causes for the observed patterns. The workflow is derived from a long-term collaboration with a group of machine learning and healthcare professionals who used our method to make sense of machine learning models they developed. The case study from this collaboration demonstrates that the proposed workflow helps experts derive useful knowledge about the model and the phenomena it describes, thus experts can generate useful hypotheses on how a model can be improved.",,https://github.com/nyuvis/explanation_explorer,,,vimeo 235631465,,2017,2017,VAST,102-ABC,Friday,ML3: Classification,,9:10:00 AM,9:30:00 AM
openaccessvis.csv,VAST,VAST,CRICTO: Supporting Sensemaking through Crowdsourced Information Schematization,,"Haeyong Chung, Sai Prashanth Dasari, Santhosh Nandhakumar, Christopher Andrews",,,,,,,,,2017,2017,VAST,207,Thursday,Sensemaking,,5:15:00 PM,5:35:00 PM
openaccessvis.csv,VAST,VAST,CrystalBall: A Visual Analytic System for Future Event Discovery and Analysis from Social Media Data,,"Isaac Cho, Ryan Wesslen, Svitlana Volkova, Bill Ribarsky, Wenwen Dou",https://wesslen.github.io/assets/documents/papers/crystalball.pdf,"Social media data bear valuable insights regarding events that occur around the world. Events are inherently temporal and spatial. Existing visual text analysis systems have focused on detecting and analyzing past and ongoing events. Few have leveraged social media information to look for events that may occur in the future. In this paper, we present an interactive visual analytic system, CrystalBall, that automatically identifies and ranks future events from Twitter streams. CrystalBall integrates new methods to discover events with interactive visualizations that permit sensemaking of the identified future events. Our computational methods integrate seven different measures to identify and characterize future events, leveraging information regarding time, location, social networks, and the informativeness of the messages. A visual interface is tightly coupled with the computational methods to present a concise summary of the possible future events. A novel connection graph and glyphs are designed to visualize the characteristics of the future events. To demonstrate the efficacy of CrystalBall in identifying future events and supporting interactive analysis, we present multiple case studies and validation studies on analyzing events derived from Twitter data.",,,,,vimeo 230830262,,2017,2017,VAST,301-C,Wednesday,Sequences and Events,,2:40:00 PM,3:00:00 PM
openaccessvis.csv,VAST,VAST,E-Map: A Visual Analytics Approach for Exploring Significant Event Evolutions in Social Media,,"Siming Chen, Shuai Chen, Lijing Lin, Xiaoru Yuan, Jie Liang, Xiaolong (Luke) Zhang",,,,,,,,,2017,2017,VAST,301-C,Wednesday,Sequences and Events,,3:00:00 PM,3:20:00 PM
openaccessvis.csv,VAST,VAST,Interactive Visual Alignment of Medieval Text Versions,,"Stefan J„nicke, David Wrisley",,,,,,,,,2017,2017,VAST,301-C,Thursday,Interaction in the Analysis Process,,3:20:00 PM,3:40:00 PM
openaccessvis.csv,VAST,VAST,Pattern Trails: Visual Analysis of Pattern Transitions in Subspaces,,"Dominik J„ckle, Michael Hund, Michael Behrisch, Daniel A. Keim, Tobias Schreck",https://dominikjaeckle.com/projects/2017/pattern_trails/paper/2017_jaeckle_pattern_trails.pdf,"Subspace analysis methods have gained interest for identifying patterns in subspaces of high-dimensional data. Existing techniques allow to visualize and compare patterns in subspaces. However, many subspace analysis methods produce an abundant amount of patterns, which often remain redundant and are difficult to relate. Creating effective layouts for comparison of subspace patterns remains challenging. We introduce Pattern Trails, a novel approach for visually ordering and comparing subspace patterns. Central to our approach is the notion of pattern transitions as an interpretable structure imposed to order and compare patterns between subspaces. The basic idea is to visualize projections of subspaces side-by-side, and indicate changes between adjacent patterns in the subspaces by a linked representation, hence introducing pattern transitions. Our contributions comprise a systematization for how pairs of subspace patterns can be compared, and how changes can be interpreted in terms of pattern transitions. We also contribute a technique for visual subspace analysis based on a data-driven similarity measure between subspace representations. This measure is useful to order the patterns, and interactively group subspaces to reduce redundancy. We demonstrate the usefulness of our approach by application to several use cases, indicating that data can be meaningfully ordered and interpreted in terms of pattern transitions.",,,,,vimeo 230829949,,2017,2017,VAST,301-C,Wednesday,High-dimensional Data,,8:50:00 AM,9:10:00 AM
openaccessvis.csv,VAST,VAST,QSAnglyzer: Visual Analytics for Prismatic Analysis of Question Answering System Evaluations,,"Nan-Chen Chen, Been Kim",http://nanchen.csie.org/publications/qsanglyzer_vast2017.pdf,"Developing sophisticated artificial intelligence (AI) systems requires AI researchers to experiment with different designs and analyze results from evaluations (we refer this task as evaluation analysis). In this paper, we tackle the challenges of evaluation analysis in the domain of question-answering (QA) systems. Through in-depth studies with QA researchers, we identify tasks and goals of evaluation analysis and derive a set of design rationales, based on which we propose a novel approach termed prismatic analysis. Prismatic analysis examines data through multiple ways of categorization (referred as angles). Categories in each angle are measured by aggregate metrics to enable diverse comparison scenarios.<br/>To facilitate prismatic analysis of QA evaluations, we design and implement the Question Space Anglyzer (QSAnglyzer), a visual analytics (VA) tool. In QSAnglyzer, the high-dimensional space formed by questions is divided into categories based on several angles (e.g., topic and question type). Each category is aggregated by accuracy, the number of questions, and accuracy variance across evaluations. QSAnglyzer visualizes these angles so that QA researchers can examine and compare evaluations from various aspects both individually and collectively. Furthermore, QA researchers filter questions based on any angle by clicking to construct complex queries. We validate QSAnglyzer through controlled experiments and by expert reviews. The results indicate that when using QSAnglyzer, users perform analysis tasks faster (p < 0.01) and more accurately (p < 0.05), and are quick to gain new insight. We discuss how *e-mail: nanchen@uw.edu ? e-mail: beenkim@csail.mit.edu prismatic analysis and QSAnglyzer scaffold evaluation analysis, and provide directions for future research.",,,,,vimeo 230829824,,2017,2017,VAST,301-C,Thursday,Visual Representation and Design Study,,8:30:00 AM,8:50:00 AM
openaccessvis.csv,VAST,VAST,"The y of it Matters, Even for Storyline Visualization",,"Dustin Arendt, Megan Pirrung",,,,,,,,,2017,2017,VAST,301-C,Thursday,Visual Representation and Design Study,,9:50:00 AM,10:10:00 AM
openaccessvis.csv,VAST,VAST,The Anchoring Effect in Decision-Making with Visual Analytics,,"Isaac Cho, Ryan Wesslen, Alireza Karduni, Sashank Santhanam, Samira Shaikh, Wenwen Dou",https://wesslen.github.io/assets/documents/papers/anchorbias.pdf,"Anchoring effect is the tendency to focus too heavily on one piece of information when making decisions. In this paper, we present a novel, systematic study and resulting analyses that investigate the effects of anchoring effect on human decision-making using visual analytic systems. Visual analytics interfaces typically contain multiple views that present various aspects of information such as spatial, temporal, and categorical. These views are designed to present complex, heterogeneous data in accessible forms that aid decisionmaking. However, human decision-making is often hindered by the use of heuristics, or cognitive biases, such as anchoring effect. Anchoring effect can be triggered by the order in which information is presented or the magnitude of information presented. Through carefully designed laboratory experiments, we present evidence of anchoring effect in analysis with visual analytics interfaces when users are primed by representation of different pieces of information. We also describe detailed analyses of users? interaction logs which reveal the impact of anchoring bias on the visual representation preferred and paths of analysis. We discuss implications for future research to possibly detect and alleviate anchoring bias.",,,https://github.com/wesslen/vast2017-anchoringeffect,,vimeo 230830292,,2017,2017,VAST,301-C,Thursday,Theory and Analysis Process,,11:30:00 AM,11:50:00 AM
openaccessvis.csv,VAST,VAST,The Role of Explicit Knowledge: A Conceptual Model of Knowledge-Assisted Visual Analytics,,"Paolo Federico, Markus Wagner, Alexander Rind, Albert Amor-Amor¢s, Silvia Miksch, Wolfgang Aigner",http://www.cvast.tuwien.ac.at/sites/default/files/federico-2017-vast.pdf,"Visual Analytics (VA) aims to combine the strengths of humans and computers for effective data analysis. In this endeavor, humans? tacit knowledge from prior experience is an important asset that can be leveraged by both human and computer to improve the analytic process. While VA environments are starting to include features to formalize, store, and utilize such knowledge, the mechanisms and degree in which these environments integrate explicit knowledge varies widely. Additionally, this important class of VA environments has never been elaborated on by existing work on VA theory. This paper proposes a conceptual model of Knowledge-assisted VA conceptually grounded on the visualization model by van Wijk. We apply the model to describe various examples of knowledge-assisted VA from the literature and elaborate on three of them in finer detail. Moreover, we illustrate the utilization of the model to compare different design alternatives and to evaluate existing approaches with respect to their use of knowledge. Finally, the model can inspire designers to generate novel VA environments using explicit knowledge effectively",,,,,vimeo 230830806,,2017,2017,VAST,301-C,Thursday,Theory and Analysis Process,,10:50:00 AM,11:10:00 AM
openaccessvis.csv,VAST,VAST,Understanding Hidden Memories of Recurrent Neural Networks,,"Yao Ming, Shaozu CAO, Ruixiang Zhang, Zhen LI, Yuanzhe Chen, Yangqiu Song, Huamin Qu",https://osf.io/f36tb/,"Recurrent neural networks (RNNs) have been successfully appliedto various natural language processing (NLP) tasks and achievedbetter results than conventional methods. However, the lack ofunderstanding of the mechanisms behind their effectiveness lim-its further improvements on their architectures. In this paper, wepresent a visual analytics method for understanding and comparingRNN models for NLP tasks. We propose a technique to explainthe function of individual hidden state units based on their expectedresponse to input texts. We then co-cluster hidden state units andwords based on the expected response and visualize co-clusteringresults as memory chips and word clouds to provide more structuredknowledge on RNNs? hidden states. We also propose a glyph-based sequence visualization based on aggregate information to analyzethe behavior of an RNN?s hidden state atthesentence-level. Theusability and effectiveness of our methodaredemonstrated throughcase studies and reviews from domain experts.",,https://github.com/myaooo/RNNVis,,,youtube 0QFDNLdQ6_w,,2017,2017,VAST,301-C,Wednesday,ML1: Deep Learning,,10:50:00 AM,11:10:00 AM
openaccessvis.csv,VAST,VAST,Visual Causality Analysis Made Practical,,"Jun Wang, Klaus Mueller",http://www3.cs.stonybrook.edu/~mueller/papers/Visual%20Causality%20Analysis%20Made%20Practical.pdf,"Deriving the exact casual model that governs the relations between variables in a multidimensional dataset is difficult in practice. It is because causal inference algorithms by themselves typically cannot encode an adequate amount of domain knowledge to break all ties. Visual analytic approaches are considered a feasible alternative to fully automated methods. However, their application in real-world scenarios can be tedious. This paper focuses on these practical aspects of visual causality analysis. The most imperative of these aspects is posed by Simpson? Paradox. It implies the existence of multiple causal models differing in both structure and parameter depending on how the data is subdivided. We propose a comprehensive interface that engages human experts in identifying these subdivisions and allowing them to establish the corresponding causal models via a rich set of interactive facilities. Other features of our interface include: (1) a new causal network visualization that emphasizes the flow of causal dependencies, (2) a model scoring mechanism with visual hints for interactive model refinement, and (3) flexible approaches for handling heterogeneous data. Various real-world data examples are given.",,,,,youtube nbHOBIlEzt4,,2017,2017,VAST,207,Thursday,Sensemaking,,5:35:00 PM,5:55:00 PM
openaccessvis.csv,VAST,VAST,Visualizing Real-Time Strategy Games: The Example of StarCraft II,,"Yen-Ting Kuan, Yu-Shuen Wang, Jung-Hong Chuang",,,,,,,,,2017,2017,VAST,301-C,Thursday,Visual Representation and Design Study,,9:10:00 AM,9:30:00 AM
openaccessvis.csv,VAST,VAST,"Warning, Bias May Occur: A Proposed Approach to Detecting Cognitive Bias in Interactive Visual Analytics",,"Emily Wall, Leslie M. Blaha, Lyndsey Franklin, Alex Endert",https://www.cc.gatech.edu/~ewall9/media/papers/BiasVAST17.pdf,"Visual analytic tools combine the complementary strengths of humans and machines in human-in-the-loop systems. Humans provide invaluable domain expertise and sensemaking capabilities to this discourse with analytic models; however, little consideration has yet been given to the ways inherent human biases might shape the visual analytic process. In this paper, we establish a conceptual framework for considering bias assessment through human-in-the-loop systems and lay the theoretical foundations for bias measurement. We propose six preliminary metrics to systematically detect and quantify bias from user interactions and demonstrate how the metrics might be implemented in an existing visual analytic system, InterAxis. We discuss how our proposed metrics could be used by visual analytic systems to mitigate the negative effects of cognitive biases by making users aware of biased processes throughout their analyses.",,,,,youtube W9LWi3oXjM0,,2017,2017,VAST,301-C,Thursday,Theory and Analysis Process,,11:10:00 AM,11:30:00 AM
openaccessvis.csv,SciVis,TVCG,A Virtual Reality Visualization Tool for Neuron Tracing,,"Will Usher, Pavol Klacansky, Frederick Federer, Peer-Timo Bremer, Aaron Knoll, Alessandra Angelucci, Valerio Pascucci",http://sci.utah.edu/~will/papers/vrnt/vr-neuron-tracing.pdf,"Tracing neurons in large-scale microscopy data is crucial to establishing a wiring diagram of the brain, which is needed to understand how neural circuits in the brain process information and generate behavior. Automatic techniques often fail for large and complex datasets, and connectomics researchers may spend weeks or months manually tracing neurons using 2D image stacks. We present a design study of a new virtual reality (VR) system, developed in collaboration with trained neuroanatomists, to trace neurons in microscope scans of the visual cortex of primates. We hypothesize that using consumer-grade VR technology to interact with neurons directly in 3D will help neuroscientists better resolve complex cases and enable them to trace neurons faster and with less physical and mental strain. We discuss both the design process and technical challenges in developing an interactive system to navigate and manipulate terabyte-sized image volumes in VR. Using a number of different datasets, we demonstrate that, compared to widely used commercial software, consumer-grade VR presents a promising alternative for scientists",,,,,vimeo 230835553,,2018,2017,SciVis,207,Tuesday,Volume Rendering,,5:35:00 PM,5:55:00 PM
openaccessvis.csv,SciVis,TVCG,Abstractocyte: A Visual Tool for Exploring Nanoscale Astroglial Cells,,"Haneen Mohammed, Ali Al-Awami, Johanna Beyer, Corrado Cali, Pierre Magistretti, Hanspeter Pfister, Markus Hadwiger",,"This paper presents <em>Abstractocyte</em>, a system for the visual analysis of astrocytes and their relation to neurons, in nanoscale volumes of brain tissue. Astrocytes are glial cells, i.e., non-neuronal cells that support neurons and the nervous system. The study of astrocytes has immense potential for understanding brain function. However, their complex and widely-branching structure requires high-resolution electron microscopy imaging and makes visualization and analysis challenging. Furthermore, the structure and function of astrocytes is very different from neurons, and therefore requires the development of new visualization and analysis tools. With Abstractocyte, biologists can explore the morphology of astrocytes using various visual abstraction levels, while simultaneously analyzing neighboring neurons and their connectivity. We define a novel, conceptual 2D abstraction space for jointly visualizing astrocytes and neurons. Neuroscientists can choose a specific joint visualization as a point in this space. Interactively moving this point allows them to smoothly transition between different abstraction levels in an intuitive manner. In contrast to simply switching between different visualizations, this preserves the visual context and correlations throughout the transition. Users can smoothly navigate from concrete, highly-detailed 3D views to simplified and abstracted 2D views. In addition to investigating astrocytes, neurons, and their relationships, we enable the interactive analysis of the distribution of glycogen, which is of high importance to neuroscientists. We describe the design of Abstractocyte, and present three case studies in which neuroscientists have successfully used our system to assess astrocytic coverage of synapses, glycogen distribution in relation to synapses, and astrocytic-mitochondria coverage.",,,,,vimeo 230835732,,2018,2017,SciVis,207,Thursday,Visualization in Biology and Medicine,,8:30:00 AM,8:50:00 AM
openaccessvis.csv,SciVis,TVCG,Activity-Centered Domain Characterization for Problem-Driven Scientific Visualization,,Liz Marai,,,,,,,,,2018,2017,SciVis,207,Tuesday,"Mix: Foundations, uncertainty, particles",,2:00:00 PM,2:20:00 PM
openaccessvis.csv,SciVis,TVCG,An Intelligent System Approach for Probabilistic Volume Rendering using Hierarchical 3D Convolutional Sparse Coding,,"Tran Minh Quan, JunYoung Choi, HaeJin Jeong, Won-Ki Jeong",,,,,,,,,2018,2017,SciVis,207,Tuesday,Volume Rendering,,4:15:00 PM,4:35:00 PM
openaccessvis.csv,SciVis,TVCG,BASTet: Shareable and reproducible analysis and visualization of mass spectrometry imaging data via OpenMSI,,"Oliver Ruebel, Benjamin P. Bowen",,,https://openmsi.nersc.gov/openmsi/client/bastet.html,https://github.com/biorack/BASTet,,,vimeo 230835941,,2018,2017,SciVis,106-ABC,Friday,Applications and Visual analysis,,9:50:00 AM,10:10:00 AM
openaccessvis.csv,SciVis,TVCG,Clique Community Persistence: A Topological Visual Analysis Approach for Complex Networks,,"Bastian Rieck, Ulderico Fugacci, Jonas Lukasczyk, Heike Leitte",https://osf.io/td973/,"Complex networks require effective tools and visualizations for their analysis and comparison. Clique communities have been recognized as a powerful concept for describing cohesive structures in networks. We propose an approach that extends the computation of clique communities by considering persistent homology, a topological paradigm originally introduced to characterize and compare the global structure of shapes. Our persistence-based algorithm is able to detect clique communities and to keep track of their evolution according to different edge weight thresholds. We use this information to define comparison metrics and a new centrality measure, both reflecting the relevance of the clique communities inherent to the network. Moreover, we propose an interactive visualization tool based on nested graphs that is capable of compactly representing the evolving relationships between communities for different thresholds and clique degrees. We demonstrate the effectiveness of our approach on various network types",,https://osf.io/rdktg/,,,vimeo 230835775,,2018,2017,SciVis,207,Wednesday,Topology-based methods,,2:20:00 PM,2:40:00 PM
openaccessvis.csv,SciVis,TVCG,Dynamic Load Balancing Based on Constrained K-D Tree Decomposition for Parallel Particle Tracing,,"Jiang Zhang, Hanqi Guo, Fan Hong, Xiaoru Yuan, Tom Peterka",http://www.mcs.anl.gov/papers/P7034-0417.pdf,"Particle tracing is a fundamental technique in flow field data visualization. In this work, we present a novel dynamic load balancing method for parallel particle tracing. Specifically, we employ a constrained k-d tree decomposition approach to dynamically redistribute tasks among processes. Each process is initially assigned a regularly partitioned block along with duplicated ghost layer under the memory limit. During particle tracing, the k-d tree decomposition is dynamically performed by constraining the cutting planes in the overlap range of duplicated data. This ensures that each process is reassigned particles as even as possible, and on the other hand the new assigned particles for a process always locate in its block. Result shows good load balance and high efficiency of our method.",,,,,,,2018,2017,SciVis,207,Tuesday,"Mix: Foundations, uncertainty, particles",,3:20:00 PM,3:40:00 PM
openaccessvis.csv,SciVis,TVCG,Globe Browsing: Contextualized Spatio-Temporal Planetary Surface Visualization,,"Karl Bladin, Emil Axelsson, Erik Broberg, Carter Emmart, Patric Ljung, Alexander Bock, Anders Ynnerman",https://alexanderbock.github.io/papers/vis17-bladin-globe_browsing.pdf,"Results of planetary mapping are often shared openly for use in scientific research and mission planning. In its raw format, however, the data is not accessible to non-experts due to the difficulty in grasping the context and the intricate acquisition process. We present work on tailoring and integration of multiple data processing and visualization methods to interactively contextualize geospatial surface data of celestial bodies for use in science communication. As our approach handles dynamic data sources, streamed from online repositories, we are significantly shortening the time between discovery and dissemination of data and results. We describe the image acquisition pipeline, the pre-processing steps to derive a 2.5D terrain, and a chunked level-of-detail, out-of-core rendering approach to enable interactive exploration of global maps and high-resolution digital terrain models. The results are demonstrated for three different celestial bodies. The first case addresses high-resolution map data on the surface of Mars. A second case is showing dynamic processes, such as concurrent weather conditions on Earth that require temporal datasets. As a final example we use data from the New Horizons spacecraft which acquired images during a single flyby of Pluto. We visualize the acquisition process as well as the resulting surface data. Our work has been implemented in the OpenSpace software [8], which enables interactive presentations in a range of environments such as immersive dome theaters, interactive touch tables, and virtual reality headsets.",,https://github.com/OpenSpace/OpenSpace,,,vimeo 230835323,,2018,2017,Other,207,Tuesday,VIS Awards & Best Papers,,9:45:00 AM,10:05:00 AM
openaccessvis.csv,SciVis,TVCG,Instant Construction and Visualization of Crowded Biological Environments,,"Tobias Klein, Ludovic K. Autin, Barbora Kozlikova, David Goodsell, Arthur Olson, Eduard Gr”ller, Ivan Viola",https://www.cg.tuwien.ac.at/research/publications/2017/klein_2017_IM/klein_2017_IM-paper.pdf,"We present the first approach to integrative structural modeling of the biological mesoscale within an interactive visual environment. These complex models can comprise up to millions of molecules with defined atomic structures, locations, and interactions. Their construction has previously been attempted only within a non-visual and non-interactive environment. Our solution unites the modeling and visualization aspect, enabling interactive construction of atomic resolution mesoscale models of large portions of a cell. We present a novel set of GPU algorithms that build the basis for the rapid construction of complex biological structures. These structures consist of multiple membrane-enclosed compartments including both soluble molecules and fibrous structures. The compartments are defined using volume voxelization of triangulated meshes. For membranes, we present an extension of the Wang Tile concept that populates the bilayer with individual lipids. Soluble molecules are populated within compartments using the Halton sequence for their distribution. Fibrous structures, such as RNA or actin filaments, are created by self-avoiding random walks. Resulting overlaps of molecules are resolved by a forced-based system. Our approach opens new possibilities to the world of interactive construction of cellular compartments. We demonstrate its effectiveness by showcasing scenes of different scale and complexity that comprise blood plasma, mycoplasma, and HIV.",,,,,vimeo 230835707,,2018,2017,SciVis,207,Thursday,Visualization in Biology and Medicine,,8:50:00 AM,9:10:00 AM
openaccessvis.csv,SciVis,TVCG,Interactive Design and Visualization of Branched Covering Spaces,,"Lawrence Roy, Prashant Kumar, Sanaz Golbabaei, Yue Zhang, Eugene Zhang",http://web.engr.oregonstate.edu/~zhange/images/Paper_BCSVis_main.pdf,"Branched covering spaces are a mathematical concept which originates from complex analysis and topology and has applications in tensor field topology and geometry remeshing. Given a manifold surface and an N-way rotational symmetry field, a branched covering space is a manifold surface that has an N-to-1 map to the original surface except at the ramification points, which correspond to the singularities in the rotational symmetry field. Understanding the notion and mathematical properties of branched covering spaces is important to researchers in tensor field visualization and geometry processing, and their application areas. In this paper, we provide a framework to interactively design and visualize the branched covering space (BCS) of an input mesh surface and a rotational symmetry field defined on it. In our framework, the user can visualize not only the BCSs but also their construction process. In addition, our system allows the user to design the geometric realization of the BCS using mesh deformation techniques as well as connecting tubes. This enables the user to verify important facts about BCSs such as that they are manifold surfaces around singularities, as well as the Riemann-Hurwitz formula which relates the Euler characteristic of the BCS to that of the original mesh. Our system is evaluated by student researchers in scientific visualization and geometry processing as well as faculty members in mathematics at our university who teach topology. We include their evaluations and feedback in the paper.",,,,,vimeo 230835443,,2018,2017,SciVis,207,Wednesday,Topology-based methods,,3:20:00 PM,3:40:00 PM
openaccessvis.csv,SciVis,TVCG,Interactive Dynamic Volume Illumination with Refraction and Caustics,,"Jens Magnus, Stefan Bruckner",,,,,,,youtube 3tn6sSXw4NQ,,2018,2017,SciVis,207,Tuesday,Volume Rendering,,5:15:00 PM,5:35:00 PM
openaccessvis.csv,SciVis,TVCG,Multiscale Visualization and Scale-Adaptive Modification of DNA Nanostructures,,"Haichao Miao, Elisa De Llano, Johannes Sorger, Yasaman Ahmadi, Tadija Kekic, Tobias Isenberg, Eduard Gr”ller, Ivan Barisic, Ivan Viola",https://hal.inria.fr/hal-01581203/file/Miao_2018_MVS.pdf,"We present an approach to represent DNA nanostructures in varying forms of semantic abstraction, describe ways to smoothly transition between them, and thus create a continuous multiscale visualization and interaction space for applications in DNA nanotechnology. This new way of observing, interacting with, and creating DNA nanostructures enables domain experts to approach their work in any of the semantic abstraction levels, supporting both low-level manipulations and high-level visualization and modifications. Our approach allows them to deal with the increasingly complex DNA objects that they are designing, to improve their features, and to add novel functions in a way that no existing single-scale approach offers today. For this purpose we collaborated with DNA nanotechnology experts to design a set of ten semantic scales. These scales take the DNA?s chemical and structural behavior into account and depict it from atoms to the targeted architecture with increasing levels of abstraction. To create coherence between the discrete scales, we seamlessly transition between them in a well-defined manner. We use special encodings to allow experts to estimate the nanoscale object?s stability. We also add scale-adaptive interactions that facilitate the intuitive modification of complex structures at multiple scales. We demonstrate the applicability of our approach on an experimental use case. Moreover, feedback from our collaborating domain experts confirmed an increased time efficiency and certainty for analysis and modification tasks on complex DNA structures. Our method thus offers exciting new opportunities with promising applications in medicine and biotechnology",,,,,vimeo 230835588,,2018,2017,SciVis,106-ABC,Friday,Applications and Visual analysis,,8:30:00 AM,8:50:00 AM
openaccessvis.csv,SciVis,TVCG,On the Treatment of Field Quantities and Elemental Continuity in FEM Solutions,,"Ashok Jallepalli, Julia Docampo, Jennifer Ryan, Robert Haimes, Mike Kirby",,,,,,,,,2018,2017,SciVis,207,Wednesday,Flow Visualization,,9:30:00 AM,9:50:00 AM
openaccessvis.csv,SciVis,TVCG,Robust detection and visualization of jet-stream core lines in atmospheric flow,,"Michael Kern, Tim Hewson, Filip Sadlo, Rdiger Westermann, Marc Rautenhaus",,"Jet-streams, their core lines and their role in atmospheric dynamics have been subject to considerable meteorological research since the first half of the twentieth century. Yet, until today no consistent automated feature detection approach has been proposed to identify jet-stream core lines from 3D wind fields. Such 3D core lines can facilitate meteorological analyses previously not possible. Although jet-stream cores can be manually analyzed by meteorologists in 2D as height ridges in the wind speed field, to the best of our knowledge no automated ridge detection approach has been applied to jet-stream core detection. In this work, we ?a team of visualization scientists and meteorologists? propose a method that exploits directional information in the wind field to extract core lines in a robust and numerically less involved manner than traditional 3D ridge detection. For the first time, we apply the extracted 3D core lines to meteorological analysis, considering real-world case studies and demonstrating our method?s benefits for weather forecasting and meteorological research.",,,,,vimeo 230835424,,2018,2017,SciVis,207,Wednesday,Flow Visualization,,8:30:00 AM,8:50:00 AM
openaccessvis.csv,SciVis,TVCG,Screen-Space Normal Distribution Function Caching for Consistent Multi-Resolution Rendering of Large Particle Data,,"Mohamed Ibrahim, Patrick Wickenh„user, Peter Rautek, Guido Reina, Markus Hadwiger",http://vccvisualization.org/publications/2017_ibrahim_SNDF.pdf,"Molecular dynamics (MD) simulations are crucial to investigating important processes in physics and thermodynamics. The simulated atoms are usually visualized as hard spheres with Phong shading, where individual particles and their local density can be perceived well in close-up views. However, for large-scale simulations with 10 million particles or more, the visualization of large fields-of-view usually suffers from strong aliasing artifacts, because the mismatch between data size and output resolution leads to severe under-sampling of the geometry. Excessive super-sampling can alleviate this problem, but is prohibitively expensive. This paper presents a novel visualization method for large-scale particle data that addresses aliasing while enabling interactive high-quality rendering. We introduce the novel concept of screen-space normal distribution functions (S-NDFs) for particle data. S-NDFs represent the distribution of surface normals that map to a given pixel in screen space, which enables high-quality re-lighting without re-rendering particles. In order to facilitate interactive zooming, we cache S-NDFs in a screen-space mipmap (S-MIP). Together, these two concepts enable interactive, scale-consistent re-lighting and shading changes, as well as zooming, without having to re-sample the particle data. We show how our method facilitates the interactive exploration of real-world large-scale MD simulation data in different scenarios.",,,,,video http://vccvisualization.org/publications/2017_ibrahim_SNDF.mp4,10.1109/TVCG.2017.2743979,2018,2017,SciVis,207,Tuesday,"Mix: Foundations, uncertainty, particles",,3:00:00 PM,3:20:00 PM
openaccessvis.csv,SciVis,TVCG,SparseLeap: Efficient Empty Space Skipping for Large-Scale Volume Rendering,,"Markus Hadwiger, Ali K. Al-Awami, Johanna Beyer, Marco Agus, Hanspeter Pfister",https://johanna-b.github.io/files/documents/sparseleap_vis17.pdf,"Recent advances in data acquisition produce volume data of very high resolution and large size, such as terabyte-sized microscopy volumes. These data often contain many fine and intricate structures, which pose huge challenges for volume rendering, and make it particularly important to efficiently skip empty space. This paper addresses two major challenges: (1) The complexity of large volumes containing fine structures often leads to highly fragmented space subdivisions that make empty regions hard to skip efficiently. (2) The classification of space into empty and non-empty regions changes frequently, because the user or the evaluation of an interactive query activate a different set of objects, which makes it unfeasible to pre-compute a well-adapted space subdivision. We describe the novel SparseLeap method for efficient empty space skipping in very large volumes, even around fine structures. The main performance characteristic of SparseLeap is that it moves the major cost of empty space skipping out of the ray-casting stage. We achieve this via a hybrid strategy that balances the computational load between determining empty ray segments in a rasterization (object-order) stage, and sampling non-empty volume data in the ray-casting (image-order) stage. Before ray-casting, we exploit the fast hardware rasterization of GPUs to create a ray segment list for each pixel, which identifies non-empty regions along the ray. The ray-casting stage then leaps over empty space without hierarchy traversal. Ray segment lists are created by rasterizing a set of fine-grained, view-independent bounding boxes. Frame coherence is exploited by re-using the same bounding boxes unless the set of active objects changes. We show that SparseLeap scales better to large, sparse data than standard octree empty space skipping.",,,,,vimeo 230835661,,2018,2017,SciVis,207,Tuesday,Volume Rendering,,4:55:00 PM,5:15:00 PM
openaccessvis.csv,SciVis,TVCG,StreetVizor: Visual Exploration of Human-Scale Urban Forms based on Street Views,,"Qiaomu Shen, Wei Zeng, Yu Ye, Stefan Mueller Arisona, Simon Schubiger, Remo Burkhard, Huamin Qu",,,,,,,,,2018,2017,SciVis,106-ABC,Friday,Applications and Visual analysis,,9:30:00 AM,9:50:00 AM
openaccessvis.csv,SciVis,TVCG,"The Good, the Bad, and the Ugly: A Theoretical Framework for the Assessment of Continuous Colormaps",,"Roxana Bujack, Terece Turton, Francesca Samsel, David Rogers, James Ahrens, Colin Ware",,,,,,,vimeo 230835348,,2018,2017,SciVis,207,Tuesday,"Mix: Foundations, uncertainty, particles",,2:20:00 PM,2:40:00 PM
openaccessvis.csv,SciVis,TVCG,The Topology ToolKit,,"Julien Tierny, Guillaume Favelier, Joshua Levine, Charles Gueunet, Micha‰l Michaux",https://hal.archives-ouvertes.fr/hal-01499905/document,"This system paper presents the Topology ToolKit (TTK), a software platform designed for the topological analysis of scalar data in scientific visualization. While topological data analysis has gained in popularity over the last two decades, it has not yet been widely adopted as a standard data analysis tool for end users or developers. TTK aims at addressing this problem by providing a unified, generic, efficient, and robust implementation of key algorithms for the topological analysis of scalar data, including: critical points, integral lines, persistence diagrams, persistence curves, merge trees, contour trees, Morse-Smale complexes, fiber surfaces, continuous scatterplots, Jacobi sets, Reeb spaces, and more. TTK is easily accessible to end users due to a tight integration with ParaView. It is also easily accessible to developers through a variety of bindings (Python, VTK/C++) for fast prototyping or through direct, dependency-free, C++, to ease integration into pre-existing complex systems. While developing TTK, we faced several algorithmic and software engineering challenges, which we document in this paper. In particular, we present an algorithm for the construction of a discrete gradient that complies to the critical points extracted in the piecewise-linear setting. This algorithm guarantees a combinatorial consistency across the topological abstractions supported by TTK, and importantly, a unified implementation of topological data simplification for multi-scale exploration and analysis. We also present a cached triangulation data structure, that supports time efficient and generic traversals, which self-adjusts its memory usage on demand for input simplicial meshes and which implicitly emulates a triangulation for regular grids with no memory overhead. Finally, we describe an original software architecture, which guarantees memory efficient and direct accesses to TTK features, while still allowing for researchers powerful and easy bindings and extensions. TTK is open source (BSD license) and its code, online documentation and video tutorials are available on TTK?s website [108].",https://topology-tool-kit.github.io/,https://github.com/topology-tool-kit/ttk,,,youtube Hn8w0V-jHgw,,2018,2017,SciVis,207,Wednesday,Topology-based methods,,2:40:00 PM,3:00:00 PM
openaccessvis.csv,SciVis,TVCG,TopoAngler: Interactive Topology-based Extraction of Fishes,,"Alexander Bock, Harish Doraiswamy, Adam Summers, Claudio Silva",https://alexanderbock.github.io/papers/vis17-bock-topoangler.pdf,"We present TopoAngler, a visualization framework that enables an interactive user-guided segmentation of fishes contained in a micro-CT scan. The inherent noise in the CT scan coupled with the often disconnected (and sometimes broken) skeletal structure of fishes makes an automatic segmentation of the volume impractical. To overcome this, our framework combines techniques from computational topology with an interactive visual interface, enabling the human-in-the-loop to effectively extract fishes from the volume. In the first step, the join tree of the input is used to create a hierarchical segmentation of the volume. Through the use of linked views, the visual interface then allows users to interactively explore this hierarchy, and gather parts of individual fishes into a coherent sub-volume, thus reconstructing entire fishes. Our framework was primarily developed for its application to CT scans of fishes, generated as part of the ScanAllFish project, through close collaboration with their lead scientist. However, we expect it to also be applicable in other biological applications where a single data set contains multiple specimen; a common routine that is now widely followed in laboratories to increase throughput of expensive CT scanners.",,,,,youtube gz22DjMRJjk,,2018,2017,SciVis,207,Wednesday,Topology-based methods,,2:00:00 PM,2:20:00 PM
openaccessvis.csv,SciVis,TVCG,Uncertainty Visualization Using Copula-Based Analysis in Mixed Distribution Models,,"Subhashis Hazarika, Ayan Biswas, Han-Wei Shen",,,,,,,,,2018,2017,SciVis,207,Tuesday,"Mix: Foundations, uncertainty, particles",,2:40:00 PM,3:00:00 PM
openaccessvis.csv,SciVis,TVCG,Visualization Multi-Pipeline for Communicating Biology,,"Peter Mindek, David Kou?il, Johannes Sorger, Daniel Toloudis, Blair Lyons, Graham Johnson, M. Eduard Gr”ller, Ivan Viola",https://www.cg.tuwien.ac.at/research/publications/2017/mindek-2017-marion/mindek-2017-marion-Paper.pdf,"We propose a system to facilitate biology communication by developing a pipeline to support the instructional visualization of heterogeneous biological data on heterogeneous user-devices. Discoveries and concepts in biology are typically summarized with illustrations assembled manually from the interpretation and application of heterogenous data. The creation of such illustrations is time consuming, which makes it incompatible with frequent updates to the measured data as new discoveries are made. Illustrations are typically non-interactive, and when an illustration is updated, it still has to reach the user. Our system is designed to overcome these three obstacles. It supports the integration of heterogeneous datasets, reflecting the knowledge that is gained from different data sources in biology. After pre-processing the datasets, the system transforms them into visual representations as inspired by scientific illustrations. As opposed to traditional scientific illustration these representations are generated in real-time - they are interactive. The code generating the visualizations can be embedded in various software environments. To demonstrate this, we implemented both a desktop application and a remote-rendering server in which the pipeline is embedded. The remote-rendering server supports multi-threaded rendering and it is able to handle multiple users simultaneously. This scalability to different hardware environments, including multi-GPU setups, makes our system useful for efficient public dissemination of biological discoveries.",,,,,video https://www.cg.tuwien.ac.at/research/publications/2017/mindek-2017-marion/mindek-2017-marion-Preview.avi,,2018,2017,SciVis,207,Thursday,Visualization in Biology and Medicine,,9:30:00 AM,9:50:00 AM
openaccessvis.csv,SciVis,TVCG,Decision Graph Embedding for High-Resolution Manometry Diagnosis,,"Julian Kreiser, Alexander Hann, Eugen Zizer, Timo Ropinski",,,,,,,,,2018,2017,SciVis,207,Thursday,Visualization in Biology and Medicine,,9:10:00 AM,9:30:00 AM
openaccessvis2018.csv,VAST,TVCG,TPFlow: Progressive Partition and Multidimensional Pattern Extraction for Large-Scale Spatio-Temporal Data Analysis,J),"Dongyu Liu, Panpan Xu, Liu Ren",https://lliquid.github.io/homepage/files/draft_vis18_st.pdf,"Consider a multi-dimensional spatio-temporal (ST) dataset where each entry is a numerical measure defined by the corresponding temporal, spatial and other domain-specific dimensions. A typical approach to explore such data utilizes interactive visualizations with multiple coordinated views. Each view displays the aggregated measures along one or two dimensions. By brushing on the views, analysts can obtain detailed information. However, this approach often cannot provide sufficient guidance for analysts to identify patterns hidden within subsets of data. Without a priori hypotheses, analysts need to manually select and iterate through different slices to search for patterns, which can be a tedious and lengthy process. In this work, we model multidimensional ST data as tensors and propose a novel piecewise rank-one tensor decomposition algorithm which supports automatically slicing the data into homogeneous partitions and extracting the latent patterns in each partition for comparison and visual summarization. The algorithm optimizes a quantitative measure about how faithfully the extracted patterns visually represent the original data. Based on the algorithm we further propose a visual analytics framework that supports a top-down, progressive partitioning workflow for level-of-detail multidimensional ST data exploration. We demonstrate the general applicability and effectiveness of our technique on three datasets from different application domains: regional sales trend analysis, customer traffic analysis in department stores, and taxi trip analysis with origin-destination (OD) data. We further interview domain experts to verify the usability of the prototype.",,,,,video https://lliquid.github.io/homepage/files/video_vast18_tpflow_1920x1080_v7.mp4,10.1109/tvcg.2018.2865018,2018,2018,Other,"Hall 1, Section C+D",Tuesday,VIS Awards & Best Papers,2022-10-23,10:00:00 AM,10:20:00 AM
openaccessvis2018.csv,InfoVis,TVCG,Formalizing Visualization Design Knowledge as Constraints: Actionable and Extensible Models in Draco,J),"Dominik Moritz, Chenglong Wang, Greg L. Nelson, Halden Lin, Adam M. Smith, Bill Howe, Jeffrey Heer",https://osf.io/3eg9c/,"There exists a gap between visualization design guidelines and their application in visualization tools. While empirical studies can provide design guidance, we lack a formal framework for representing design knowledge, integrating results across studies, and applying this knowledge in automated design tools that promote effective encodings and facilitate visual exploration. We propose modeling visualization design knowledge as a collection of constraints, in conjunction with a method to learn weights for soft constraints from experimental data. Using constraints, we can take theoretical design knowledge and express it in a concrete, extensible, and testable form: the resulting models can recommend visualization designs and can easily be augmented with additional constraints or updated weights. We implement our approach in Draco, a constraint-based system based on Answer Set Programming (ASP). We demonstrate how to construct increasingly sophisticated automated visualization design systems, including systems based on weights learned directly from the results of graphical perception experiments.",https://medium.com/@uwdata/draco-representing-applying-learning-visualization-design-guidelines-64ce20287e9d,https://uwdata.github.io/draco/,,,vimeo 289784521,10.1109/tvcg.2018.2865240,2018,2018,Other,"Hall 1, Section C+D",Tuesday,VIS Awards & Best Papers,2022-10-23,10:20:00 AM,10:40:00 AM
openaccessvis2018.csv,SciVis,TVCG,Deadeye: A Novel Preattentive Visualization Technique Based on Dichoptic Presentation,J),"Andrey Krekhov, Jens Krueger",,,,,,,vimeo 290325240,10.1109/tvcg.2018.2864498,2018,2018,Other,"Hall 1, Section C+D",Tuesday,VIS Awards & Best Papers,2022-10-23,10:40:00 AM,11:00:00 AM
openaccessvis2018.csv,VAST,TVCG,Evaluating Multi-Dimensional Visualizations for Understanding Fuzzy Clusters,J),"Ying Zhao, Feng Luo, Minghui Chen, Yingchao Wang, Jiazhi Xia, Fangfang Zhou, Yunhai Wang, Yi Chen, Wei Chen",http://www.cad.zju.edu.cn/home/vagblog/VAG_Work/Fuzzy%20Clusters.pdf,"Fuzzy clustering assigns a probability of membership for a datum to a cluster, which veritably reflects real-world clustering scenarios but significantly increases the complexity of understanding fuzzy clusters. Many studies have demonstrated that visualization techniques for multi-dimensional data are beneficial to understand fuzzy clusters. However, no empirical evidence exists on the effectiveness and efficiency of these visualization techniques in solving analytical tasks featured by fuzzy clusters. In this paper, we conduct a controlled experiment to evaluate the ability of fuzzy clusters analysis to use four multi-dimensional visualization techniques, namely, parallel coordinate plot, scatterplot matrix, principal component analysis, and Radviz. First, we define the analytical tasks and their representative questions specific to fuzzy clusters analysis. Then, we design objective questionnaires to compare the accuracy, time, and satisfaction in using the four techniques to solve the questions. We also design subjective questionnaires to collect the experience of the volunteers with the four techniques in terms of ease of use, informativeness, and helpfulness. With a complete experiment process and a detailed result analysis, we test against four hypotheses that are formulated on the basis of our experience, and provide instructive guidance for analysts in selecting appropriate and efficient visualization techniques to analyze fuzzy clusters.",,,,,vimeo 289787891,10.1109/tvcg.2018.2865020,2018,2018,VAST,"Hall 1, Section C",Tuesday,Evaluation and Theory,2022-10-23,2:20:00 PM,2:40:00 PM
openaccessvis2018.csv,VAST,VAST,The Effect of Proximity in Social Data Charts on Perceived Unity,C),"Marlen Promann, Sabine Brunswicker",,,,,,,vimeo 289787716,,2018,2018,VAST,"Hall 1, Section C",Tuesday,Evaluation and Theory,2022-10-23,2:40:00 PM,3:00:00 PM
openaccessvis2018.csv,VAST,TVCG,Futzing and Moseying: Interviews with Professional Data Analysts on Exploration Practices,J),"Sara Alspaugh, Nava Zokaei, Andrea Liu, Cindy Jin, Marti Hearst",http://people.ischool.berkeley.edu/~hearst/papers/vast2018.pdf,"We report the results of interviewing thirty professional data analysts working in a range of industrial, academic, and regulatory environments. This study focuses on participants' descriptions of exploratory activities and tool usage in these activities. Highlights of the ndings include: distinctions between exploration as a precursor to more directed analysis versus truly open-ended exploration; conrmation that some analysts see ""finding something interesting"" as a valid goal of data exploration while others explicitly disavow this goal; conicting views about the role of intelligent tools in data exploration; and pervasive use of visualization for exploration, but with only a subset using direct manipulation interfaces. These findings provide guidelines for future tool development, as well as a better understanding of the meaning of the term ""data exploration"" based on the words of practitioners ""in the wild.""",,,,,vimeo 289787961,10.1109/TVCG.2018.2865040,2018,2018,VAST,"Hall 1, Section C",Tuesday,Evaluation and Theory,2022-10-23,3:00:00 PM,3:20:00 PM
openaccessvis2018.csv,VAST,VAST,The Effect of Semantic Interaction on Foraging in Text Analysis,C),"John Wenskovitch, Lauren Bradel, Michelle Dowling, Leanna House, Chris North",https://infovis.cs.vt.edu/sites/default/files/effect-semantic-interaction.pdf,"Completing text analysis tasks is a continuous sensemaking loop of foraging for information and incrementally synthesizing it into hypotheses. Past research has shown the advantages of using spatial workspaces as a means for synthesizing information through externalizing hypotheses and creating spatial schemas. However, spatializing the entirety of datasets becomes prohibitive as the number of documents available to the analysts grows, particularly when only a small subset are relevant to the task at hand. StarSPIRE is a visual analytics tool designed to explore collections of documents, leveraging users? semantic interactions to steer (1) a synthesis model that aids in document layout, and (2) a foraging model to automatically retrieve new relevant information. In contrast to traditional keyword search foraging (KSF), ?semantic interaction foraging? (SIF) occurs as a result of the user?s synthesis actions. To quantify the value of semantic interaction foraging, we use StarSPIRE to evaluate its utility for an intelligence analysis sensemaking task. Semantic interaction foraging accounted for 26% of useful documents found, and it also resulted in increased synthesis interactions and improved sensemaking task performance by users in comparison to only using keyword search.",,,,,vimeo 289787752,,2018,2018,VAST,"Hall 1, Section C",Tuesday,Evaluation and Theory,2022-10-23,3:20:00 PM,3:40:00 PM
openaccessvis2018.csv,VAST,TVCG,An Information-Theoretic Approach to the Cost-benefit Analysis of Visualization in Virtual Environments,J),"Min Chen, Kelly Gaither, Nigel John, Brian McCann",,,,,,,vimeo 289787910,10.1109/TVCG.2018.2865025,2018,2018,VAST,"Hall 1, Section C",Tuesday,Evaluation and Theory,2022-10-23,3:40:00 PM,4:00:00 PM
openaccessvis2018.csv,InfoVis,TVCG,Shape-preserving Star Coordinates,J),"Vladimir Molchanov, Lars Linsen",,,,,,,vimeo 289785145,10.1109/tvcg.2018.2865118,2018,2018,InfoVis,"Hall 1, Section D",Tuesday,Multiple Dimensions,2022-10-23,2:20:00 PM,2:40:00 PM
openaccessvis2018.csv,TVCG,TVCG,Using Dashboard Networks to Visualize Multiple Patient Histories: A Design Study on Post-operative Prostate Cancer,T),"Jrgen Bernard, David Sessler, J”rn Kohlhammer, Roy A. Ruddle",http://eprints.whiterose.ac.uk/128739/1/bernard-ieee-tvcg-dashboard-networks.pdf,"In this design study, we present a visualization technique that segments patients' histories instead of treating them as raw event sequences, aggregates the segments using criteria such as the whole history or treatment combinations, and then visualizes the aggregated segments as static dashboards that are arranged in a dashboard network to show longitudinal changes. The static dashboards were developed in nine iterations, to show 15 important attributes from the patients' histories. The final design was evaluated with five non-experts, five visualization experts and four medical experts, who successfully used it to gain an overview of a 2,000 patient dataset, and to make observations about longitudinal changes and differences between two cohorts. The research represents a step-change in the detail of large-scale data that may be successfully visualized using dashboards, and provides guidance about how the approach may be generalized.",,,,,vimeo 289789053,10.1109/tvcg.2018.2803829,2018,2018,InfoVis,"Hall 1, Section D",Tuesday,Multiple Dimensions,2022-10-23,2:40:00 PM,3:00:00 PM
openaccessvis2018.csv,InfoVis,TVCG,SRVis: Towards Better Spatial Integration in Ranking Visualization,J),"Di Weng, Ran Chen, Zikun Deng, Feiran Wu, Jingmin Chen, Yingcai Wu",http://zjuvis.org/files/srvis.pdf,"Interactive ranking techniques have substantially promoted analysts' ability in making judicious and informed decisions effectively based on multiple criteria. However, the existing techniques cannot satisfactorily support the analysis tasks involved in ranking large-scale spatial alternatives, such as selecting optimal locations for chain stores, where the complex spatial contexts involved are essential to the decision-making process. Limitations observed in the prior attempts of integrating rankings with spatial contexts motivate us to develop a context-integrated visual ranking technique. Based on a set of generic design requirements we summarized by collaborating with domain experts, we propose SRVis, a novel spatial ranking visualization technique that supports efficient spatial multi-criteria decision-making processes by addressing three major challenges in the aforementioned context integration, namely, a) the presentation of spatial rankings and contexts, b) the scalability of rankings' visual representations, and c) the analysis of context-integrated spatial rankings. Specifically, we encode massive rankings and their cause with scalable matrix-based visualizations and stacked bar charts based on a novel two-phase optimization framework that minimizes the information loss, and the flexible spatial filtering and intuitive comparative analysis are adopted to enable the in-depth evaluation of the rankings and assist users in selecting the best spatial alternative. The effectiveness of the proposed technique has been evaluated and demonstrated with an empirical study of optimization methods, two case studies, and expert interviews.",https://srvis.zjuvis.org/,,,,vimeo 289784783,10.1109/TVCG.2018.2865126,2018,2018,InfoVis,"Hall 1, Section D",Tuesday,Multiple Dimensions,2022-10-23,3:00:00 PM,3:20:00 PM
openaccessvis2018.csv,InfoVis,TVCG,A Declarative Rendering Model for Multiclass Density Maps,J),"Jaemin Jo, Fr‚d‚ric Vernier, Pierre Dragicevic, Jean-Daniel Fekete",https://hal.inria.fr/hal-01848427/document,"Multiclass maps are scatterplots, multidimensional projections, or thematic geographic maps where data points have a categorical attribute in addition to two quantitative attributes. This categorical attribute is often rendered using shape or color, which does not scale when overplotting occurs. When the number of data points increases, multiclass maps must resort to data aggregation to remain readable. We present multiclass density maps: multiple 2D histograms computed for each of the category values. Multiclass density maps are meant as a building block to improve the expressiveness and scalability of multiclass map visualization. In this article, we first present a short survey of aggregated multiclass maps, mainly from cartography. We then introduce a declarative model?a simple yet expressive JSON grammar associated with visual semantics?that specifies a wide design space of visualizations for multiclass density maps. Our declarative model is expressive and can be efficiently implemented in visualization front-ends such as modern web browsers. Furthermore, it can be reconfigured dynamically to support data exploration tasks without recomputing the raw data. Finally, we demonstrate how our model can be used to reproduce examples from the past and support exploring data at scale.",https://jaeminjo.github.io/Multiclass-Density-Maps/,https://github.com/e-/Multiclass-Density-Maps,,,vimeo 289785026,10.1109/TVCG.2018.2865141,2018,2018,InfoVis,"Hall 1, Section D",Tuesday,Multiple Dimensions,2022-10-23,3:20:00 PM,3:40:00 PM
openaccessvis2018.csv,InfoVis,TVCG,DimReader: Axis lines that explain non-linear projections,J),"Rebecca Faust, David Glickenstein, Carlos Scheidegger",https://arxiv.org/pdf/1710.00992.pdf,"Non-linear dimensionality reduction (NDR) methods such as LLE and t-SNE are popular with visualization researchers and experienced data analysts, but present serious problems of interpretation. In this paper, we present DimReader, a technique that recovers readable axes from such techniques. DimReader is based on analyzing infinitesimal perturbations of the dataset with respect to variables of interest. The perturbations define exactly how we want to change each point in the original dataset and we measure the effect that these changes have on the projection. The recovered axes are in direct analogy with the axis lines (grid lines) of traditional scatterplots. We also present methods for discovering perturbations on the input data that change the projection the most. The calculation of the perturbations is efficient and easily integrated into programs written in modern programming languages. We present results of DimReader on a variety of NDR methods and datasets both synthetic and real-life, and show how it can be used to compare different NDR methods. Finally, we discuss limitations of our proposal and situations where further research is needed.",,,,,vimeo 289784574,10.1109/tvcg.2018.2865194,2018,2018,InfoVis,"Hall 1, Section D",Tuesday,Multiple Dimensions,2022-10-23,3:40:00 PM,4:00:00 PM
openaccessvis2018.csv,SciVis,TVCG,Recirculation Surfaces for Flow Visualization,J),"Thomas Wilde, Christian R”ssl, Holger Theisel",http://vc.cs.ovgu.de/files/publications/2018/Wilde_2018_VISa.pdf,"We present a formal approach to the visual analysis of recirculation in flows by introducing recirculation surfaces for 3D unsteady flow fields. Recirculation surfaces are the loci where massless particle integration returns to its starting point after some variable, finite integration. We give a rigorous definition of recirculation surfaces as 2-manifolds embedded in 5D space and study their properties. Based on this we construct an algorithm for their extraction, which searches for intersections of a recirculation surface with lines defined in 3D. This reduces the problem to a repeated search for critical points in 3D vector fields. We provide a uniform sampling of the search space paired with a surface reconstruction and visualize results. This way, we present the first algorithm for a comprehensive feature extraction in the 5D flow map of a 3D flow. The problem of finding isolated closed orbits in steady vector fields occurs as a special case of recirculation surfaces. This includes isolated closed orbits with saddle behavior. We show recirculation surfaces for a number of artificial and real flow data sets.",,,,,video http://isgwww.cs.uni-magdeburg.de/visual/files/publications/2018/Wilde_2018_VISa.mp4,10.1109/tvcg.2018.2864813,2018,2018,SciVis,Estrel Hall A+B,Tuesday,Flow Features,2022-10-23,2:20:00 PM,2:40:00 PM
openaccessvis2018.csv,SciVis,TVCG,Objective Vortex Corelines of Finite-sized Objects in Fluid Flows,J),"Tobias Gnther, Holger Theisel",https://isgwww.cs.uni-magdeburg.de/visual/files/publications/2018/Guenther_2018_VIS.pdf,"Vortices are one of the most-frequently studied phenomena in fluid flows. The center of the rotating motion is called the vortex coreline and its successful detection strongly depends on the choice of the reference frame. The optimal frame moves with the center of the vortex, which incidentally makes the observed fluid flow steady and thus standard vortex coreline extractors such as Sujudi-Haimes become applicable. Recently, an objective optimization framework was proposed that determines a near-steady reference frame for tracer particles. In this paper, we extend this technique to the detection of vortex corelines of inertial particles. An inertial particle is a finite-sized object that is carried by a fluid flow. In contrast to the usual tracer particles, they do not move tangentially with the flow, since they are subject to gravity and exhibit mass-dependent inertia. Their particle state is determined by their position and own velocity, which makes the search for the optimal frame a high-dimensional problem. We demonstrate in this paper that the objective detection of an inertial vortex coreline can be reduced in 2D to a critical point search in 2D. For 3D flows, however, the vortex coreline criterion remains a parallel vectors condition in 6D. To detect the vortex corelines we propose a recursive subdivision approach that is tailored to the underlying structure of the 6D vectors. The resulting algorithm is objective, and we demonstrate the vortex coreline extraction in a number of 2D and 3D vector fields.",,,,,video http://isgwww.cs.uni-magdeburg.de/visual/files/publications/2018/Guenther_2018_VIS.mp4,10.1109/TVCG.2018.2864828,2018,2018,SciVis,Estrel Hall A+B,Tuesday,Flow Features,2022-10-23,2:40:00 PM,3:00:00 PM
openaccessvis2018.csv,TVCG,TVCG,Towards High-quality Visualization of Superfluid Vortices,T),"Yulong Guo, Xiaopei Liu, Chi Xiong, Xuemiao Xu, Chi-Wing Fu",https://arxiv.org/pdf/1710.02630.pdf,"Superfluidity is a special state of matter exhibiting macroscopic quantum phenomena and acting like a fluid with zero viscosity. In such a state, superfluid vortices exist as phase singularities of the model equation with unique distributions. This paper presents novel techniques to aid the visual understanding of superfluid vortices based on the state-of-the-art non-linear Klein-Gordon equation, which evolves a complex scalar field, giving rise to special vortex lattice/ring structures with dynamic vortex formation, reconnection, and Kelvin waves, etc. By formulating a numerical model with theoretical physicists in superfluid research, we obtain high-quality superfluid flow data sets without noise-like waves, suitable for vortex visualization. By further exploring superfluid vortex properties, we develop a new vortex identification and visualization method: a novel mechanism with velocity circulation to overcome phase singularity and an orthogonal-plane strategy to avoid ambiguity. Hence, our visualizations can help reveal various superfluid vortex structures and enable domain experts for related visual analysis, such as the steady vortex lattice/ring structures, dynamic vortex string interactions with reconnections and energy radiations, where the famous Kelvin waves and decaying vortex tangle were clearly observed. These visualizations have assisted physicists to verify the superfluid model, and further explore its dynamic behavior more intuitively.",,,,,youtube TlEQbPSbYTQ ,10.1109/TVCG.2017.2719684,2017,2018,SciVis,Estrel Hall A+B,Tuesday,Flow Features,2022-10-23,3:00:00 PM,3:20:00 PM
openaccessvis2018.csv,TVCG,TVCG,Semantic Flow Graph: A Framework for Discovering Object Relationships in Flow Fields,T),"Jun Tao, Chaoli Wang, Nitesh Chawla, Lei Shi, Seung Hyun Kim",https://www3.nd.edu/~cwang11/research/tvcg18-sfg.pdf,"Visual exploration of flow fields is important for studying dynamic systems. We introduce semantic flow graph (SFG), a novel graph representation and interaction framework that enables users to explore the relationships among key objects (i.e., field lines, features, and spatiotemporal regions) of both steady and unsteady flow fields. The objects and their relationships are organized as a heterogeneous graph. We assign each object a set of attributes, based on which a semantic abstraction of the heterogeneous graph is generated. This semantic abstraction is SFG. We design a suite of operations to explore the underlying flow fields based on this graph representation and abstraction mechanism. Users can flexibly reconfigure SFG to examine the relationships among groups of objects at different abstraction levels. Three linked views are developed to display SFG, its node split criteria and history, and the objects in the spatial volume. For simplicity, we introduce SFG construction and exploration for steady flow fields with critical points being the only features. Then we demonstrate that SFG can be naturally extended to deal with unsteady flow fields and multiple types of features. We experiment with multiple data sets and conduct an expert evaluation to demonstrate the effectiveness of our approach. ",,,,,video http://www.nd.edu/~cwang11/research/tvcg18-sfg.wmv,10.1109/tvcg.2017.2773071,2018,2018,SciVis,Estrel Hall A+B,Tuesday,Flow Features,2022-10-23,3:20:00 PM,3:40:00 PM
openaccessvis2018.csv,VAST,TVCG,Visual Abstraction of the Large Scale Geospatial Origin-Destination Movement Data,J),"Zhiguang Zhou, Linhao Meng, Cheng Tang, Ying Zhao, Zhiyong Guo, Miaoxin Hu, Wei Chen",,,,,,,vimeo 289787224,10.1109/TVCG.2018.2864503,2018,2018,VAST,"Hall 1, Section C",Tuesday,Spatio-Temporal Data,2022-10-23,4:20:00 PM,4:40:00 PM
openaccessvis2018.csv,VAST,TVCG,Analysis of Flight Variability: a Systematic Approach,J),"Natalia Andrienko, Gennady Andrienko, Jose Manuel Cordero Garcia, David Scarlatti",http://openaccess.city.ac.uk/20334/1/analysis-flight-variability.pdf,"In movement data analysis, there exists a problem of comparing multiple trajectories of moving objects to common or distinct reference trajectories. We introduce a general conceptual framework for comparative analysis of trajectories and an analytical procedure, which consists of (1) finding corresponding points in pairs of trajectories, (2) computation of pairwise difference measures, and (3) interactive visual analysis of the distributions of the differences with respect to space, time, set of moving objects, trajectory structures, and spatio-temporal context. We propose a combination of visualisation, interaction, and data transformation techniques supporting the analysis and demonstrate the use of our approach for solving a challenging problem from the aviation domain.",,,,,vimeo 289787283,10.1109/TVCG.2018.2864811,2018,2018,VAST,"Hall 1, Section C",Tuesday,Spatio-Temporal Data,2022-10-23,4:40:00 PM,5:00:00 PM
openaccessvis2018.csv,VAST,TVCG,ForVizor: Visualizing Spatio-Temporal Team Formations in Soccer,J),"Yingcai Wu, Xiao Xie, Jiachen Wang, Dazhen Deng, Hongye Liang, Hui Zhang, Shoubin Cheng, Wei Chen",http://zjuvis.org/files/forvizor.pdf,"Regarded as a high-level tactic in soccer, a team formation assigns players different tasks and indicates their active regions on the pitch, thereby influencing the team performance significantly. Analysis of formations in soccer has become particularly indispensable for soccer analysts. However, formations of a team are intrinsically time-varying and contain inherent spatial information. The spatio-temporal nature of formations and other characteristics of soccer data, such as multivariate features, make analysis of formations in soccer a challenging problem. In this study, we closely worked with domain experts to characterize domain problems of formation analysis in soccer and formulated several design goals. We design a novel spatio-temporal visual representation of changes in team formation, allowing analysts to visually analyze the evolution of formations and track the spatial flow of players within formations over time. Based on the new design, we further design and develop ForVizor, a visual analytics system, which empowers users to track the spatio-temporal changes in formation and understand how and why such changes occur. With ForVizor, domain experts conduct formation analysis of two games. Analysis results with insights and useful feedback are summarized in two case studies.",,,,,vimeo 289787566,10.1109/tvcg.2018.2865041,2018,2018,VAST,"Hall 1, Section C",Tuesday,Spatio-Temporal Data,2022-10-23,5:00:00 PM,5:20:00 PM
openaccessvis2018.csv,VAST,TVCG,MotionRugs: Visualizing Collective Trends in Space and Time,J),"Juri Buchmuller, Dominik Jackle, Eren Cakmak, Ulrik Brandes, Daniel Keim",https://bib.dbvis.de/uploadedFiles/MotionRugsPreprint.pdf,"Understanding the movement patterns of collectives, such as flocks of birds or fish swarms, is an interesting open research question. The collectives are driven by mutual objectives or react to individual direction changes and external influence factors and stimuli. The challenge in visualizing collective movement data is to show space and time of hundreds of movements at the same time to enable the detection of spatiotemporal patterns. In this paper, we propose MotionRugs, a novel space efficient technique for visualizing moving groups of entities. Building upon established space-partitioning strategies, our approach reduces the spatial dimensions in each time step to a one-dimensional ordered representation of the individual entities. By design, MotionRugs provides an overlap-free, compact overview of the development of group movements over time and thus, enables analysts to visually identify and explore group-specific temporal patterns. We demonstrate the usefulness of our approach in the field of fish swarm analysis and report on initial feedback of domain experts from the field of collective behavior.",,https://github.com/jbuchmueller/motionrugs,,,youtube xSewCmdgN40,10.1109/tvcg.2018.2865049,2018,2018,VAST,"Hall 1, Section C",Tuesday,Spatio-Temporal Data,2022-10-23,5:20:00 PM,5:40:00 PM
openaccessvis2018.csv,VAST,TVCG,Identification of Temporally Varying Areas of Interest in Long Duration Eye Tracking Data Sets,J),"Prithiviraj Kaliappa Gounder Muthumanickam, Katerina Vrotsou, Aida Nordman, Jimmy Johansson, Matthew Cooper",,,,,,,vimeo 289787582,10.1109/TVCG.2018.2865042,2018,2018,VAST,"Hall 1, Section C",Tuesday,Spatio-Temporal Data,2022-10-23,5:40:00 PM,6:00:00 PM
openaccessvis2018.csv,InfoVis,TVCG,A Heuristic Approach to Value-Driven Evaluation of Visualizations,J),"Emily Wall, Meeshu Agnihotri, Laura Matzen, Kristin Divis, Michael Haass, Alex Endert, John Stasko",https://www.cc.gatech.edu/~ewall9/media/papers/ValueVIS2018.pdf,"Recently, an approach for determining the value of a visualization was proposed, one moving beyond simple measurements of task accuracy and speed. The value equation contains components for the time savings a visualization provides, the insights and insightful questions it spurs, the overall essence of the data it conveys, and the confidence about the data and its domain it inspires. This articulation of value is purely descriptive, however, providing no actionable method of assessing a visualization's value. In this work, we create a heuristic-based evaluation methodology to accompany the value equation for assessing interactive visualizations. We refer to the methodology colloquially as ICE-T, based on an anagram of the four value components. Our approach breaks the four components down into guidelines, each of which is made up of a small set of low-level heuristics. Evaluators who have knowledge of visualization design principles then assess the visualization with respect to the heuristics. We conducted an initial trial of the methodology on three interactive visualizations of the same data set, each evaluated by 15 visualization experts. We found that the methodology showed promise, obtaining consistent ratings across the three visualizations and mirroring judgments of the utility of the visualizations by instructors of the course in which they were developed.",,,,,vimeo 289784928,10.1109/tvcg.2018.2865146,2018,2018,InfoVis,"Hall 1, Section D",Tuesday,Evaluation & Applications,2022-10-23,4:20:00 PM,4:40:00 PM
openaccessvis2018.csv,InfoVis,TVCG,Patterns and Pace: Quantifying Diverse Exploration Behavior with Visualizations on the Web,J),"Mi Feng, Evan Peck, Lane Harrison",https://osf.io/9wqgk/,"The diverse and vibrant ecosystem of interactive visualizations on the web presents an opportunity for researchers and practitioners to observe and analyze how everyday people interact with data visualizations. However, existing metrics of visualization interaction behavior used in research do not fully reveal the breadth of peoples' open-ended explorations with visualizations. One possible way to address this challenge is to determine high-level goals for visualization interaction metrics, and infer corresponding features from user interaction data that characterize different aspects of peoples' explorations of visualizations. In this paper, we address this challenge by identifying needs for visualization behavior analysis, and by developing corresponding candidate features that can be inferred from users' interaction data with visualization. We then propose metrics that capture novel aspects of peoples' open-ended explorations, including exploration uniqueness and exploration pacing. We evaluate these metrics along with four other metrics recently proposed in visualization literature by applying them to interaction data from prior visualization studies. The results of these evaluations suggest that these new metrics 1) reveal new characteristics of peoples' use of visualizations, 2) can be used to evaluate statistical differences between visualization designs, and 3) are statistically independent of prior metrics used in visualization research. We discuss implications of these results for future studies, including the potential for applying these metrics in visualization interaction analysis, as well as emerging challenges in developing a design space of metrics for visualization engagement.",,,https://osf.io/dx43q/wiki/home/,,vimeo 289785167,10.1109/tvcg.2018.2865117,2018,2018,InfoVis,"Hall 1, Section D",Tuesday,Evaluation & Applications,2022-10-23,4:40:00 PM,5:00:00 PM
openaccessvis2018.csv,TVCG,TVCG,Lineage: Visualizing Multivariate Clinical Data in Genealogy Graphs,T),"Carolina Nobre, Nils Gehlenborg, Hilary Coon, Alexander Lex",https://www.biorxiv.org/content/early/2018/02/27/128579,"The majority of diseases that are a significant challenge for public and individual heath are caused by a combination of hereditary and environmental factors. In this paper we introduce Lineage, a novel visual analysis tool designed to support domain experts who study such multifactorial diseases in the context of genealogies. Incorporating familial relationships between cases with other data can provide insights into shared genomic variants and shared environmental exposures that may be implicated in such diseases. We introduce a data and task abstraction, and argue that the problem of analyzing such diseases based on genealogical, clinical, and genetic data can be mapped to a multivariate graph visualization problem. The main contribution of our design study is a novel visual representation for tree-like, multivariate graphs, which we apply to genealogies and clinical data about the individuals in these families. We introduce data-driven aggregation methods to scale to multiple families. By designing the genealogy graph layout to align with a tabular view, we are able to incorporate extensive, multivariate attributes in the analysis of the genealogy without cluttering the graph. We validate our designs by conducting case studies with our domain collaborators.",,https://github.com/caleydo/lineage,,,vimeo 289789223,10.1109/tvcg.2018.2811488,2018,2018,InfoVis,"Hall 1, Section D",Tuesday,Evaluation & Applications,2022-10-23,5:00:00 PM,5:20:00 PM
openaccessvis2018.csv,InfoVis,TVCG,IDMVis: Temporal Event Sequence Visualization for Type 1 Diabetes Treatment Decision Support,J),"Yixuan Zhang, Kartik Chanana, Cody Dunne",https://github.com/zjanice/PHI/blob/master/IDMVis_IEEEVIS18_preprint.pdf,"Type 1 diabetes is a chronic, incurable autoimmune disease affecting millions of Americans in which the body stops producing insulin and blood glucose levels rise. The goal of intensive diabetes management is to lower average blood glucose through frequent adjustments to insulin protocol, diet, and behavior. Manual logs and medical device data are collected by patients, but these multiple sources are presented in disparate visualization designs to the clinician?making temporal inference difficult. We conducted a design study over 18 months with clinicians performing intensive diabetes management. We present a data abstraction and novel hierarchical task abstraction for this domain. We also contribute IDMVis: a visualization tool for temporal event sequences with multidimensional, interrelated data. IDMVis includes a novel technique for folding and aligning records by dual sentinel events and scaling the intermediate timeline. We validate our design decisions based on our domain abstractions, best practices, and through a qualitative evaluation with six clinicians. The results of this study indicate that IDMVis accurately reflects the workflow of clinicians. Using IDMVis, clinicians are able to identify issues of data quality such as missing or conflicting data, reconstruct patient records when data is missing, differentiate between days with different patterns, and promote educational interventions after identifying discrepancies.",,https://github.com/VisDunneRight/IDMVis,,,vimeo 289785100,10.1109/tvcg.2018.2865076,2018,2018,InfoVis,"Hall 1, Section D",Tuesday,Evaluation & Applications,2022-10-23,5:20:00 PM,5:40:00 PM
openaccessvis2018.csv,TVCG,TVCG,Visualization of Cultural Heritage Collection Data: State of the Art and Future Challenges,T),"Florian Windhager, Paolo Federico, Gnther Schreder, Katrin Glinka, Marian D”rk, Silvia Miksch, Eva Mayr",https://uclab.fh-potsdam.de/wp/wp-content/uploads/tvcg2018.pdf,"After decades of digitization, large cultural heritage collections have emerged on the web, which contain massive stocks of content from galleries, libraries, archives, and museums. This increase in digital cultural heritage data promises new modes of analysis and increased levels of access for academic scholars and casual users alike. Going beyond the standard representations of search-centric and grid-based interfaces, a multitude of approaches has recently started to enable visual access to cultural collections, and to explore them as complex and comprehensive information spaces by the means of interactive visualizations. In contrast to conventional web interfaces, we witness a widening spectrum of innovative visualization types specially designed for rich collections from the cultural heritage sector. This new class of information visualizations gives rise to a notable diversity of interaction and representation techniques while lending currency and urgency to a discussion about principles such as serendipity, generosity, and criticality in connection with visualization design. With this survey, we review information visualization approaches to digital cultural heritage collections and reflect on the state of the art in techniques and design choices. We contextualize our survey with humanist perspectives on the field and point out opportunities for future research.",,,,,vimeo 289789286,10.1109/tvcg.2018.2830759,2018,2018,InfoVis,"Hall 1, Section D",Tuesday,Evaluation & Applications,2022-10-23,5:40:00 PM,6:00:00 PM
openaccessvis2018.csv,SciVis,TVCG,Interactive Visualization of RNA and DNA Structures,J),"Norbert Lindow, Daniel Baum, Morgan Leborgne, Hans-Christian Hege",,,,,,,vimeo 290325417,10.1109/tvcg.2018.2864507,2018,2018,SciVis,Estrel Hall A+B,Tuesday,Biological Applications,2022-10-23,4:20:00 PM,4:40:00 PM
openaccessvis2018.csv,SciVis,TVCG,Labels on Levels: Labeling of Multi-Scale Multi-Instance and Crowded 3D Biological Environments,J),"David Kou?il, Ladislav ?mol¡k, Barbora Kozl¡kov , Hsiang-Yun Wu, Graham Johnson, David S. Goodsell, Arthur Olson, Eduard Gr”ller, Ivan Viola",https://www.cg.tuwien.ac.at/research/publications/2019/kouril-2018-LoL/kouril-2018-LoL-paper.pdf,"Labeling is intrinsically important for exploring and understanding complex environments and models in a variety of domains. We present a method for interactive labeling of crowded 3D scenes containing very many instances of objects spanning multiple scales in size. In contrast to previous labeling methods, we target cases where many instances of dozens of types are present and where the hierarchical structure of the objects in the scene presents an opportunity to choose the most suitable level for each placed label. Our solution builds on and goes beyond labeling techniques in medical 3D visualization, cartography, and biological illustrations from books and prints. In contrast to these techniques, the main characteristics of our new technique are: 1) a novel way of labeling objects as part of a bigger structure when appropriate, 2) visual clutter reduction by labeling only representative instances for each type of an object, and a strategy of selecting those. The appropriate level of label is chosen by analyzing the scene?s depth buffer and the scene objects? hierarchy tree. We address the topic of communicating the parent-children relationship between labels by employing visual hierarchy concepts adapted from graphic design. Selecting representative instances considers several criteria tailored to the character of the data and is combined with a greedy optimization approach. We demonstrate the usage of our method with models from mesoscale biology where these two characteristics?multi-scale and multi-instance?are abundant, along with the fact that these scenes are extraordinarily dense.",,,,,vimeo 290325281,10.1109/tvcg.2018.2864491,2018,2018,SciVis,Estrel Hall A+B,Tuesday,Biological Applications,2022-10-23,4:40:00 PM,5:00:00 PM
openaccessvis2018.csv,SciVis,TVCG,Visualization of Large Molecular Trajectories,J),"David Duran Rosich, Pedro Hermosilla Casajus, Timo Ropinski, Barbora Kozl¡kov , ?lvar Vinacua, Pere-Pau V zquez",https://www.uni-ulm.de/fileadmin/website_uni_ulm/iui.inst.100/institut/Papers/viscom/2018/vazquez2018-largemol.pdf,"The analysis of protein-ligand interactions is a time-intensive task. Researchers have to analyze multiple physico-chemical properties of the protein at once and combine them to derive conclusions about the protein-ligand interplay. Typically, several charts are inspected, and 3D animations can be played side-by-side to obtain a deeper understanding of the data. With the advances in simulation techniques, larger and larger datasets are available, with up to hundreds of thousands of steps. Unfortunately, such large trajectories are very difficult to investigate with traditional approaches. Therefore, the need for special tools that facilitate inspection of these large trajectories becomes substantial. In this paper, we present a novel system for visual exploration of very large trajectories in an interactive and user-friendly way. Several visualization motifs are automatically derived from the data to give the user the information about interactions between protein and ligand. Our system offers specialized widgets to ease and accelerate data inspection and navigation to interesting parts of the simulation. The system is suitable also for simulations where multiple ligands are involved. We have tested the usefulness of our tool on a set of datasets obtained from protein engineers, and we describe the expert feedback.",,,,,vimeo 290328133,10.1109/tvcg.2018.2864851,2018,2018,SciVis,Estrel Hall A+B,Tuesday,Biological Applications,2022-10-23,5:00:00 PM,5:20:00 PM
openaccessvis2018.csv,TVCG,TVCG,Robust Tracing and Visualization of Heterogeneous Microvascular Networks,T),"Pavel Govyadinov, Tasha Womack, Jason L. Eriksen, Guoning Chen, David Mayerich",,,,,,,vimeo 289789196,10.1109/tvcg.2018.2818701,2018,2018,SciVis,Estrel Hall A+B,Tuesday,Biological Applications,2022-10-23,5:20:00 PM,5:40:00 PM
openaccessvis2018.csv,VAST,TVCG,Visual Analysis of the Temporal Evolution of Ensemble Forecast Sensitivities,J),"Alexander Kumpf, Marc Rautenhaus, Michael Riemer, Rdiger Westermann",http://www.in.tum.de/fileadmin/w00bws/cg/Research/Publications/2018/ESAWorkflow/Preprint_Correlation_wDOI.pdf,"Ensemble sensitivity analysis (ESA) has been established in the atmospheric sciences as a correlation-based approach to determine the sensitivity of a scalar forecast quantity computed by a numerical weather prediction model to changes in another model variable at a different model state. Its applications include determining the origin of forecast errors and placing targeted observations to improve future forecasts. We?a team of visualization scientists and meteorologists?present a visual analysis framework to improve upon current practice of ESA. We support the user in selecting regions to compute a meaningful target forecast quantity by embedding correlation-based grid-point clustering to obtain statistically coherent regions. The evolution of sensitivity features computed via ESA are then traced through time, by integrating a quantitative measure of feature matching into optical-flow-based feature assignment, and displayed by means of a swipe-path showing the geo-spatial evolution of the sensitivities. Visualization of the internal correlation structure of computed features guides the user towards those features robustly predicting a certain weather event. We demonstrate the use of our method by application to real-world 2D and 3D cases that occurred during the 2016 NAWDEX field campaign, showing the interactive generation of hypothesis chains to explore how atmospheric processes sensitive to each other are interrelated.",,,,,vimeo 289787833,10.1109/tvcg.2018.2864901,2018,2018,VAST,"Hall 1, Section C",Wednesday,Ensemble and Provenance,2022-10-24,9:00:00 AM,9:20:00 AM
openaccessvis2018.csv,VAST,TVCG,EnsembleLens: Ensemble-based Visual Exploration of Anomaly Detection Algorithms with Multidimensional Data,J),"Ke Xu, Meng Xia, Xing Mu, Yun Wang, Nan Cao",https://lukeluker.github.io/papers/EnsembleLens_VAST2018_KeXu.pdf,"The results of anomaly detection are sensitive to the choice of detection algorithms as they are specialized for different properties of data, especially for multidimensional data. Thus, it is vital to select the algorithm appropriately. To systematically select the algorithms, ensemble analysis techniques have been developed to support the assembly and comparison of heterogeneous algorithms. However, challenges remain due to the absence of the ground truth, interpretation, or evaluation of these anomaly detectors. In this paper, we present a visual analytics system named EnsembleLens that evaluates anomaly detection algorithms based on the ensemble analysis process. The system visualizes the ensemble processes and results by a set of novel visual designs and multiple coordinated contextual views to meet the requirements of correlation analysis, assessment and reasoning of anomaly detection algorithms. We also introduce an interactive analysis workflow that dynamically produces contextualized and interpretable data summaries that allow further refinements of exploration results based on user feedback. We demonstrate the effectiveness of EnsembleLens through a quantitative evaluation, three case studies with real-world data and interviews with two domain experts.",,,,,vimeo 289787339,10.1109/TVCG.2018.2864825,2018,2018,VAST,"Hall 1, Section C",Wednesday,Ensemble and Provenance,2022-10-24,9:20:00 AM,9:40:00 AM
openaccessvis2018.csv,TVCG,TVCG,Exploring Variability within Ensembles of Decadal Climate Predictions,T),"Christopher P. Kappe, Michael B”ttinger, Heike Leitte",,,,,,,vimeo 289789327,10.1109/tvcg.2018.2810919,2018,2018,VAST,"Hall 1, Section C",Wednesday,Ensemble and Provenance,2022-10-24,9:40:00 AM,10:00:00 AM
openaccessvis2018.csv,VAST,TVCG,KnowledgePearls: Provenance-Based Visualization Retrieval,J),"Holger Stitz, Samuel Gratzl, Harald Piringer, Thomas Zichner, Marc Streit",https://www.vrvis.at/publications/pdfs/PB-VRVis-2018-031.pdf,"Storing analytical provenance generates a knowledge base with a large potential for recalling previous results and guiding users in future analyses. However, without extensive manual creation of meta information and annotations by the users, search and retrieval of analysis states can become tedious. We present KnowledgePearls, a solution for efficient retrieval of analysis states that are structured as provenance graphs containing automatically recorded user interactions and visualizations. As a core component, we describe a visual interface for querying and exploring analysis states based on their similarity to a partial definition of a requested analysis state. Depending on the use case, this definition may be provided explicitly by the user by formulating a search query or inferred from given reference states. We explain our approach using the example of efficient retrieval of demographic analyses by Hans Rosling and discuss our implementation for a fast look-up of previous states. Our approach is independent of the underlying visualization framework. We discuss the applicability for visualizations which are based on the declarative grammar Vega and we use a Vega-based implementation of Gapminder as guiding example. We additionally present a biomedical case study to illustrate how KnowledgePearls facilitates the exploration process by recalling states from earlier analyses.",,https://github.com/Caleydo/knowledge-pearls,,,vimeo 289787528,10.1109/tvcg.2018.2865024,2018,2018,VAST,"Hall 1, Section C",Wednesday,Ensemble and Provenance,2022-10-24,10:00:00 AM,10:20:00 AM
openaccessvis2018.csv,VAST,TVCG,Enhancing Web-based Analytics Applications through Provenance,J),"Akhilesh Camisetty, Chaitanya Chandurkar, Maoyuan Sun, David Koop",http://www.cis.umassd.edu/~dkoop/pubs/simprov.pdf,"Visual analytics systems continue to integrate new technologies and leverage modern environments for exploration and collaboration, making tools and techniques available to a wide audience through web browsers. Many of these systems have been developed with rich interactions, offering users the opportunity to examine details and explore hypotheses that have not been directly encoded by a designer. Understanding is enhanced when users can replay and revisit the steps in the sensemaking process, and in collaborative settings, it is especially important to be able to review not only the current state but also what decisions were made along the way. Unfortunately, many web-based systems lack the ability to capture such reasoning, and the path to a result is transient, forgotten when a user moves to a new view. This paper explores the requirements to augment existing client-side web applications with support for capturing, reviewing, sharing, and reusing steps in the reasoning process. Furthermore, it considers situations where decisions are made with streaming data, and the insights gained from revisiting those choices when more data is available. It presents a proof of concept, the Shareable Interactive Manipulation Provenance framework (SIMProv.js), that addresses these requirements in a modern, client-side JavaScript library, and describes how it can be integrated with existing frameworks.",,,,,vimeo 289787554,10.1109/tvcg.2018.2865039,2018,2018,VAST,"Hall 1, Section C",Wednesday,Ensemble and Provenance,2022-10-24,10:20:00 AM,10:40:00 AM
openaccessvis2018.csv,InfoVis,TVCG,Comparing Similarity Perception in Time Series Visualizations,J),"Anna Gogolou, Theophanis Tsandilas, Themis Palpanas, Anastasia Bezerianos",https://hal.inria.fr/hal-01845008/document,"A common challenge faced by many domain experts working with time series data is how to identify and compare similar patterns. This operation is fundamental in high-level tasks, such as detecting recurring phenomena or creating clusters of similar temporal sequences. While automatic measures exist to compute time series similarity, human intervention is often required to visually inspect these automatically generated results. The visualization literature has examined similarity perception and its relation to automatic similarity measures for line charts, but has not yet considered if alternative visual representations, such as horizon graphs and colorfields, alter this perception. Motivated by how neuroscientists evaluate epileptiform patterns, we conducted two experiments that study how these three visualization techniques affect similarity perception in EEG signals. We seek to understand if the time series results returned from automatic similarity measures are perceived in a similar manner, irrespective of the visualization technique; and if what people perceive as similar with each visualization aligns with different automatic measures and their similarity constraints. Our findings indicate that horizon graphs align with similarity measures that allow local variations in temporal position or speed (i.e., dynamic time warping) more than the two other techniques. On the other hand, horizon graphs do not align with measures that are insensitive to amplitude and y-offset scaling (i.e., measures based on z-normalization), but the inverse seems to be the case for line charts and colorfields. Overall, our work indicates that the choice of visualization affects what temporal patterns we consider as similar, i.e., the notion of similarity in time series is not visualization independent.",,,,,vimeo 289785077,10.1109/tvcg.2018.2865077,2018,2018,InfoVis,"Hall 1, Section D",Wednesday,Time,2022-10-24,9:00:00 AM,9:20:00 AM
openaccessvis2018.csv,TVCG,TVCG,A Multiresolution Streamgraph Approach to Explore Hierarchical Time Series,T),"Erick Cuenca, Arnaud Sallaberry, Florence Ying Wang, Pascal Poncelet",http://www.lirmm.fr/~poncelet/publications/papers/Multistream2018.pdf,"Multiple time series are a set of multiple quantitative variables occurring at the same interval. They are present in many domains such as medicine, finance, and manufacturing for analytical purposes. In recent years, streamgraph visualization (evolved from ThemeRiver) has been widely used for representing temporal evolution patterns in multiple time series. However, streamgraph as well as ThemeRiver suffer from scalability problems when dealing with several time series. To solve this problem, multiple time series can be organized into a hierarchical structure where individual time series are grouped hierarchically according to their proximity. In this paper, we present a new streamgraph-based approach to convey the hierarchical structure of multiple time series to facilitate the exploration and comparisons of temporal evolution. Based on a focus+context technique, our method allows time series exploration at different granularities (e. g., from overview to details). To illustrate our approach, two usage examples are presented.",http://advanse.lirmm.fr/multistream/,https://github.com/erickedu85/multistream,,,vimeo 289789365,10.1109/TVCG.2018.2796591,2018,2018,InfoVis,"Hall 1, Section D",Wednesday,Time,2022-10-24,9:20:00 AM,9:40:00 AM
openaccessvis2018.csv,TVCG,TVCG,Line Graph or Scatter Plot? Automatic Selection of Methods for Visualizing Trends in Time Series,T),"Yunhai Wang, Fubo Han, Lifeng Zhu, Oliver Deussen, Baoquan Chen",http://www.yunhaiwang.org/vis-selection/timeseries.pdf,"Line graphs are usually considered to be the best choice for visualizing time series data, whereas sometimes also scatter plots are used for showing main trends. So far there are no guidelines that indicate which of these visualization methods better display trends in time series for a given canvas. Assuming that the main information in a time series is its overall trend, we propose an algorithm that automatically picks the visualization method that reveals this trend best. This is achieved by measuring the visual consistency between the trend curve represented by a LOESS fit and the trend described by a scatter plot or a line graph. To measure the consistency between our algorithm and user choices, we performed an empirical study with a series of controlled experiments that show a large correspondence. In a factor analysis we furthermore demonstrate that various visual and data factors have effects on the preference for a certain type of visualization.",,,,,vimeo 289788836,10.1109/tvcg.2017.2653106,2018,2018,InfoVis,"Hall 1, Section D",Wednesday,Time,2022-10-24,9:40:00 AM,10:00:00 AM
openaccessvis2018.csv,TVCG,TVCG,A Vector Field Design Approach to Animated Transitions,T),"Yong Wang, Daniel Archambault, Carlos E. Scheidegger, Huamin Qu",http://www.cs.swansea.ac.uk/~csdarchambault/publications/animatedTransitionFinalSubVersion.pdf,"Animated transitions can be effective in explaining and exploring a small number of visualizations where there are drastic changes in the scene over a short interval of time. This is especially true if data elements cannot be visually distinguished by other means. Current research in animated transitions has mainly focused on linear transitions (all elements follow straight line paths) or enhancing coordinated motion through bundling of linear trajectories. In this paper, we introduce animated transition design, a technique to build smooth, non-linear transitions for clustered data with either minimal or no user involvement. The technique is flexible and simple to implement, and has the additional advantage that it explicitly enhances coordinated motion and can avoid crowding, which are both important factors to support object tracking in a scene. We investigate its usability, provide preliminary evidence for the effectiveness of this technique through metric evaluations and user study and discuss limitations and future directions.",,,,,vimeo 289789555,10.1109/tvcg.2017.2750689,2017,2018,InfoVis,"Hall 1, Section D",Wednesday,Time,2022-10-24,10:00:00 AM,10:20:00 AM
openaccessvis2018.csv,InfoVis,TVCG,Temporal Treemaps: Static Visualization of Evolving Trees,J),"Wiebke K”pp, Tino Weinkauf",http://www.csc.kth.se/~weinkauf/publications/documents/koepp19a.pdf,"We consider temporally evolving trees with changing topology and data: tree nodes may persist for a time range, merge or split, and the associated data may change. Essentially, one can think of this as a time series of trees with a node correspondence per hierarchy level between consecutive time steps. Existing visualization approaches for such data include animated 2D treemaps, where the dynamically changing layout makes it difficult to observe the data in its entirety. We present a method to visualize this dynamic data in a static, nested, and space-filling visualization. This is based on two major contributions: First, the layout constitutes a graph drawing problem. We approach it for the entire time span at once using a combination of a heuristic and simulated annealing. Second, we propose a rendering that emphasizes the hierarchy through an adaption of the classic cushion treemaps. We showcase the wide range of applicability using data from feature tracking in time-dependent scalar fields, evolution of file system hierarchies, and world population.",http://www.csc.kth.se/~weinkauf/publications/documents/koepp19a_algorithm.mp4,,,,vimeo 289784452,10.1109/TVCG.2018.2865265,2018,2018,InfoVis,"Hall 1, Section D",Wednesday,Time,2022-10-24,10:20:00 AM,10:40:00 AM
openaccessvis2018.csv,SciVis,TVCG,Visual Analysis of Aneurysm Data using Statistical Graphics,J),"Monique Meuschke, Tobias Gnther, Philipp Berg, Ralph Wickenhoefer, Markus Gross, Bernhard Preim, Kai Lawonn",https://cgl.ethz.ch/Downloads/Publications/Papers/2018/Meu18b/Meu18b.pdf,"This paper presents a framework to explore multi-field data of aneurysms occurring at intracranial and cardiac arteries by using statistical graphics. The rupture of an aneurysm is often a fatal scenario, whereas during treatment serious complications for the patient can occur. Whether an aneurysm ruptures or whether a treatment is successful depends on the interaction of different morphological such as wall deformation and thickness, and hemodynamic attributes like wall shear stress and pressure. Therefore, medical researchers are very interested in better understanding these relationships. However, the required analysis is a time-consuming process, where suspicious wall regions are difficult to detect due to the time-dependent behavior of the data. Our proposed visualization framework enables medical researchers to efficiently assess aneurysm risk and treatment options. This comprises a powerful set of views including 2D and 3D depictions of the aneurysm morphology as well as statistical plots of different scalar fields. Brushing and linking aids the user to identify interesting wall regions and to understand the influence of different attributes on the aneurysm?s state. Moreover, a visual comparison of pre- and post-treatment as well as different treatment options is provided. Our analysis techniques are designed in collaboration with domain experts, e.g., physicians, and we provide details about the evaluation.",,,,,vimeo 290325604,10.1109/tvcg.2018.2864509,2018,2018,SciVis,Estrel Hall A+B,Wednesday,Biomedical Visualization,2022-10-24,9:00:00 AM,9:20:00 AM
openaccessvis2018.csv,SciVis,TVCG,Interactive Visualization of 3D Histopathology in Native Resolution,J),"Martin Falk, Anders Ynnerman, Darren Treanor, Claes Lundstr”m",http://scivis.itn.liu.se/publications/2019/FYTL19//falk-3dhistology-preprint.pdf," We present a visualization application that enables effective interactive visual analysis of large-scale 3D histopathology, that is, high-resolution 3D microscopy data of human tissue. Clinical work flows and research based on pathology have, until now, largely been dominated by 2D imaging. As we will show in the paper, studying volumetric histology data will open up novel and useful opportunities for both research and clinical practice. Our starting point is the current lack of appropriate visualization tools in histopathology, which has been a limiting factor in the uptake of digital pathology. Visualization of 3D histology data does pose difficult challenges in several aspects. The full-color datasets are dense and large in scale, on the order of 100,000 ? 100,000? 100 voxels. This entails serious demands on both rendering performance and user experience design. Despite this, our developed application supports interactive study of 3D histology datasets at native resolution. Our application is based on tailoring and tuning of existing methods, system integration work, as well as a careful study of domain specific demands emanating from a close participatory design process with domain experts as team members. Results from a user evaluation employing the tool demonstrate a strong agreement among the 14 participating pathologists that 3D histopathology will be a valuable and enabling tool for their work",,,,,vimeo 290325921,10.1109/TVCG.2018.2864816,2018,2018,SciVis,Estrel Hall A+B,Wednesday,Biomedical Visualization,2022-10-24,9:20:00 AM,9:40:00 AM
openaccessvis2018.csv,SciVis,TVCG,Visualization of Neuronal Structures in Wide-field Microscopy Brain Images,J),"Saeed Boorboor, Shreeraj Jadhav, Mala Ananth, David Talmage, Lorna W Role, Arie Kaufman",,,,,,,vimeo 290328215,10.1109/TVCG.2018.2864852,2018,2018,SciVis,Estrel Hall A+B,Wednesday,Biomedical Visualization,2022-10-24,9:40:00 AM,10:00:00 AM
openaccessvis2018.csv,TVCG,TVCG,Classification of Blood Flow Patterns in Cerebral Aneurysms,T),"Monique Meuschke, Steffen Oeltze-Jafra, Oliver Beuing, Bernhard Preim, Kai Lawonn",,,,,,,youtube jI8GxKXaoU8,10.1109/tvcg.2018.2834923,2018,2018,SciVis,Estrel Hall A+B,Wednesday,Biomedical Visualization,2022-10-24,10:00:00 AM,10:20:00 AM
openaccessvis2018.csv,TVCG,TVCG,Bridging Text Visualization and Mining: A Task-Driven Survey,T),"Shixia Liu, Xiting Wang, Christopher Collins, Wenwen Dou, Fangxin Ouyang, Mennatallah El-Assady, Liu Jiang, Daniel Keim",,,,,,,vimeo 289789579,10.1109/tvcg.2018.2834341,2018,2018,VAST,Estrel Hall C,Wednesday,Text,2022-10-24,9:00:00 AM,9:20:00 AM
openaccessvis2018.csv,VAST,TVCG,Doccurate: A Curation-Based Approach for Clinical Text Visualization,J),"Nicole Sultanum, Devin Singh, Michael Brudno, Fanny Chevalier",https://nicksultanum.github.io/web/files/pubs/2018-doccurate.pdf,"Before seeing a patient, physicians seek to obtain an overview of the patient?s medical history. Text plays a major role in this activity since it represents the bulk of the clinical documentation, but reviewing it quickly becomes onerous when patient charts grow too large. Text visualization methods have been widely explored to manage this large scale through visual summaries that rely on information retrieval algorithms to structure text and make it amenable to visualization. However, the integration with such automated approaches comes with a number of limitations, including significant error rates and the need for healthcare providers to fine-tune algorithms without expert knowledge of their inner mechanics. In addition, several of these approaches obscure or substitute the original clinical text and therefore fail to leverage qualitative and rhetorical flavours of the clinical notes. These drawbacks have limited the adoption of text visualization and other summarization technologies in clinical practice. In this work we present <i>Doccurate</i>, a novel system embodying a curation-based approach for the visualization of large clinical text datasets. Our approach offers automation auditing and customizability to physicians while also preserving and extensively linking to the original text. We discuss findings of a formal qualitative evaluation conducted with 6 domain experts, shedding light onto physicians? information needs, perceived strengths and limitations of automated tools, and the importance of customization while balancing efficiency. We also present use case scenarios to showcase Doccurate?s envisioned usage in practice.",,,,,vimeo 289787431,10.1109/TVCG.2018.2864905,2018,2018,VAST,Estrel Hall C,Wednesday,Text,2022-10-24,9:20:00 AM,9:40:00 AM
openaccessvis2018.csv,VAST,TVCG,VIS Author Profiles: Interactive Descriptions of Publication Records Combining Text and Visualization,J),"Shahid Latif, Fabian Beck, Devin Singh, Michael Brudno, Fanny Chevalier",https://www.vis.wiwi.uni-due.de/uploads/tx_itochairt3/publications/vap-preprint.pdf,"Publication records and collaboration networks are important for assessing the expertise and experience of researchers. Existing digital libraries show the raw publication lists in author profiles, whereas visualization techniques focus on specific subproblems. Instead, we look at publication records from various perspectives mixing low-level publication data with high-level abstractions and background information. This work presents VIS Author Profiles, a novel approach to generate integrated textual and visual descriptions to highlight patterns in publication records. We leverage template-based natural language generation to summarize notable publication statistics, evolution of research topics, and collaboration relationships. Seamlessly integrated visualizations augment the textual description and are interactively connected with each other and the text. The underlying publication data and detailed explanations of the analysis are available on demand. We compare our approach to existing systems by taking into account information needs of users and demonstrate its usefulness in two realistic application examples.",https://vis-tools.paluno.uni-due.de/vap/,,,,vimeo 289787504,10.1109/TVCG.2018.2865022,2018,2018,VAST,Estrel Hall C,Wednesday,Text,2022-10-24,9:40:00 AM,10:00:00 AM
openaccessvis2018.csv,TVCG,TVCG,A Visual Analytics Framework for Identifying Topic Drivers in Media,T),"Yafeng Lu, Hong Wang, Steven Landis, Ross Maciejewski",http://rmaciejewski.faculty.asu.edu/papers/2018/Identifying%20Topic%20Drivers.pdf,"Media data has been the subject of large scale analysis with applications of text mining being used to provide overviews of media themes and information flows. Such information extracted from media articles has also shown its contextual value of being integrated with other data, such as criminal records and stock market pricing. In this work, we explore linking textual media data with curated secondary textual data sources through user-guided semantic lexical matching for identifying relationships and data links. In this manner, critical information can be identified and used to annotate media timelines in order to provide a more detailed overview of events that may be driving media topics and frames. These linked events are further analyzed through an application of causality modeling to model temporal drivers between the data series. Such causal links are then annotated through automatic entity extraction which enables the analyst to explore persons, locations, and organizations that may be pertinent to the media topic of interest. To demonstrate the proposed framework, two media datasets and an armed conflict event dataset are explored.",,,,,vimeo 289788885,10.1109/TVCG.2017.2752166,2018,2018,VAST,Estrel Hall C,Wednesday,Text,2022-10-24,10:00:00 AM,10:20:00 AM
openaccessvis2018.csv,TVCG,TVCG,Visualizing a Thinker?s Life,T),"Patrick Riehmann, Dora Kiesel, Martin Kohlhaas, Bernd Fr”hlich",,,,,,,vimeo 289789544,10.1109/TVCG.2018.2824822,2018,2018,VAST,Estrel Hall C,Wednesday,Text,2022-10-24,10:20:00 AM,10:40:00 AM
openaccessvis2018.csv,TVCG,TVCG,Commercial Visual Analytics Systems ? Advances in the Big Data Analytics Field,T),"Michael Behrisch, Dirk Streeb, Florian Stoffel, Daniel Seebacher, Stefan Hagen Weber, Sebastian Mittelstaedt, Hanspeter Pfister, Daniel Keim",https://commercialtools.dbvis.de/assets/data/submission/CommercialTools_TVCG_Journal_FINAL.pdf,"Five years after the first state-of-the-art report on Commercial Visual Analytics Systems we present a reevaluation of the Big Data Analytics field. We build on the success of the 2012 survey, which was influential even beyond the boundaries of the InfoVis and Visual Analytics (VA) community. While the field has matured significantly since the original survey, we find that innovation and research-driven development are increasingly sacrificed to satisfy a wide range of user groups. We evaluate new product versions on established evaluation criteria, such as available features, performance, and usability, to extend on and assure comparability with the previous survey. We also investigate previously unavailable products to paint a more complete picture of the commercial VA landscape. Furthermore, we introduce novel measures, like suitability for specific user groups and the ability to handle complex data types, and undertake a new case study to highlight innovative features. We explore the achievements in the commercial sector in addressing VA challenges and propose novel developments that should be on systems? roadmaps in the coming years.",,https://commercialtools.dbvis.de/questions,,,vimeo 289789498,10.1109/TVCG.2018.2859973,2018,2018,VAST,"Hall 1, Section C",Wednesday,Applications,2022-10-24,11:00:00 AM,11:20:00 AM
openaccessvis2018.csv,VAST,TVCG,BitExTract: Interactive Visualization for Extracting Bitcoin Exchange Intelligence,J),"Xuanwu Yue, Xinhuan Shu, Xinyu ZHU, Xinnan Du, Zheqing Yu, Dimitrios Papadopoulos, Siyuan Liu",,,,,,,vimeo 289787312,10.1109/TVCG.2018.2864814,2018,2018,VAST,"Hall 1, Section C",Wednesday,Applications,2022-10-24,11:20:00 AM,11:40:00 AM
openaccessvis2018.csv,TVCG,TVCG,KAVAGait: Knowledge-Assisted Visual Analytics for Clinical Gait Analysis,T),"Markus Wagner, Djordje Slijepcevic, Brian Horsak, Alexander Rind, Matthias Zeppelzauer, Wolfgang Aigner",https://arxiv.org/pdf/1707.06105.pdf,"In 2014, more than 10 million people in the US were affected by an ambulatory disability. Thus, gait rehabilitation is a crucial part of health care systems. The quantification of human locomotion enables clinicians to describe and analyze a patient?s gait performance in detail and allows them to base clinical decisions on objective data. These assessments generate a vast amount of complex data which need to be interpreted in a short time period. We conducted a design study in cooperation with gait analysis experts to develop a novel Knowledge-Assisted Visual Analytics solution for clinical Gait analysis (KAVAGait). KAVAGait allows the clinician to store and inspect complex data derived during clinical gait analysis. The system incorporates innovative and interactive visual interface concepts, which were developed based on the needs of clinicians. Additionally, an explicit knowledge store (EKS) allows externalization and storage of implicit knowledge from clinicians. It makes this information available for others, supporting the process of data inspection and clinical decision making. We validated our system by conducting expert reviews, a user study, and a case study. Results suggest that KAVAGait is able to support a clinician during clinical practice by visualizing complex gait data and providing knowledge of other clinicians.",,,,,vimeo 289788975,10.1109/tvcg.2017.2785271,2018,2018,VAST,"Hall 1, Section C",Wednesday,Applications,2022-10-24,11:40:00 AM,12:00:00 PM
openaccessvis2018.csv,TVCG,TVCG,Precision Risk Analysis of Cancer Therapy with Interactive Nomograms and Survival Plots,T),"G.Elisabeta Marai, Chihua Ma, Andrew T. Burks, Filippo Pellolio, Guadalupe Canahuate, David M. Vock, Abdallah S.R. Mohamed, C. David Fuller",https://www.evl.uic.edu/documents/ieee_precisionriskanalysis.pdf,"We present the design and evaluation of an integrated problem solving environment for cancer therapy analysis. The environment intertwines a statistical martingale model and a K Nearest Neighbor approach with visual encodings, including novel interactive nomograms, in order to compute and explain a patient?s probability of survival as a function of similar patient results. A coordinated views paradigm enables exploration of the multivariate, heterogeneous and few-valued data from a large head and neck cancer repository. A visual scaffolding approach further enables users to build from familiar representations to unfamiliar ones. Evaluation with domain experts show how this visualization approach and set of streamlined workflows enable the systematic and precise analysis of a patient prognosis in the context of cohorts of similar patients. We describe the design lessons learned from this successful, multi-site remote collaboration.",,,,,vimeo 289789079,10.1109/tvcg.2018.2817557,2018,2018,VAST,"Hall 1, Section C",Wednesday,Applications,2022-10-24,12:00:00 PM,12:20:00 PM
openaccessvis2018.csv,VAST,VAST,VUSphere: Visual Analysis of Video Utilization in Online Distance Education,C),"Huan He, Qinghua Zheng, Bo Dong",,,,,,,vimeo 289788052,,2018,2018,VAST,"Hall 1, Section C",Wednesday,Applications,2022-10-24,12:20:00 PM,12:40:00 PM
openaccessvis2018.csv,InfoVis,TVCG,Juniper: A Tree+Table Approach to Multivariate Graph Visualization,J),"Carolina Nobre, Marc Streit, Alexander Lex",https://arxiv.org/pdf/1804.03261.pdf,"Analyzing large, multivariate graphs is an important problem in many domains, yet such graphs are challenging to visualize. In this paper, we introduce a novel, scalable, tree+table multivariate graph visualization technique, which makes many tasks related to multivariate graph analysis easier to achieve. The core principle we follow is to selectively query for nodes or subgraphs of interest and visualize these subgraphs as a spanning tree of the graph. The tree is laid out linearly, which enables us to juxtapose the nodes with a table visualization where diverse attributes can be shown. We also use this table as an adjacency matrix, so that the resulting technique is a hybrid node-link/adjacency matrix technique. We implement this concept in Juniper and complement it with a set of interaction techniques that enable analysts to dynamically grow, restructure, and aggregate the tree, as well as change the layout or show paths between nodes. We demonstrate the utility of our tool in usage scenarios for different multivariate networks: a bipartite network of scholars, papers, and citation metrics and a multitype network of story characters, places, books, etc.",,https://github.com/caleydo/lineage/tree/juniper,,,vimeo 289784894,10.1109/TVCG.2018.2865149,2018,2018,InfoVis,"Hall 1, Section D",Wednesday,Graphs & Trees,2022-10-24,11:00:00 AM,11:20:00 AM
openaccessvis2018.csv,TVCG,TVCG,Graph Thumbnails: Identifying and Comparing Multiple Graphs at a Glance,T),"Vahan Yoghourdjian, Tim Dwyer, Karsten Klein, Kim Marriott, Michael Wybrow",http://vahany.com/docs/Graph_Thumbnails_preprint.pdf,"We propose <i>Graph Thumbnails</i>, small icon-like visualisations of the high-level structure of network data. Graph Thumbnails are designed to be legible in small multiples to support rapid browsing within large graph corpora. Compared to existing graph-visualisation techniques our representation has several advantages: (1) the visualisation can be computed in linear time; (2) it is canonical in the sense that isomorphic graphs will always have identical thumbnails; and (3) it provides precise information about the graph structure. We report the results of two user studies. The first study compares Graph Thumbnails to node-link and matrix views for identifying similar graphs. The second study investigates the comprehensibility of the different representations. We demonstrate the usefulness of this representation for summarising the evolution of protein-protein interaction networks across a range of species.",,,,,vimeo 289789353,10.1109/tvcg.2018.2790961,2018,2018,InfoVis,"Hall 1, Section D",Wednesday,Graphs & Trees,2022-10-24,11:20:00 AM,11:40:00 AM
openaccessvis2018.csv,InfoVis,TVCG,Structure-Based Suggestive Exploration: A New Approach for Effective Exploration of Large Networks,J),"Fangzhou Guo, Wei Chen, Dongming Han, Jiacheng Pan, Xiaotao Nie, Jiazhi Xia, Xiaolong (Luke) Zhang",http://www.cad.zju.edu.cn/home/vagblog/VAG_Work/Structure-Based%20Suggestive%20Exploration.pdf,"When analyzing a visualized network, users need to explore different sections of the network to gain insight. However, effective exploration of large networks is often a challenge. While various tools are available for users to explore the global and local features of a network, these tools usually require significant interaction activities, such as repetitive navigation actions to follow network nodes and edges. In this paper, we propose a structure-based suggestive exploration approach to support effective exploration of large networks by suggesting appropriate structures upon user request. Encoding nodes with vectorized representations by transforming information of surrounding structures of nodes into a high dimensional space, our approach can identify similar structures within a large network, enable user interaction with multiple similar structures simultaneously, and guide the exploration of unexplored structures. We develop a web-based visual exploration system to incorporate this suggestive exploration approach and compare performances of our approach under different vectorizing methods and networks. We also present the usability and effectiveness of our approach through a controlled user study with two datasets.",,,,,vimeo 289785045,10.1109/tvcg.2018.2865139,2018,2018,InfoVis,"Hall 1, Section D",Wednesday,Graphs & Trees,2022-10-24,11:40:00 AM,12:00:00 PM
openaccessvis2018.csv,InfoVis,TVCG,Structure-aware Fisheye Views for Efficient Large Graph Exploration,J),"Yunhai Wang, Yanyan Wang, Yinqi Sun, Haifeng Zhang, Chi-Wing Fu, Michael Sedlmair, Baoquan Chen, Oliver Deussen",https://homepage.univie.ac.at/michael.sedlmair/papers/wang2019fisheye.pdf,"Traditional fisheye views for exploring large graphs introduce substantial distortions that often lead to a decreased readability of paths and other interesting structures. To overcome these problems, we propose a framework for <i>structure-aware</i> fisheye views. Using edge orientations as constraints for graph layout optimization allows us not only to reduce spatial and temporal distortions during fisheye zooms, but also to improve the readability of the graph structure. Furthermore, the framework enables us to optimize fisheye lenses towards specific tasks and design a family of new lenses: polyfocal, cluster, and path lenses. A GPU implementation lets us process large graphs with up to 15,000 nodes at interactive rates. A comprehensive evaluation, a user study, and two case studies demonstrate that our structure-aware fisheye views improve layout readability and user performance.",,,,,vimeo 289785238,10.1109/tvcg.2018.2864911,2018,2018,InfoVis,"Hall 1, Section D",Wednesday,Graphs & Trees,2022-10-24,12:00:00 PM,12:20:00 PM
openaccessvis2018.csv,InfoVis,TVCG,"Graphicle: Exploring Units, Networks, and Context in a Blended Visualization Approach ",J),"Timothy Major, Rahul C. Basole",http://entsci.gatech.edu/resources/basole-2019-tvcg-graphicle.pdf,"Many real-world datasets are large, multivariate, and relational in nature and relevant associated decisions frequently require a simultaneous consideration of both attributes and connections. Existing visualization systems and approaches, however, often make an explicit trade-off between either affording rich exploration of individual data units and their attributes or exploration of the underlying network structure. In doing so, important analysis opportunities and insights are potentially missed. In this study, we aim to address this gap by (1) considering visualizations and interaction techniques that blend the spectrum between unit and network visualizations, (2) discussing the nature of different forms of contexts and the challenges in implementing them, and (3) demonstrating the value of our approach for visual exploration of multivariate, relational data for a real-world use case. Specifically, we demonstrate through a system called Graphicle how network structure can be layered on top of unit visualization techniques to create new opportunities for visual exploration of physician characteristics and referral data. We report on the design, implementation, and evaluation of the system and effectiveness of our blended approach.",,,,,vimeo 262664447,10.1109/tvcg.2018.2865151,2018,2018,InfoVis,"Hall 1, Section D",Wednesday,Graphs & Trees,2022-10-24,12:20:00 PM,12:40:00 PM
openaccessvis2018.csv,SciVis,TVCG,Interactive Obstruction-free Lensing for Volumetric Data Visualization,J),"Michael Traor‚, Christophe Hurter, Alexandru Telea",http://recherche.enac.fr/~hurter/ObstructionFreeLens/Vis2018Traore.pdf,"Occlusion is an issue in volumetric visualization as it prevents direct visualization of the region of interest. While many techniques such as transfer functions, volume segmentation or view distortion have been developed to address this, there is still room for improvement to better support the understanding of objects? vicinity. However, most existing Focus+Context fail to solve partial occlusion in datasets where the target and the occluder are very similar density-wise. For these reasons, we investigate a new technique which maintains the general structure of the investigated volumetric dataset while addressing occlusion issues. With our technique, the user interactively defines an area of interest where an occluded region or object is partially visible. Then our lens starts pushing at its border occluding objects, thus revealing hidden volumetric data. Next, the lens is modified with an extended field of view (fish-eye deformation) to better see the vicinity of the selected region. Finally, the user can freely explore the surroundings of the area under investigation within the lens. To provide real-time exploration, we implemented our lens using a GPU accelerated ray-casting framework to handle ray deformations, local lighting, and local viewpoint manipulation. We illustrate our technique with five application scenarios in baggage inspection, 3D fluid flow visualization, chest radiology, air traffic planning, and DTI fiber exploration.",,,,,youtube FOiCmznSOz4,10.1109/TVCG.2018.2864690,2018,2018,SciVis,Estrel Hall A+B,Wednesday,Volume Visualization,2022-10-24,11:00:00 AM,11:20:00 AM
openaccessvis2018.csv,SciVis,TVCG,Dynamic Volume Lines: Visual Comparison of 3D Volumes through Space-filling Curves,J),"Johannes Weissenb”ck, Bernhard Fr”hler, Eduard Gr”ller, Johann Kastner, Christoph Heinzl",,,,,,,vimeo 290325634,10.1109/tvcg.2018.2864510,2018,2018,SciVis,Estrel Hall A+B,Wednesday,Volume Visualization,2022-10-24,11:20:00 AM,11:40:00 AM
openaccessvis2018.csv,SciVis,TVCG,A Declarative Grammar of Flexible Volume Visualization Pipelines,J),"Min Shih, Charles Rozhon, Kwan-Liu Ma",,,,,,,vimeo 290327611,10.1109/tvcg.2018.2864841,2018,2018,SciVis,Estrel Hall A+B,Wednesday,Volume Visualization,2022-10-24,11:40:00 AM,12:00:00 PM
openaccessvis2018.csv,TVCG,TVCG,Multi-Material Volume Rendering with a Physically-Based Surface Reflection Model,T),"Oleg Igouchkine, Yubo Zhang, Kwan-Liu Ma",,,,,,,vimeo 289789120,10.1109/tvcg.2017.2784830,2018,2018,SciVis,Estrel Hall A+B,Wednesday,Volume Visualization,2022-10-24,12:00:00 PM,12:20:00 PM
openaccessvis2018.csv,TVCG,TVCG,A Generative Model for Volume Rendering,T),"Matthew Berger, Jixian Li, Joshua A. Levine",https://arxiv.org/pdf/1710.09545.pdf,"We present a technique to synthesize and analyze volume-rendered images using generative models. We use the Generative Adversarial Network (GAN) framework to compute a model from a large collection of volume renderings, conditioned on (1) viewpoint and (2) transfer functions for opacity and color. Our approach facilitates tasks for volume analysis that are challenging to achieve using existing rendering techniques such as ray casting or texture-based methods. We show how to guide the user in transfer function editing by quantifying expected change in the output image. Additionally, the generative model transforms transfer functions into a view-invariant latent space specifically designed to synthesize volume-rendered images. We use this space directly for rendering, enabling the user to explore the space of volume-rendered images. As our model is independent of the choice of volume rendering process, we show how to analyze volume-rendered images produced by direct and global illumination lighting, for a variety of volume datasets.",,https://github.com/matthewberger/tfgan,,,vimeo 289789468,10.1109/tvcg.2018.2816059,2018,2018,SciVis,Estrel Hall A+B,Wednesday,Volume Visualization,2022-10-24,12:20:00 PM,12:40:00 PM
openaccessvis2018.csv,InfoVis,TVCG,Vistrates: A Component Model for Ubiquitous Analytics,J),"Sriram Karthik Badam, Andreas Mathisen, Roman R„dle, Clemens Nylandsted Klokmose, Niklas Elmqvist",http://users.umiacs.umd.edu/~elm/projects/vistrates/vistrates.pdf,"Visualization tools are often specialized for specific tasks, which turns the user's analytical workflow into a fragmented process performed across many tools. In this paper, we present a component model design for data visualization to promote modular designs of visualization tools that enhance their analytical scope. Rather than fragmenting tasks across tools, the component model supports unification, where components?the building blocks of this model?can be assembled to support a wide range of tasks. Furthermore, the model also provides additional key properties, such as support for collaboration, sharing across multiple devices, and adaptive usage depending on expertise, from creating visualizations using dropdown menus, through instantiating components, to actually modifying components or creating entirely new ones from scratch using JavaScript or Python source code. To realize our model, we introduce VISTRATES, a literate computing platform for developing, assembling, and sharing visualization components. From a visualization perspective, Vistrates features cross-cutting components for visual representations, interaction, collaboration, and device responsiveness maintained in a component repository. From a development perspective, Vistrates offers a collaborative programming environment where novices and experts alike can compose component pipelines for specific analytical activities. Finally, we present several Vistrates use cases that span the full range of the classic ""anytime"" and ""anywhere"" motto for ubiquitous analysis: from mobile and on-the-go usage, through office settings, to collaborative smart environments covering a variety of tasks and devices.",,https://github.com/karthikbadam/Vistrates,,,vimeo 289784994,10.1109/tvcg.2018.2865144,2018,2018,InfoVis,Estrel Hall C,Wednesday,Devices,2022-10-24,11:00:00 AM,11:20:00 AM
openaccessvis2018.csv,InfoVis,TVCG,SmartCues: A Multitouch Query Approach for Details-on-Demand through Dynamically Computed Overlays,J),"Hariharan Subramonyam, Eytan Adar",,,,,,,vimeo 289784720,10.1109/tvcg.2018.2865231,2018,2018,InfoVis,Estrel Hall C,Wednesday,Devices,2022-10-24,11:20:00 AM,11:40:00 AM
openaccessvis2018.csv,InfoVis,TVCG,"Multiple Coordinated Views at Large Displays for Multiple Users: Empirical Findings on User Behavior, Movements, and Distances ",J),"Ricardo Langner, Ulrike Kister, Raimund Dachselt",https://imld.de/cnt/uploads/Langner-2018_MCV-LargeDisplays_InfoVis2018.pdf,"Interactive wall-sized displays benefit data visualization. Due to their sheer display size, they make it possible to show large amounts of data in multiple coordinated views (MCV) and facilitate collaborative data analysis. In this work, we propose a set of important design considerations and contribute a fundamental input vocabulary and interaction mapping for MCV functionality. We also developed a fully functional application with more than 45 coordinated views visualizing a real-world, multivariate data set of crime activities, which we used in a comprehensive qualitative user study investigating how pairs of users behave. Most importantly, we found that flexible movement is essential and?depending on user goals?is connected to collaboration, perception, and interaction. Therefore, we argue that for future systems interaction from the distance is required and needs good support. We show that our consistent design for both direct touch at the large display and distant interaction using mobile phones enables the seamless exploration of large-scale MCV at wall-sized displays. Our MCV application builds on design aspects such as simplicity, flexibility, and visual consistency and, therefore, supports realistic workflows. We believe that in the future, many visual data analysis scenarios will benefit from wall-sized displays presenting numerous coordinated visualizations, for which our findings provide a valuable foundation.",,,https://imld.de/docs/projects/mcv-displaywall/study-logs.zip,,youtube kiXMn2VPZek,10.1109/tvcg.2018.2865235,2018,2018,InfoVis,Estrel Hall C,Wednesday,Devices,2022-10-24,11:40:00 AM,12:00:00 PM
openaccessvis2018.csv,InfoVis,TVCG,Visualizing Ranges over Time on Mobile Phones: A Task-Based Crowdsourced Evaluation,J),"Matthew Brehmer, Bongshin Lee, Petra Isenberg, Eun Kyoung Choe",https://hal.inria.fr/hal-01857469/document,"In the first crowdsourced visualization experiment conducted exclusively on mobile phones, we compare approaches to visualizing ranges over time on small displays. People routinely consume such data via a mobile phone, from temperatures in weather forecasting apps to sleep and blood pressure readings in personal health apps. However, we lack guidance on how to effectively visualize ranges on small displays in the context of different value retrieval and comparison tasks, or with respect to different data characteristics such as periodicity, seasonality, or the cardinality of ranges. Central to our experiment is a comparison between two ways to lay out ranges: a more conventional linear layout strikes a balance between quantitative and chronological scale resolution, while a less conventional radial layout emphasizes the cyclicality of time and may prioritize discrimination between values at its periphery. With results from 87 crowd workers, we found that while participants completed tasks more quickly with linear layouts than with radial ones, there were few differences in terms of error rate between layout conditions. We also found that participants performed similarly with both layouts in tasks that involved comparing superimposed observed and average ranges.",,https://github.com/Microsoft/RangesOnMobile/blob/master/StudyApp,https://github.com/Microsoft/RangesOnMobile/blob/master/StudyDataAnalysis,,vimeo 289784625,10.1109/tvcg.2018.2865234,2018,2018,InfoVis,Estrel Hall C,Wednesday,Devices,2022-10-24,12:00:00 PM,12:20:00 PM
openaccessvis2018.csv,InfoVis,TVCG,Glanceable Visualization: Studies of Data Comparison Performance on Smartwatches,J),"Tanja Blascheck, Lonni Besan‡on, Anastasia Bezerianos, Bongshin Lee, Petra Isenberg",https://hal.inria.fr/hal-01851306/file/Blascheck_2018_Glanceable_Visualization.pdf,"We present the results of two perception studies to assess how quickly people can perform a simple data comparison task for small-scale visualizations on a smartwatch. The main goal of these studies is to extend our understanding of design constraints for smartwatch visualizations. Previous work has shown that a vast majority of smartwatch interactions last under 5 s. It is still unknown what people can actually perceive from visualizations during such short glances, in particular with such a limited display space of smartwatches. To shed light on this question, we conducted two perception studies that assessed the lower bounds of task time for a simple data comparison task. We tested three chart types common on smartwatches: bar charts, donut charts, and radial bar charts with three different data sizes: 7, 12, and 24 data values. In our first study, we controlled the differences of the two target bars to be compared, while the second study varied the difference randomly. For both studies, we found that participants performed the task on average in <300 ms for the bar chart, <220 ms for the donut chart, and in <1780 ms for the radial bar chart. Thresholds in the second study per chart type were on average 1.14?1.35? higher than in the first study. Our results show that bar and donut charts should be preferred on smartwatch displays when quick data comparisons are necessary.",,,,,vimeo 289785013,10.1109/tvcg.2018.2865142,2018,2018,InfoVis,Estrel Hall C,Wednesday,Devices,2022-10-24,12:20:00 PM,12:40:00 PM
openaccessvis2018.csv,CG&A,CGA,Physical Visualization of Geospatial Datasets,,"Hessam Djavaherpour, Ali Mahdavi-Amiri, Faramarz F. Samavati",,,,,,,vimeo 289785692,10.1109/mcg.2017.38,2017,2018,Other,Room III,Wednesday,CG&A Session 1,2022-10-24,11:00:00 AM,11:20:00 AM
openaccessvis2018.csv,CG&A,CGA,Typology of Uncertainty in Static Geolocated Graphs for Visualization,,"Tatiana von Landesberger, Sebastian Bremm, Marcel Wunderlich",,,,,,,vimeo 289785707,10.1109/mcg.2017.3621220,2017,2018,Other,Room III,Wednesday,CG&A Session 1,2022-10-24,11:20:00 AM,11:40:00 AM
openaccessvis2018.csv,CG&A,CGA,Impact of Spatial Scales on the Intercomparison of Climate Scenarios,,"Wei Luo, Michael Steptoe, Zheng Chang, Robert Link, Leon Clarke, Ross Maciejewski",,,,,,,vimeo 289785725,10.1109/mcg.2017.3621222,2017,2018,Other,Room III,Wednesday,CG&A Session 1,2022-10-24,11:40:00 AM,12:00:00 PM
openaccessvis2018.csv,CG&A,CGA,Urban Space Explorer: A Visual Analytics System for Urban Planning,,"Alireza Karduni, Isaac Cho, Ginette Wessel, William Ribarsky, Eric Sauda, Wenwen Dou",,,,,,,vimeo 289785751,10.1109/mcg.2017.3621223,2017,2018,Other,Room III,Wednesday,CG&A Session 1,2022-10-24,12:00:00 PM,12:20:00 PM
openaccessvis2018.csv,CG&A,CGA,Name Profiler Toolkit,,"Feng Wang, Brett Hansen, Ryan Simmons, Ross Maciejewski",http://rmaciejewski.faculty.asu.edu/papers/2017/Names-CGA.pdf,"The Name Profiler Toolkit is a visual analytics system designed to enable the interactive exploration and analysis of forename and surname geographical distributions across the United States. Using demographic data from the US Census Bureau and Zillow, the toolkit lets users interactively compare distributions of names and name attributes.",,,,,vimeo 289785766,10.1109/mcg.2017.3621224,2017,2018,Other,Room III,Wednesday,CG&A Session 1,2022-10-24,12:20:00 PM,12:40:00 PM
openaccessvis2018.csv,VAST,TVCG,"SIRIUS: Dual, Symmetric, Interactive Dimension Reductions ",J),"Michelle Dowling, John Wenskovitch, J.T. Fry, Leanna House, Scotland Leman, Chris North",,,,,,,vimeo 289787667,10.1109/tvcg.2018.2865047,2018,2018,VAST,"Hall 1, Section C",Wednesday,High Dimensional Data,2022-10-24,2:20:00 PM,2:40:00 PM
openaccessvis2018.csv,TVCG,TVCG,A Perception-Driven Approach to Supervised Dimensionality Reduction for Visualization,T),"Yunhai Wang, Kang Feng, Xiaowei Chu, Jian Zhang, Chi-Wing Fu, Michael Sedlmair, Xiaohui Yu, Baoquan Chen",http://www.yunhaiwang.org/tvcg-dr/paper.pdf,"Dimensionality reduction (DR) is a common strategy for visual analysis of labeled high-dimensional data. Low-dimensional representations of the data help, for instance, to explore the class separability and the spatial distribution of the data. Widely-used unsupervised DR methods like PCA do not aim to maximize the class separation, while supervised DR methods like LDA often assume certain spatial distributions and do not take perceptual capabilities of humans into account. These issues make them ineffective for complicated class structures. Towards filling this gap, we present a <i>perception-driven linear dimensionality reduction</i> approach that maximizes the perceived class separation in projections. Our approach builds on recent developments in perception-based separation measures that have achieved good results in imitating human perception. We extend these measures to be density-aware and incorporate them into a customized simulated annealing algorithm, which can rapidly generate a near optimal DR projection. We demonstrate the effectiveness of our approach by comparing it to state-of-the-art DR methods on 93 datasets, using both quantitative measure and human judgments. We also provide case studies with class-imbalanced and unlabeled data",,,,,vimeo 289788938,10.1109/tvcg.2017.2701829,2018,2018,VAST,"Hall 1, Section C",Wednesday,High Dimensional Data,2022-10-24,2:40:00 PM,3:00:00 PM
openaccessvis2018.csv,VAST,VAST,SMARTexplore: Simplifying High-Dimensional Data Analysis through a Table-Based Visual Analytics Approach,C),"Michael Blumenschein, Michael Behrisch, Stefanie Schmid, Simon Butscher, Deborah R. Wahl, Karoline Villinger, Britta Renner, Harald Reiterer, Daniel Keim",https://bib.dbvis.de/uploadedFiles/BlumenscheinetalVAST2018SMARTexplore.pdf,"We present SMARTEXPLORE, a novel visual analytics technique that simplifies the identification and understanding of clusters, correlations, and complex patterns in high-dimensional data. The analysis is integrated into an interactive table-based visualization that maintains a consistent and familiar representation throughout the analysis. The visualization is tightly coupled with pattern matching, subspace analysis, reordering, and layout algorithms. To increase the analyst?s trust in the revealed patterns, SMARTEXPLORE automatically selects and computes statistical measures based on dimension and data properties. While existing approaches to analyzing highdimensional data (e.g., planar projections and Parallel coordinates) have proven effective, they typically have steep learning curves for non-visualization experts. Our evaluation, based on three expert case studies, confirms that non-visualization experts successfully reveal patterns in high-dimensional data when using SMARTEXPLORE.",,,,,vimeo 289787735,,2018,2018,VAST,"Hall 1, Section C",Wednesday,High Dimensional Data,2022-10-24,3:00:00 PM,3:20:00 PM
openaccessvis2018.csv,TVCG,TVCG,ColorMapND: A Data-Driven Approach and Tool for Mapping Multivariate Data to Color,T),"Shenghui Cheng, Wei Xu, Klaus Mueller",https://www3.cs.stonybrook.edu/~shecheng/Paper/ColormapND.pdf,"A wide variety of color schemes have been devised for mapping scalar data to color. We address the challenge of color-mapping multivariate data. While a number of methods can map low-dimensional data to color, for example, using bilinear or barycentric interpolation for two or three variables, these methods do not scale to higher data dimensions. Likewise, schemes that take a more artistic approach through color mixing and the like also face limits when it comes to the number of variables they can encode. Our approach does not have these limitations. It is data driven in that it determines a proper and consistent color map from first embedding the data samples into a circular interactive multivariate color mapping display (ICD) and then fusing this display with a convex (CIE HCL) color space. The variables (data attributes) are arranged in terms of their similarity and mapped to the ICD?s boundary to control the embedding. Using this layout, the color of a multivariate data sample is then obtained via modified generalized barycentric coordinate interpolation of the map. The system we devised has facilities for contrast and feature enhancement, supports both regular and irregular grids, can deal with multi-field as well as multispectral data, and can produce heat maps, choropleth maps, and diagrams such as scatterplots.",,,,,vimeo 289788955,10.1109/tvcg.2018.2808489,2018,2018,VAST,"Hall 1, Section C",Wednesday,High Dimensional Data,2022-10-24,3:20:00 PM,3:40:00 PM
openaccessvis2018.csv,VAST,VAST,EmbeddingVis: A Visual Analytics Approach to Comparative Network Embedding Inspection,C),"Quan Li, Kristanto Sean Njotoprawiro, Hammad Haleem, Qiaoan Chen, Chris YI, Xiaojuan Ma",https://arxiv.org/pdf/1808.09074.pdf,"Constructing latent vector representation for nodes in a network through embedding models has shown its practicality in many graph analysis applications, such as node classification, clustering, and link prediction. However, despite the high efficiency and accuracy of learning an embedding model, people have little clue of what information about the original network is preserved in the embedding vectors. The abstractness of low-dimensional vector representation, stochastic nature of the construction process, and non-transparent hyper-parameters all obscure understanding of network embedding results. Visualization techniques have been introduced to facilitate embedding vector inspection, usually by projecting the embedding space to a two-dimensional display. Although the existing visualization methods allow simple examination of the structure of embedding space, they cannot support in-depth exploration of the embedding vectors. In this paper, we design an exploratory visual analytics system that supports the comparative visual interpretation of embedding vectors at the cluster, instance, and structural levels. To be more specific, it facilitates comparison of what and how node metrics are preserved across different embedding models and investigation of relationships between node metrics and selected embedding vectors. Several case studies confirm the efficacy of our system. Experts? feedback suggests that our approach indeed helps them better embrace the understanding of network embedding models.",,,,,vimeo 289788000,,2018,2018,VAST,"Hall 1, Section C",Wednesday,High Dimensional Data,2022-10-24,3:40:00 PM,4:00:00 PM
openaccessvis2018.csv,InfoVis,TVCG,Evaluating 'Graphical Perception' with CNNs,,"Daniel Haehn, James Tompkin, Hanspeter Pfister",https://osf.io/8b9xs/,"Convolutional neural networks can successfully perform many computer vision tasks on images. For visualization, how do CNNs perform when applied to graphical perception tasks? We investigate this question by reproducing Cleveland and McGill's seminal 1984 experiments, which measured human perception efficiency of different visual encodings and defined elementary perceptual tasks for visualization. We measure the graphical perceptual capabilities of four network architectures on five different visualization tasks and compare to existing and new human performance baselines. While under limited circumstances CNNs are able to meet or outperform human task performance, we find that CNNs are not currently a good model for human graphical perception. We present the results of these experiments to foster the understanding of how CNNs succeed and fail when applied to data visualizations.",,https://github.com/rhoana/perception,https://osf.io/jsxdq/,,vimeo 280506639,10.1109/TVCG.2018.2865138,2018,2018,InfoVis,"Hall 1, Section D",Wednesday,Text & Communication,2022-10-24,2:20:00 PM,2:40:00 PM
openaccessvis2018.csv,InfoVis,TVCG,NLIZE: A Perturbation-Driven Visual Interrogation Tool for Analyzing and Interpreting Natural Language Inference Models,J),"Shusen Liu, Zhimin Li, Tao Li, Vivek Srikumar, Valerio Pascucci, Peer-Timo Bremer",http://www.sci.utah.edu/~shusenl/publications/paper_entailVis.pdf,"With the recent advances in deep learning, neural network models have obtained state-of-the-art performances for many linguistic tasks in natural language processing. However, this rapid progress also brings enormous challenges. The opaque nature of a neural network model leads to hard-to-debug-systems and difficult-to-interpret mechanisms. Here, we introduce a visualization system that, through a tight yet flexible integration between visualization elements and the underlying model, allows a user to interrogate the model by perturbing the input, internal state, and prediction while observing changes in other parts of the pipeline. We use the natural language inference problem as an example to illustrate how a perturbation-driven paradigm can help domain experts assess the potential limitation of a model, probe its inner states, and interpret and form hypotheses about fundamental model mechanisms such as attention.",,,,,vimeo 289784737,10.1109/tvcg.2018.2865230,2018,2018,InfoVis,"Hall 1, Section D",Wednesday,Text & Communication,2022-10-24,2:40:00 PM,3:00:00 PM
openaccessvis2018.csv,InfoVis,TVCG,Elastic Documents: Coupling Text and Tables through Contextual Visualizations for Enhanced Document Reading,J),"Sriram Karthik Badam, Zhicheng Liu, Niklas Elmqvist",http://users.umiacs.umd.edu/~elm/projects/elastic-documents/elastic-documents.pdf,"Today's data-rich documents are often complex datasets in themselves, consisting of information in different formats such as text, gures, and data tables. These additional media augment the textual narrative in the document. However, the static layout of a traditional for-print document often impedes deep understanding of its content because of the need to navigate to access content scattered throughout the text. In this paper, we seek to facilitate enhanced comprehension of such documents through a contextual visualization technique that couples text content with data tables contained in the document. We parse the text content and data tables, cross-link the components using a keyword-based matching algorithm, and generate on-demand visualizations based on the reader's current focus within a document. We evaluate this technique in a user study comparing our approach to a traditional reading experience. Results from our study show that (1) participants comprehend the content better with tighter coupling of text and data, (2) the contextual visualizations enable participants to develop better summaries that capture the main data-rich insights within the document, and (3) overall, our method enables participants to develop a more detailed understanding of the document content.",,,,,vimeo 289784966,10.1109/TVCG.2018.2865119,2018,2018,InfoVis,"Hall 1, Section D",Wednesday,Text & Communication,2022-10-24,3:00:00 PM,3:20:00 PM
openaccessvis2018.csv,InfoVis,TVCG,Augmenting Visualizations with Interactive Data Facts to Facilitate Interpretation and Communication,J),"Arjun Srinivasan, Steven Drucker, Alex Endert, John Stasko",https://arjun010.github.io/static/papers/voder-infovis18.pdf,"Recently, an increasing number of visualization systems have begun to incorporate natural language generation (NLG) capabilities into their interfaces. NLG-based visualization systems typically leverage a suite of statistical functions to automatically extract key facts about the underlying data and surface them as natural language sentences alongside visualizations. With current systems, users are typically required to read the system-generated sentences and mentally map them back to the accompanying visualization. However, depending on the features of the visualization (e.g., visualization type, data density) and the complexity of the data fact, mentally mapping facts to visualizations can be a challenging task. Furthermore, more than one visualization could be used to illustrate a single data fact. Unfortunately, current tools provide little or no support for users to explore such alternatives. In this paper, we explore how system-generated data facts can be treated as interactive widgets to help users interpret visualizations and communicate their findings. We present Voder, a system that lets users interact with automatically-generated data facts to explore both alternative visualizations to convey a data fact as well as a set of embellishments to highlight a fact within a visualization. Leveraging data facts as interactive widgets, Voder also facilitates data fact-based visualization search. To assess Voder's design and features, we conducted a preliminary user study with 12 participants having varying levels of experience with visualization tools. Participant feedback suggested that interactive data facts aided them in interpreting visualizations. Participants also stated that the suggestions surfaced through the facts helped them explore alternative visualizations and embellishments to communicate individual data facts.",,,,,vimeo 289784943,10.1109/tvcg.2018.2865145,2018,2018,InfoVis,"Hall 1, Section D",Wednesday,Text & Communication,2022-10-24,3:20:00 PM,3:40:00 PM
openaccessvis2018.csv,InfoVis,TVCG,What Do We Talk About When We Talk About Dashboards?,J),"Alper Sarikaya, Michael Correll, Lyn Bartram, Melanie Tory, Danyel A Fisher",https://alper.datav.is/assets/publications/dashboards/dashboards-preprint.pdf,"Dashboards are one of the most common use cases for data visualization, and their design and contexts of use are considerably different from exploratory visualization tools. In this paper, we look at the broad scope of how dashboards are used in practice through an analysis of dashboard examples and documentation about their use. We systematically review the literature surrounding dashboard use, construct a design space for dashboards, and identify major dashboard types. We characterize dashboards by their design goals, levels of interaction, and the practices around them. Our framework and literature review suggest a number of fruitful research directions to better support dashboard design, implementation, and use.",,,,,vimeo 289785315,10.1109/tvcg.2018.2864903,2018,2018,InfoVis,"Hall 1, Section D",Wednesday,Text & Communication,2022-10-24,3:40:00 PM,4:00:00 PM
openaccessvis2018.csv,SciVis,TVCG,Visualization of Bubble Formation in Porous Media,J),"Hui Zhang, Steffen Frey, Holger Steeb, David Uribe, Thomas Ertl, Wenping Wang",,,,,,,vimeo 290325359,10.1109/tvcg.2018.2864506,2018,2018,SciVis,Estrel Hall A+B,Wednesday,Space and Physics,2022-10-24,2:20:00 PM,2:40:00 PM
openaccessvis2018.csv,SciVis,TVCG,Gaia Sky: Navigating the Gaia Catalog,J),"Toni Sagrist… Sell‚s, Stefan Jordan, Thomas Mueller, Filip Sadlo",https://vcg.iwr.uni-heidelberg.de/static/publications/Sagrista2019gaiaSky.pdf,"In this paper, we present Gaia Sky, a free and open-source multiplatform 3D Universe system, developed since 2014 in the Data Processing and Analysis Consortium framework of ESA?s Gaia mission. Gaia?s data release 2 represents the largest catalog of the stars of our Galaxy, comprising 1.3 billion star positions, with parallaxes, proper motions, magnitudes, and colors. In this mission, Gaia Sky is the central tool for off-the-shelf visualization of these data, and for aiding production of outreach material. With its capabilities to effectively handle these data, to enable seamless navigation along the high dynamic range of distances, and at the same time to provide advanced visualization techniques including relativistic aberration and gravitational wave effects, currently no actively maintained cross-platform, modern, and open alternative exists.",,,,,vimeo 290325474,10.1109/tvcg.2018.2864508,2018,2018,SciVis,Estrel Hall A+B,Wednesday,Space and Physics,2022-10-24,2:40:00 PM,3:00:00 PM
openaccessvis2018.csv,SciVis,TVCG,Interactive 3D Visual Analysis of Atmospheric Fronts,J),"Michael Alexander Kern, Timothy David Hewson, Andreas Sch„fler, Rdiger Westermann, Marc Rautenhaus",http://www.in.tum.de/fileadmin/w00bws/cg/Research/Publications/2018/Atmospheric_Fronts/kern_fronts_vis2018.pdf,"Atmospheric fronts play a central role in meteorology, as the boundaries between different air masses and as fundamental features of extra-tropical cyclones. They appear in numerous conceptual model depictions of extra-tropical weather systems. Conceptually, fronts are three-dimensional surfaces in space possessing an innate structural complexity, yet in meteorology, both manual and objective identification and depiction have historically focused on the structure in two dimensions. In this work, we ?a team of visualization scientists and meteorologists? propose a novel visualization approach to analyze the three-dimensional structure of atmospheric fronts and related physical and dynamical processes. We build upon existing approaches to objectively identify fronts as lines in two dimensions and extend these to obtain frontal surfaces in three dimensions, using the magnitude of temperature change along the gradient of a moist potential temperature field as the primary identifying factor. We introduce the use of normal curves in the temperature gradient field to visualize a frontal zone (i.e., the transitional zone between the air masses) and the distribution of atmospheric variables in such zones. To enable for the first time a statistical analysis of frontal zones, we present a new approach to obtain the volume enclosed by a zone, by classifying grid boxes that intersect with normal curves emanating from a selected front. We introduce our method by means of an idealized numerical simulation and demonstrate its use with two real-world cases using numerical weather prediction data.",,,,,vimeo 290325737,10.1109/tvcg.2018.2864806,2018,2018,SciVis,Estrel Hall A+B,Wednesday,Space and Physics,2022-10-24,3:00:00 PM,3:20:00 PM
openaccessvis2018.csv,SciVis,TVCG,An Interactive Framework for Visualization of Weather Forecast Ensembles,J),"Bo Ma, Alireza Entezari",,,,,,,youtube 2tsXxxLsU7U,10.1109/tvcg.2018.2864815,2018,2018,SciVis,Estrel Hall A+B,Wednesday,Space and Physics,2022-10-24,3:20:00 PM,3:40:00 PM
openaccessvis2018.csv,TVCG,TVCG,Animation Plans for Before-And-After Satellite images,T),"Mar¡a-Jes£s Lobo, Caroline Appert, Emmanuel Pietriga",https://hal.inria.fr/hal-01773882/document,"Before-and-after image pairs show how entities in a given region have evolved over a specific period of time. Satellite images are a major source of such data, that capture how natural phenomena or human activity impact a geographical area. These images are used both for data analysis and to illustrate the resulting findings to diverse audiences. The simple techniques used to display them, including juxtaposing, swapping and monolithic blending, often fail to convey the underlying phenomenon in a meaningful manner. We introduce Baia, a framework to create advanced animated transitions, called animation plans, between before-and-after images. Baia relies on a pixel-based transition model that gives authors much expressive power, while keeping animations for common types of changes easy to create thanks to predefined animation primitives. We describe our model, the associated animation editor, and report on two user studies. In the first study, advanced transitions enabled by Baia were compared to monolithic blending, and perceived as more realistic and better at focusing viewer?s attention on a region of interest than the latter. The second study aimed at gathering feedback about the usability of Baia?s animation editor. ",,,,,vimeo 289789265,10.1109/TVCG.2018.2796557,2018,2018,SciVis,Estrel Hall A+B,Wednesday,Space and Physics,2022-10-24,3:40:00 PM,4:00:00 PM
openaccessvis2018.csv,VAST,TVCG,Vulnus: Visual Vulnerability Analysis for Network Security,J),"Marco Angelini, Graziano Blasilli, Tiziana Catarci, Simone Lenti, Giuseppe Santucci",,,,,,,vimeo 289787623,10.1109/tvcg.2018.2865028,2018,2018,VAST,"Hall 1, Section C",Thursday,"Security, Privacy, and Anomaly",2022-10-25,9:00:00 AM,9:20:00 AM
openaccessvis2018.csv,VAST,TVCG,GraphProtector: a Visual Interface for Employing and Assessing Multiple Privacy Preserving Graph Algorithms,J),"Xumeng Wang, Wei Chen, Huihua Guan, Wenlong Chen, Rusheng Pan, Jia-Kai Chou, Chris Bryan, Kwan-Liu Ma",http://www.cad.zju.edu.cn/home/vagblog/VAG_Work/GraphProtector.pdf,"Analyzing social networks reveals the relationships between individuals and groups in the data. However, such analysis can also lead to privacy exposure (whether intentionally or inadvertently): leaking the real-world identity of ostensibly anonymous individuals. Most sanitization strategies modify the graph's structure based on hypothesized tactics that an adversary would employ. While combining multiple anonymization schemes provides a more comprehensive privacy protection, deciding the appropriate set of techniques?along with evaluating how applying the strategies will affect the utility of the anonymized results?remains a signicant challenge. To address this problem, we introduce GraphProtector, a visual interface that guides a user through a privacy preservation pipeline. GraphProtector enables multiple privacy protection schemes which can be simultaneously combined together as a hybrid approach. To demonstrate the effectiveness of GraphProtector, we report several case studies and feedback collected from interviews with expert users in various scenarios.",,,,,vimeo 289787471,10.1109/TVCG.2018.2865021,2018,2018,VAST,"Hall 1, Section C",Thursday,"Security, Privacy, and Anomaly",2022-10-25,9:20:00 AM,9:40:00 AM
openaccessvis2018.csv,VAST,TVCG,Situ: Identifying and explaining suspicious behavior in networks,J),"John Goodall, Eric Ragan, Chad Steed, Joel Reed, Gregory Richardson, Kelly Huffer, Robert Bridges, Jason Laska",https://www.cise.ufl.edu/~eragan/papers/Goodall_Situ_2018.pdf,"Despite the best efforts of cyber security analysts, networked computing assets are routinely compromised, resulting in the loss of intellectual property, the disclosure of state secrets, and major nancial damages. Anomaly detection methods are benecial for detecting new types of attacks and abnormal network activity, but such algorithms can be difcult to understand and trust. Network operators and cyber analysts need fast and scalable tools to help identify suspicious behavior that bypasses automated security systems, but operators do not want another automated tool with algorithms they do not trust. Experts need tools to augment their own domain expertise and to provide a contextual understanding of suspicious behavior to help them make decisions. In this paper we present Situ, a visual analytics system for discovering suspicious behavior in streaming network data. Situ provides a scalable solution that combines anomaly detection with information visualization. The system's visualizations enable operators to identify and investigate the most anomalous events and IP addresses, and the tool provides context to help operators understand why they are anomalous. Finally, operators need tools that can be integrated into their workow and with their existing tools. This paper describes the Situ platform and its deployment in an operational network setting. We discuss how operators are currently using the tool in a large organization's security operations center and present the results of expert reviews with professionals.",,,,,vimeo 289787635,10.1109/TVCG.2018.2865029,2018,2018,VAST,"Hall 1, Section C",Thursday,"Security, Privacy, and Anomaly",2022-10-25,9:40:00 AM,10:00:00 AM
openaccessvis2018.csv,VAST,TVCG,A Visual Analytics Framework for the Detection of Anomalous Call Stack Trees in High Performance Computing Applications,J),"Cong Xie, Wei Xu, Klaus Mueller",,,,,,,vimeo 289787924,10.1109/tvcg.2018.2865026,2018,2018,VAST,"Hall 1, Section C",Thursday,"Security, Privacy, and Anomaly",2022-10-25,10:00:00 AM,10:20:00 AM
openaccessvis2018.csv,VAST,TVCG,Lessons Learned Developing a Visual Analytics Solution for Investigative Analysis of Scamming Activities,J),"Jay Koven, Cristian Felix, Hossein Siadati, Enrico Bertini, Markus Jakobsson",,,,,,,vimeo 289787515,10.1109/tvcg.2018.2865023,2018,2018,VAST,"Hall 1, Section C",Thursday,"Security, Privacy, and Anomaly",2022-10-25,10:20:00 AM,10:40:00 AM
openaccessvis2018.csv,InfoVis,TVCG,Origin-Destination Flow Maps in Immersive Environments,J),"Yalong Yang, Tim Dwyer, Bernhard Jenny, Kim Marriott, Maxime Cordeil, Haohui Chen",https://ialab.it.monash.edu/~dwyer/papers/flow-maps-ia.pdf,"Immersive virtual- and augmented-reality headsets can overlay a flat image against any surface or hang virtual objects in the space around the user. The technology is rapidly improving and may, in the long term, replace traditional flat panel displays in many situations. When displays are no longer intrinsically flat, how should we use the space around the user for abstract data visualisation? In this paper, we ask this question with respect to origin-destination flow data in a global geographic context. We report on the findings of three studies exploring different spatial encodings for flow maps. The first experiment focuses on different 2D and 3D encodings for flows on flat maps. We find that participants are significantly more accurate with raised flow paths whose height is proportional to flow distance but fastest with traditional straight line 2D flows. In our second and third experiment we compared flat maps, 3D globes and a novel interactive design we call <i>MapsLink</i>, involving a pair of linked flat maps. We find that participants took significantly more time with MapsLink than other flow maps while the 3D globe with raised flows was the fastest, most accurate, and most preferred method. Our work suggests that <i>careful</i> use of the third spatial dimension can resolve visual clutter in complex flow maps.",,,,,vimeo 279605506,10.1109/tvcg.2018.2865192,2018,2018,InfoVis,"Hall 1, Section D",Thursday,Immersive Analytics,2022-10-25,9:00:00 AM,9:20:00 AM
openaccessvis2018.csv,InfoVis,TVCG,FiberClay: Sculpting Three Dimensional Trajectories to Reveal Structural Insights,J),"Christophe Hurter, Nathalie Henry Riche, Steven Drucker, Maxime Cordeil, Richard Alligier, Romain Vuillemot",https://recherche.enac.fr/~hurter/FiberClay/FiberClay2018.pdf,"Visualizing 3D trajectories to extract insights about their similarities and spatial configuration is a critical task in several domains. Air traffic controllers for example deal with large quantities of aircrafts routes to optimize safety in airspace and neuroscientists attempt to understand neuronal pathways in the human brain by visualizing bundles of fibers from DTI images. Extracting insights from masses of 3D trajectories is challenging as the multiple three dimensional lines have complex geometries, may overlap, cross or even merge with each other, making it impossible to follow individual ones in dense areas. As trajectories are inherently spatial and three dimensional, we propose FiberClay: a system to display and interact with 3D trajectories in immersive environments. FiberClay renders a large quantity of trajectories in real time using GP-GPU techniques. FiberClay also introduces a new set of interactive techniques for composing complex queries in 3D space leveraging immersive environment controllers and user position. These techniques enable an analyst to select and compare sets of trajectories with specific geometries and data properties. We conclude by discussing insights found using FiberClay with domain experts in air traffic control and neurology.",,,,,vimeo 289784766,10.1109/tvcg.2018.2865191,2018,2018,InfoVis,"Hall 1, Section D",Thursday,Immersive Analytics,2022-10-25,9:20:00 AM,9:40:00 AM
openaccessvis2018.csv,InfoVis,TVCG,DXR: A Toolkit for Building Immersive Data Visualizations,J),"Ronell Sicat, Jiabao Li, JunYoung Choi, Maxime Cordeil, Won-Ki Jeong, Benjamin Bach, Hanspeter Pfister",https://vcg.seas.harvard.edu/publications/dxr-a-toolkit-for-building-immersive-data-visualizations/paper,"This paper presents DXR, a toolkit for building immersive data visualizations based on the Unity development platform. Over the past years, immersive data visualizations in augmented and virtual reality (AR, VR) have been emerging as a promising medium for data sense-making beyond the desktop. However, creating immersive visualizations remains challenging, and often require complex low-level programming and tedious manual encoding of data attributes to geometric and visual properties. These can hinder the iterative idea-to-prototype process, especially for developers without experience in 3D graphics, AR, and VR programming. With DXR, developers can efficiently specify visualization designs using a concise declarative visualization grammar inspired by Vega-Lite. DXR further provides a GUI for easy and quick edits and previews of visualization designs in-situ, i.e., while immersed in the virtual world. DXR also provides reusable templates and customizable graphical marks, enabling unique and engaging visualizations. We demonstrate the flexibility of DXR through several examples spanning a wide range of applications.",,https://sites.google.com/view/dxr-vis/,,,youtube p4fB_OfoaZA,10.1109/tvcg.2018.2865152,2018,2018,InfoVis,"Hall 1, Section D",Thursday,Immersive Analytics,2022-10-25,9:40:00 AM,10:00:00 AM
openaccessvis2018.csv,InfoVis,TVCG,Information Olfactation: Harnessing Scent to Convey Data,J),"Biswaksen Patnaik, Andrea Batch, Niklas Elmqvist",http://users.umiacs.umd.edu/~elm/projects/info-olfac/info-olfac.pdf,"Olfactory feedback for analytical tasks is a virtually unexplored area in spite of the advantages it offers for information recall, feature identification, and location detection. Here we introduce the concept of information olfactation as the fragrant sibling of information visualization, and discuss how scent can be used to convey data. Building on a review of the human olfactory system and mirroring common visualization practice, we propose olfactory marks, the substrate in which they exist, and their olfactory channels that are available to designers. To exemplify this idea, we present VISCENT: A six-scent stereo olfactory display capable of conveying olfactory glyphs of varying temperature and direction, as well as a corresponding software system that integrates the display with a traditional visualization display. Finally, we present three applications that make use of the viScent system: A 2D graph visualization, a 2D line and point chart, and an immersive analytics graph visualization in 3D virtual reality. We close the paper with a review of possible extensions of viScent and applications of information olfactation for general visualization beyond the examples in this paper.",,,,,vimeo 289784509,10.1109/tvcg.2018.2865237,2018,2018,InfoVis,"Hall 1, Section D",Thursday,Immersive Analytics,2022-10-25,10:00:00 AM,10:20:00 AM
openaccessvis2018.csv,InfoVis,TVCG,Dynamic Composite Data Physicalization Using Wheeled Micro-Robots,J),"Mathieu Le Goc, Charles Perin, Sean Follmer, Jean-Daniel Fekete, Pierre Dragicevic",https://hal.inria.fr/hal-01848436/document,"This paper introduces dynamic composite physicalizations, a new class of physical visualizations that use collections of self-propelled objects to represent data. Dynamic composite physicalizations can be used both to give physical form to well-known interactive visualization techniques, and to explore new visualizations and interaction paradigms. We first propose a design space characterizing composite physicalizations based on previous work in the fields of Information Visualization and Human Computer Interaction. We illustrate dynamic composite physicalizations in two scenarios demonstrating potential benefits for collaboration and decision making, as well as new opportunities for physical interaction. We then describe our implementation using wheeled micro-robots capable of locating themselves and sensing user input, before discussing limitations and opportunities for future work.",,,,,vimeo 289784806,10.1109/tvcg.2018.2865159,2018,2018,InfoVis,"Hall 1, Section D",Thursday,Immersive Analytics,2022-10-25,10:20:00 AM,10:40:00 AM
openaccessvis2018.csv,SciVis,TVCG,Robust and Fast Extraction of 3D Symmetric Tensor Field Topology,J),"Lawrence Roy, Prashant Kumar, Yue Zhang, Eugene Zhang",http://web.engr.oregonstate.edu/~zhange/images/3DTensorTopology_Detection.pdf,"3D symmetric tensor fields appear in many science and engineering domains, and topology-driven analysis is important in many of these application domains, such as solid mechanics and fluid dynamics. Degenerate curves and neutral surfaces are important topological features in 3D symmetric tensor fields. Existing methods to extract degenerate curves and neutral surfaces often miss parts of the curves and surfaces, respectively. Moreover, they are relatively expensive to extract. These issues are due to the lack of knowledge of their overall structures. In this paper, we provide theoretical analysis on the geometric and topological structures of degenerate curves and neutral surfaces of 3D linear tensor fields. These structures lead to parameterizations for degenerate curves and neutral surfaces that can not only provide more robust extraction of these features but also incur less computational cost. We demonstrate the benefits of our approach by applying our degenerate curve and neutral surface detection to solid mechanics simulation data sets.",,,,,vimeo 290325698,10.1109/tvcg.2018.2864768,2018,2018,SciVis,Estrel Hall A+B,Thursday,Tensors,2022-10-25,9:00:00 AM,9:20:00 AM
openaccessvis2018.csv,SciVis,TVCG,DT-MRI Streamsurfaces Revisited,J),"Michael Ankele, Thomas Schultz",http://cg.cs.uni-bonn.de/aigaion2root/attachments/ankele-vis18.pdf,"DT-MRI streamsurfaces, defined as surfaces that are everywhere tangential to the major and medium eigenvector fields, have been proposed as a tool for visualizing regions of predominantly planar behavior in diffusion tensor MRI. Even though it has long been known that their construction assumes that the involved eigenvector fields satisfy an integrability condition, it has never been tested systematically whether this condition is met in real-world data. We introduce a suitable and efficiently computable test to the visualization literature, demonstrate that it can be used to distinguish integrable from nonintegrable configurations in simulations, and apply it to whole-brain datasets of 15 healthy subjects. We conclude that streamsurface integrability is approximately satisfied in a substantial part of the brain, but not everywhere, including some regions of planarity. As a consequence, algorithms for streamsurface extraction should explicitly test local integrability. Finally, we propose a novel patch-based approch to streamsurface visualization that reduces visual artifacts, and is shown to more fully sample the extent of streamsurfaces.",,,,,vimeo 290327825,10.1109/tvcg.2018.2864845,2018,2018,SciVis,Estrel Hall A+B,Thursday,Tensors,2022-10-25,9:20:00 AM,9:40:00 AM
openaccessvis2018.csv,SciVis,TVCG,Tensor Field Visualization using Fiber Surfaces of Invariant Space,J),"Felix Raith, Christian Blecha, Thomas Nagel, Francesco Parisio, Olaf Kolditz, Fabian Gnther, Markus Stommel, Gerik Scheuermann",,,,,,,vimeo 290327914,10.1109/tvcg.2018.2864846,2018,2018,SciVis,Estrel Hall A+B,Thursday,Tensors,2022-10-25,9:40:00 AM,10:00:00 AM
openaccessvis2018.csv,TVCG,TVCG,Tensor Decompositions for Integral Histogram Compression and Look-Up,T),"Rafael Ballester-Ripoll, Renato Pajarola",,,,https://github.com/rballester/tthistograms,,,vimeo 289788992,10.1109/tvcg.2018.2802521,2018,2018,SciVis,Estrel Hall A+B,Thursday,Tensors,2022-10-25,10:00:00 AM,10:20:00 AM
openaccessvis2018.csv,VAST,TVCG,An Interactive Method to Improve Crowdsourced Annotations,J),"Shixia Liu, Changjian Chen, Yafeng Lu, Fangxin Ouyang, Bin Wang",http://www.shixialiu.com/publications/LabelInspect/paper.pdf,"In order to effectively infer correct labels from noisy crowdsourced annotations, learning-from-crowds models have introduced expert validation. However, little research has been done on facilitating the validation procedure. In this paper, we propose an interactive method to assist experts in verifying uncertain instance labels and unreliable workers. Given the instance labels and worker reliability inferred from a learning-from-crowds model, candidate instances and workers are selected for expert validation. The influence of verified results is propagated to relevant instances and workers through the learning-from-crowds model. To facilitate the validation of annotations, we have developed a confusion visualization to indicate the confusing classes for further exploration, a constrained projection method to show the uncertain labels in context, and a scatter-plot-based visualization to illustrate worker reliability. The three visualizations are tightly integrated with the learning-from-crowds model to provide an iterative and progressive environment for data validation. Two case studies were conducted that demonstrate our approach offers an efficient method for validating and improving crowdsourced annotations.",,,,,vimeo 289787374,10.1109/TVCG.2018.2864843,2018,2018,VAST,Estrel Hall C,Thursday,Interactive Analytics and Design,2022-10-25,9:00:00 AM,9:20:00 AM
openaccessvis2018.csv,VAST,TVCG,RegressionExplorer: Interactive Exploration of Logistic Regression Models with Subgroup Analysis,J),"Dennis Dingen, Marcel van 't Veer, Patrick Houthuizen, Eveline H. J. Mestrom, Erik H.H.M. Korsten, Arthur R.A. Bouwman, Jarke van Wijk",,,,,,,vimeo 289787606,10.1109/tvcg.2018.2865043,2018,2018,VAST,Estrel Hall C,Thursday,Interactive Analytics and Design,2022-10-25,9:20:00 AM,9:40:00 AM
openaccessvis2018.csv,VAST,TVCG,Drag and Track:  A Direct Manipulation Interface for Contextualizing Data Instances within a Continuous Parameter Space,J),"Daniel Orban, Daniel Keefe, Ayan Biswas, James Ahrens, David Rogers",http://ayanbiswas.net/orban_18.pdf,"We present a direct manipulation technique that allows material scientists to interactively highlight relevant parameterized simulation instances located in dimensionally reduced spaces, enabling a user-defined understanding of a continuous parameter space. Our goals are two-fold: first, to build a user-directed intuition of dimensionally reduced data, and second, to provide a mechanism for creatively exploring parameter relationships in parameterized simulation sets, called ensembles. We start by visualizing ensemble data instances in dimensionally reduced scatter plots. To understand these abstract views, we employ user-defined virtual data instances that, through direct manipulation, search an ensemble for similar instances. Users can create multiple of these direct manipulation queries to visually annotate the spaces with sets of highlighted ensemble data instances. User-defined goals are therefore translated into custom illustrations that are projected onto the dimensionally reduced spaces. Combined forward and inverse searches of the parameter space follow naturally allowing for continuous parameter space prediction and visual query comparison in the context of an ensemble. The potential for this visualization technique is confirmed via expert user feedback for a shock physics application and synthetic model analysis.",,,,,vimeo 289787986,10.1109/TVCG.2018.2865051,2018,2018,VAST,Estrel Hall C,Thursday,Interactive Analytics and Design,2022-10-25,9:40:00 AM,10:00:00 AM
openaccessvis2018.csv,VAST,TVCG,Clustrophile 2: Guided Visual Clustering Analysis,J),"Marco Cavallo, €agatay Demiralp",https://arxiv.org/pdf/1804.03048.pdf,"Data clustering is a common unsupervised learning method frequently used in exploratory data analysis. However, identifying relevant structures in unlabeled, high-dimensional data is nontrivial, requiring iterative experimentation with clustering parameters as well as data features and instances. The number of possible clusterings for a typical dataset is vast, and navigating in this vast space is also challenging. The absence of ground-truth labels makes it impossible to define an optimal solution, thus requiring user judgment to establish what can be considered a satisfiable clustering result. Data scientists need adequate interactive tools to effectively explore and navigate the large clustering space so as to improve the effectiveness of exploratory clustering analysis. We introduce Clustrophile 2, a new interactive tool for guided clustering analysis. Clustrophile 2 guides users in clustering-based exploratory analysis, adapts user feedback to improve user guidance, facilitates the interpretation of clusters, and helps quickly reason about differences between clusterings. To this end, Clustrophile 2 contributes a novel feature, the Clustering Tour, to help users choose clustering parameters and assess the quality of different clustering results in relation to current analysis goals and user expectations. We evaluate Clustrophile 2 through a user study with 12 data scientists, who used our tool to explore and interpret sub-cohorts in a dataset of Parkinson?s disease patients. Results suggest that Clustrophile 2 improves the speed and effectiveness of exploratory clustering analysis for both experts and non-experts.",,,,,vimeo 289787185,10.1109/TVCG.2018.2864477,2018,2018,VAST,Estrel Hall C,Thursday,Interactive Analytics and Design,2022-10-25,10:00:00 AM,10:20:00 AM
openaccessvis2018.csv,VAST,TVCG,InkPlanner: Supporting Prewriting via Intelligent Visual Diagramming,J),"Zhicong Lu, Mingming Fan, Yun Wang, Jian Zhao, Michelle Annett, Daniel Wigdor",http://mingmingfan.com/papers/InkPlanner_TVCG.pdf,"Prewriting is the process of generating and organizing ideas before drafting a document. Although often overlooked by novice writers and writing tool developers, prewriting is a critical process that improves the quality of a final document. To better understand current prewriting practices, we first conducted interviews with writing learners and experts. Based on the learners? needs and experts? recommendations, we then designed and developed InkPlanner, a novel pen and touch visualization tool that allows writers to utilize visual diagramming for ideation during prewriting. InkPlanner further allows writers to sort their ideas into a logical and sequential narrative by using a novel widget? NarrativeLine. Using a NarrativeLine, InkPlanner can automatically generate a document outline to guide later drafting exercises. Inkplanner is powered by machine-generated semantic and structural suggestions that are curated from various texts. To qualitatively review the tool and understand how writers use InkPlanner for prewriting, two writing experts were interviewed and a user study was conducted with university students. The results demonstrated that InkPlanner encouraged writers to generate more diverse ideas and also enabled them to think more strategically about how to organize their ideas for later drafting.",,,,,vimeo 289787883,10.1109/tvcg.2018.2864887,2018,2018,VAST,Estrel Hall C,Thursday,Interactive Analytics and Design,2022-10-25,10:20:00 AM,10:40:00 AM
openaccessvis2018.csv,TVCG,TVCG,Visual Analytics in Deep Learning: An Interrogative Survey for the Next Frontiers,T),"Fred Hohman, Minsuk Kahng, Robert Pienta, Duen Horng Chau",https://arxiv.org/pdf/1801.06889.pdf,"Deep learning has recently seen rapid development and received significant attention due to its state-of-the-art performance on previously-thought hard problems. However, because of the internal complexity and nonlinear structure of deep neural networks, the underlying decision making processes for why these models are achieving such performance are challenging and sometimes mystifying to interpret. As deep learning spreads across domains, it is of paramount importance that we equip users of deep learning with tools for understanding when a model works correctly, when it fails, and ultimately how to improve its performance. Standardized toolkits for building neural networks have helped democratize deep learning; visual analytics systems have now been developed to support model explanation, interpretation, debugging, and improvement. We present a survey of the role of visual analytics in deep learning research, which highlights its short yet impactful history and thoroughly summarizes the state-of-the-art using a human-centered interrogative framework, focusing on the Five W's and How (Why, Who, What, How, When, and Where). We conclude by highlighting research directions and open research problems. This survey helps researchers and practitioners in both visual analytics and deep learning to quickly learn key aspects of this young and rapidly growing body of research, whose impact spans a diverse range of domains.",,,,,vimeo 289789596,10.1109/tvcg.2018.2843369,2018,2018,VAST,"Hall 1, Section C",Thursday,Deep Learning,2022-10-25,11:00:00 AM,11:20:00 AM
openaccessvis2018.csv,VAST,VAST,Analyzing the Noise Robustness of Deep Neural Networks,C),"Mengchen Liu, Shixia Liu, Hang Su, Kelei Cao, Jun Zhu",http://www.shixialiu.com/publications/aevis/paper.pdf,"Deep neural networks (DNNs) are vulnerable to maliciously generated adversarial examples. These examples are intentionally designed by making imperceptible perturbations and often mislead a DNN into making an incorrect prediction. This phenomenon means that there is significant risk in applying DNNs to safety-critical applications, such as driverless cars. To address this issue, we present a visual analytics approach to explain the primary cause of the wrong predictions introduced by adversarial examples. The key is to analyze the datapaths of the adversarial examples and compare them with those of the normal examples. A datapath is a group of critical neurons and their connections. To this end, we formulate the datapath extraction as a subset selection problem and approximately solve it based on back-propagation. A multi-level visualization consisting of a segmented DAG (layer level), an Euler diagram (feature map level), and a heat map (neuron level), has been designed to help experts investigate datapaths from the high-level layers to the detailed neuron activations. Two case studies are conducted that demonstrate the promise of our approach in support of explaining the working mechanism of adversarial examples.",,,,,vimeo 289787703,,2018,2018,VAST,"Hall 1, Section C",Thursday,Deep Learning,2022-10-25,11:20:00 AM,11:40:00 AM
openaccessvis2018.csv,VAST,TVCG,DQNViz: A Visual Analytics Approach to Understand Deep Q-Networks,J),"Junpeng Wang, Liang Gou, Han-Wei Shen, Hao Yang",http://edda-project.github.io/files/2018-08-13/dqnvis.pdf,"Deep Q-Network (DQN), as one type of deep reinforcement learning model, targets to train an intelligent agent that acquires optimal actions while interacting with an environment. The model is well known for its ability to surpass professional human players across many Atari 2600 games. Despite the superhuman performance, in-depth understanding of the model and interpreting the sophisticated behaviors of the DQN agent remain to be challenging tasks, due to the long-time model training process and the large number of experiences dynamically generated by the agent. In this work, we propose DQNViz, a visual analytics system to expose details of the blind training process in four levels, and enable users to dive into the large experience space of the agent for comprehensive analysis. As an initial attempt in visualizing DQN models, our work focuses more on Atari games with a simple action space, most notably the Breakout game. From our visual analytics of the agent?s experiences, we extract useful action/reward patterns that help to interpret the model and control the training. Through multiple case studies conducted together with deep learning experts, we demonstrate that DQNViz can effectively help domain experts to understand, diagnose, and potentially improve DQN models.",,,,,vimeo 289787246,10.1109/tvcg.2018.2864504,2018,2018,VAST,"Hall 1, Section C",Thursday,Deep Learning,2022-10-25,11:40:00 AM,12:00:00 PM
openaccessvis2018.csv,VAST,TVCG,RetainVis: Visual Analytics with Interpretable and Interactive Recurrent Neural Network on Electronic Medical Records,J),"Bum Chul Kwon, Min-Je Choi, Joanne Kim, Edward Choi, Young Bin Kim, Soonwook Kwon, Jimeng Sun, Jaegul Choo",https://arxiv.org/pdf/1805.10724.pdf,"We have recently seen many successful applications of recurrent neural networks (RNNs) on electronic medical records (EMRs), which contain histories of patients? diagnoses, medications, and other various events, in order to predict the current and future states of patients. Despite the strong performance of RNNs, it is often challenging for users to understand why the model makes a particular prediction. Such black-box nature of RNNs can impede its wide adoption in clinical practice. Furthermore, we have no established methods to interactively leverage users? domain expertise and prior knowledge as inputs for steering the model. Therefore, our design study aims to provide a visual analytics solution to increase interpretability and interactivity of RNNs via a joint effort of medical experts, artificial intelligence scientists, and visual analytics researchers. Following the iterative design process between the experts, we design, implement, and evaluate a visual analytics tool called RetainVis, which couples a newly improved, interpretable, and interactive RNN-based model called RetainEX and visualizations for users? exploration of EMR data in the context of prediction tasks. Our study shows the effective use of RetainVis for gaining insights into how individual medical codes contribute to making risk predictions, using EMRs of patients with heart failure and cataract symptoms. Our study also demonstrates how we made substantial changes to the state-of-the-art RNN model called RETAIN in order to make use of temporal information and increase interactivity. This study will provide a useful guideline for researchers that aim to design an interpretable and interactive visual analytics tool for RNNs",,,,,vimeo 289787946,10.1109/TVCG.2018.2865027,2018,2018,VAST,"Hall 1, Section C",Thursday,Deep Learning,2022-10-25,12:00:00 PM,12:20:00 PM
openaccessvis2018.csv,VAST,TVCG,GAN Lab: Understanding Complex Deep Generative Models using Interactive Visual Experimentation,J),"Minsuk Kahng, Nikhil Thorat, Duen Horng Chau, Fernanda Viegas, Martin Wattenberg",https://arxiv.org/pdf/1809.01587.pdf,"Recent success in deep learning has generated immense interest among practitioners and students, inspiring many to learn about this new technology. While visual and interactive approaches have been successfully developed to help people more easily learn deep learning, most existing tools focus on simpler models. In this work, we present GAN Lab, the first interactive visualization tool designed for non-experts to learn and experiment with Generative Adversarial Networks (GANs), a popular class of complex deep learning models. With GAN Lab, users can interactively train generative models and visualize the dynamic training process?s intermediate results. GAN Lab tightly integrates an model overview graph that summarizes GAN?s structure, and a layered distributions view that helps users interpret the interplay between submodels. GAN Lab introduces new interactive experimentation features for learning complex deep learning models, such as step-by-step training at multiple levels of abstraction for understanding intricate training dynamics. Implemented using TensorFlow.js, GAN Lab is accessible to anyone via modern web browsers, without the need for installation or specialized hardware, overcoming a major practical challenge in deploying interactive tools for deep learning.",,,,,vimeo 289787794,10.1109/tvcg.2018.2864500,2018,2018,VAST,"Hall 1, Section C",Thursday,Deep Learning,2022-10-25,12:20:00 PM,12:40:00 PM
openaccessvis2018.csv,InfoVis,TVCG,A Framework for Creative Visualization-Opportunities Workshops,J),"Ethan Kerzner, Sarah Goodwin, Jason Dykes, Sara V Jones, Miriah Meyer",http://sci.utah.edu/~vdl/papers/2018_infovis_creative-workshops.pdf,"Applied visualization researchers often work closely with domain collaborators to explore new and useful applications of visualization. The early stages of collaborations are typically time consuming for all stakeholders as researchers piece together an understanding of domain challenges from disparate discussions and meetings. A number of recent projects, however, report on the use of creative visualization-opportunities (CVO) workshops to accelerate the early stages of applied work, eliciting a wealth of requirements in a few days of focused work. Yet, there is no established guidance for how to use such workshops effectively. In this paper, we present the results of a 2-year collaboration in which we analyzed the use of 17 workshops in 10 visualization contexts. Its primary contribution is a framework for CVO workshops that: 1) identifies a process model for using workshops; 2) describes a structure of what happens within effective workshops; 3) recommends 25 actionable guidelines for future workshops; and 4) presents an example workshop and workshop methods. The creation of this framework exemplifies the use of critical reflection to learn about visualization in practice from diverse studies and experience.",,,,,vimeo 289784415,10.1109/tvcg.2018.2865241,2018,2018,InfoVis,"Hall 1, Section D",Thursday,Design & Storytelling,2022-10-25,11:00:00 AM,11:20:00 AM
openaccessvis2018.csv,TVCG,TVCG,ATOM: A Grammar for Unit Visualizations,T),"Deokgun Park, Steven M. Drucker, Roland Fernandez, Niklas Elmqvist",http://users.umiacs.umd.edu/~elm/projects/atom/atom.pdf,"Unit visualizations are a family of visualizations where every data item is represented by a unique visual mark?a visual unit?during visual encoding. For certain datasets and tasks, unit visualizations can provide more information, better match the user?s mental model, and enable novel interactions compared to traditional aggregated visualizations. Current visualization grammars cannot fully describe the unit visualization family. In this paper, we characterize the design space of unit visualizations to derive a grammar that can express them. The resulting grammar is called <span style=""font-variant: small-caps;"">ATOM<span>, and is based on passing data through a series of layout operations that divide the output of previous operations recursively until the size and position of every data point can be determined. We evaluate the expressive power of the grammar by both using it to describe existing unit visualizations, as well as to suggest new unit visualizations.",https://intuinno.github.io/unit/#/live,,,,vimeo 289789243,10.1109/tvcg.2017.2785807,2017,2018,InfoVis,"Hall 1, Section D",Thursday,Design & Storytelling,2022-10-25,11:20:00 AM,11:40:00 AM
openaccessvis2018.csv,InfoVis,TVCG,Design Exposition with Literate Visualization,J),"Jo Wood, Alexander Kachkaev, Jason Dykes",http://openaccess.city.ac.uk/20081/1/wood_literate_2018.pdf,"We propose a new approach to the visualization design and communication process, literate visualization, based upon and extending, Donald Knuth's idea of literate programming. It integrates the process of writing data visualization code with description of the design choices that led to the implementation (design exposition). We develop a model of design exposition characterised by four visualization designer architypes: the evaluator, the autonomist, the didacticist and the rationalist. The model is used to justify the key characteristics of literate visualization: 'notebook' documents that integrate live coding input, rendered output and textual narrative; low cost of authoring textual narrative; guidelines to encourage structured visualization design and its documentation. We propose narrative schemas for structuring and validating a wide range of visualization design approaches and models, and branching narratives for capturing alternative designs and design views. We describe a new open source literate visualization environment, litvis, based on a declarative interface to Vega and Vega-Lite through the functional programming language Elm combined with markdown for formatted narrative. We informally assess the approach, its implementation and potential by considering three examples spanning a range of design abstractions: new visualization idioms; validation though visualization algebra; and feminist data visualization. We argue that the rich documentation of the design process provided by literate visualization offers the potential to improve the validity of visualization design and so benefit both academic visualization and visualization practice.",,https://github.com/gicentre/litvis,,,vimeo 289785349,10.1109/tvcg.2018.2864836,2018,2018,InfoVis,"Hall 1, Section D",Thursday,Design & Storytelling,2022-10-25,11:40:00 AM,12:00:00 PM
openaccessvis2018.csv,InfoVis,TVCG,iStoryline: Effective Convergence to Hand-drawn Storylines,J),"Tan Tang, Sadia Rubab, Jiewen Lai, Weiwei Cui, Lingyun Yu, Yingcai Wu",http://zjuvis.org/files/istoryline.pdf,"Storyline visualization techniques have progressed significantly to generate illustrations of complex stories automatically. However, the visual layouts of storylines are not enhanced accordingly despite the improvement in the performance and extension of its application area. Existing methods attempt to achieve several shared optimization goals, such as reducing empty space and minimizing line crossings and wiggles. However, these goals do not always produce optimal results when compared to hand-drawn storylines. We conducted a preliminary study to learn how users translate a narrative into a hand-drawn storyline and check whether the visual elements in hand-drawn illustrations can be mapped back to appropriate narrative contexts. We also compared the hand-drawn storylines with storylines generated by the state-of-the-art methods and found they have significant differences. Our findings led to a design space that summarizes 1) how artists utilize narrative elements and 2) the sequence of actions artists follow to portray expressive and attractive storylines. We developed iStoryline, an authoring tool for integrating high-level user interactions into optimization algorithms and achieving a balance between hand-drawn storylines and automatic layouts. iStoryline allows users to create novel storyline visualizations easily according to their preferences by modifying the automatically generated layouts. The effectiveness and usability of iStoryline are studied with qualitative evaluations",https://istoryline.github.io/,,https://istoryline.github.io/interview/interview.html,,video https://istoryline.github.io/img/iStoryline.mp4,10.1109/tvcg.2018.2864899,2018,2018,InfoVis,"Hall 1, Section D",Thursday,Design & Storytelling,2022-10-25,12:00:00 PM,12:20:00 PM
openaccessvis2018.csv,InfoVis,TVCG,Narvis: Authoring Narrative Slideshows for Introducing Data Visualization Designs,J),"Qianwen Wang, Zhen Li, Siwei Fu, Weiwei Cui, Huamin Qu",https://wangqianwen0418.github.io/assets/pdf/Narvis.pdf,"Visual designs can be complex in modern data visualization systems, which poses special challenges for explaining them to the non-experts. However, few if any presentation tools are tailored for this purpose. In this study, we present Narvis, a slideshow authoring tool designed for introducing data visualizations to non-experts. Narvis targets two types of end users: teachers, experts in data visualization who produce tutorials for explaining a data visualization, and students, non-experts who try to understand visualization designs through tutorials. We present an analysis of requirements through close discussions with the two types of end users. The resulting considerations guide the design and implementation of Narvis. Additionally, to help teachers better organize their introduction slideshows, we specify a data visualization as a hierarchical combination of components, which are automatically detected and extracted by Narvis. The teachers craft an introduction slideshow through first organizing these components, and then explaining them sequentially. A series of templates are provided for adding annotations and animations to improve efficiency during the authoring process. We evaluate Narvis through a qualitative analysis of the authoring experience, and a preliminary evaluation of the generated slideshows.",,,,,vimeo 289784711,10.1109/tvcg.2018.2865232,2018,2018,InfoVis,"Hall 1, Section D",Thursday,Design & Storytelling,2022-10-25,12:20:00 PM,12:40:00 PM
openaccessvis2018.csv,SciVis,TVCG,Culling for Extreme-Scale Segmentation Volumes: A Hybrid Deterministic and Probabilistic Approach,J),"Johanna Beyer, Haneen Mohammed, Marco Agus, Ali K. Al-Awami, Hanspeter Pfister, Markus Hadwiger",http://vccvisualization.org/publications/2018_beyer_hybridculling.pdf,"With the rapid increase in raw volume data sizes, such as terabyte-sized microscopy volumes, the corresponding segmentation label volumes have become extremely large as well. We focus on integer label data, whose efficient representation in memory, as well as fast random data access, pose an even greater challenge than the raw image data. Often, it is crucial to be able to rapidly identify which segments are located where, whether for empty space skipping for fast rendering, or for spatial proximity queries. We refer to this process as culling. In order to enable efficient culling of millions of labeled segments, we present a novel hybrid approach that combines deterministic and probabilistic representations of label data in a data-adaptive hierarchical data structure that we call the label list tree. In each node, we adaptively encode label data using either a probabilistic constant-time access representation for fast conservative culling, or a deterministic logarithmic-time access representation for exact queries. We choose the best data structures for representing the labels of each spatial region while building the label list tree. At run time, we further employ a novel query-adaptive culling strategy. While filtering a query down the tree, we prune it successively, and in each node adaptively select the representation that is best suited for evaluating the pruned query, depending on its size. We show an analysis of the efficiency of our approach with several large data sets from connectomics, including a brain scan with more than 13 million labeled segments, and compare our method to conventional culling approaches. Our approach achieves significant reductions in storage size as well as faster query times.",,,,,youtube ABf0jw1jLUY,10.1109/tvcg.2018.2864847,2018,2018,SciVis,Estrel Hall A+B,Thursday,Scalable Techniques,2022-10-25,11:00:00 AM,11:20:00 AM
openaccessvis2018.csv,SciVis,TVCG,CPU Iso-surface Ray Tracing of Adaptive Mesh Refinement Data,J),"Feng Wang, Ingo Wald, Qi Wu, Will Usher, Chris R. Johnson",http://sci.utah.edu/~will/papers/amr-isosurface.pdf,"Adaptive mesh refinement (AMR) is a key technology for large-scale simulations that allows for adaptively changing the simulation mesh resolution, resulting in significant computational and storage savings. However, visualizing such AMR data poses a significant challenge due to the difficulties introduced by the hierarchical representation when reconstructing continuous field values. In this paper, we detail a comprehensive solution for interactive isosurface rendering of block-structured AMR data. We contribute a novel reconstruction strategy?the octant method?which is continuous, adaptive and simple to implement. Furthermore, we present a generally applicable hybrid implicit isosurface ray-tracing method, which provides better rendering quality and performance than the built-in sampling-based approach in OSPRay. Finally, we integrate our octant method and hybrid isosurface geometry into OSPRay as a module, providing the ability to create high-quality interactive visualizations combining volume and isosurface representations of BS-AMR data. We evaluate the rendering performance, memory consumption and quality of our method on two gigascale block-structured AMR datasets.",,,,,vimeo 290328099,10.1109/TVCG.2018.2864850,2018,2018,SciVis,Estrel Hall A+B,Thursday,Scalable Techniques,2022-10-25,11:20:00 AM,11:40:00 AM
openaccessvis2018.csv,TVCG,TVCG,Efficient Local Statistical Analysis via Point-Wise Histograms in Tetrahedral Meshes and Curvilinear Grids,T),"Bo Zhou, Yi-Jen Chiang, Cong Wang",http://cse.poly.edu/chiang/TVCG18-Final-Paper.pdf,"Local histograms (i.e., point-wise histograms computed from local regions of mesh vertices) have been used in many data analysis and visualization applications. Previous methods for computing local histograms mainly work for regular or rectilinear grids only. In this paper, we develop theory and novel algorithms for computing local histograms in tetrahedral meshes and curvilinear grids. Our algorithms are theoretically sound and efficient, and work effectively and fast in practice. Our main focus is on scalar fields, but the algorithms also work for vector fields as a by-product with small, easy modifications. Our methods can benefit information theoretic and other distribution-driven analysis. The experiments demonstrate the efficacy of our new techniques, including a utility case study on tetrahedral vector field visualization.",,,,,vimeo 289789310,10.1109/tvcg.2018.2796555,2018,2018,SciVis,Estrel Hall A+B,Thursday,Scalable Techniques,2022-10-25,11:40:00 AM,12:00:00 PM
openaccessvis2018.csv,TVCG,TVCG,Shadow Accrual Maps: Efficient Accumulation of City-Scale Shadows over Time,T),"Fabio Miranda, Harish Doraiswamy, Marcos Lage, Luc Wilson, Mondrian Hsieh, Claudio T. Silva",http://www.harishd.com/home/assets/papers/shadows.pdf,"Large scale shadows from buildings in a city play an important role in determining the environmental quality of public spaces. They can be both beneficial, such as for pedestrians during summer, and detrimental, by impacting vegetation and by blocking direct sunlight. Determining the effects of shadows requires the accumulation of shadows over time across different periods in a year. In this paper, we propose a simple yet efficient class of approach that uses the properties of sun movement to track the changing position of shadows within a fixed time interval. We use this approach to extend two commonly used shadow techniques, shadow maps and ray tracing, and demonstrate the efficiency of our approach. Our technique is used to develop an interactive visual analysis system, Shadow Profiler, targeted at city planners and architects that allows them to test the impact of shadows for different development scenarios. We validate the usefulness of this system through case studies set in Manhattan, a dense borough of New York City",,,,,vimeo 289789412,10.1109/tvcg.2018.2802945,2018,2018,SciVis,Estrel Hall A+B,Thursday,Scalable Techniques,2022-10-25,12:00:00 PM,12:20:00 PM
openaccessvis2018.csv,TVCG,TVCG,A Scalable Hybrid Scheme for Ray-Casting of Unstructured Volume Data,T),"Roba Binyahib, Tom Peterka, Matthew Larsen, Kwan-Liu Ma, Hank Childs",https://www.mcs.anl.gov/~tpeterka/papers/2018/binyahib-tvcg18-paper.pdf,"We present an algorithm for parallel volume rendering that is a hybrid between classical object order and image order techniques. The algorithm operates on unstructured grids (and structured ones), and thus can deal with block boundaries interleaving in complex ways. It also deals effectively with cases that are prone to load imbalance, i.e., cases where cell sizes differ dramatically, either because of the nature of the input data, or because of the effects of the camera transformation. The algorithm divides work over resources such that each phase of its processing is bounded in the amount of computation it can perform. We demonstrate its efficacy through a series of studies, varying over camera position, data set size, transfer function, image size, and processor count. At its biggest, our experiments scaled up to 8,192 processors and operated on data sets with more than one billion cells. In total, we find that our hybrid algorithm performs well in all cases. This is because our algorithm naturally adapts its computation based on workload, and can operate like either an object order technique or an image order technique in scenarios where those techniques are efficient.",,,,,vimeo 289789339,10.1109/tvcg.2018.2833113,2018,2018,SciVis,Estrel Hall A+B,Thursday,Scalable Techniques,2022-10-25,12:20:00 PM,12:40:00 PM
openaccessvis2018.csv,InfoVis,TVCG,Charticulator: Interactive Construction of Bespoke Chart Layouts,J),"Donghao Ren, Bongshin Lee, Matthew Brehmer",https://donghaoren.org/publications/infovis18-charticulator.pdf,"We present Charticulator, an interactive authoring tool that enables the creation of bespoke and reusable chart layouts. Charticulator is our response to most existing chart construction interfaces that require authors to choose from predefined chart layouts, thereby precluding the construction of novel charts. In contrast, Charticulator transforms a chart specification into mathematical layout constraints and automatically computes a set of layout attributes using a constraint-solving algorithm to realize the chart. It allows for the articulation of compound marks or glyphs as well as links between these glyphs, all without requiring any coding or knowledge of constraint satisfaction. Furthermore, thanks to the constraint-based layout approach, Charticulator can export chart designs into reusable templates that can be imported into other visualization tools. In addition to describing Charticulator's conceptual framework and design, we present three forms of evaluation: a gallery to illustrate its expressiveness, a user study to verify its usability, and a click-count comparison between Charticulator and three existing tools. Finally, we discuss the limitations and potentials of Charticulator as well as directions for future research. Charticulator is available with its source code at https://charticulator.com.",https://charticulator.com/app/index.html,https://github.com/Microsoft/charticulator,,,video https://charticulator.azureedge.net/videos/charticulator-supplemental.mp4,10.1109/tvcg.2018.2865158,2018,2018,InfoVis,Estrel Hall C,Thursday,Interaction,2022-10-25,11:00:00 AM,11:20:00 AM
openaccessvis2018.csv,InfoVis,TVCG,Embedded Merge & Split: Visual Adjustment of Data Grouping,J),"Ali Sarvghad, Bahador Saket, Alex Endert, Nadir Weibel",http://bahadorsaket.com/publication/EMS.pdf,"Data grouping is among the most frequently used operations in data visualization. It is the process through which relevant information is gathered, simplified, and expressed in summary form. Many popular visualization tools support automatic grouping of data (e.g., dividing up a numerical variable into bins). Although grouping plays a pivotal role in supporting data exploration, further adjustment and customization of auto-generated grouping criteria is non-trivial. Such adjustments are currently performed either programmatically or through menus and dialogues which require specific parameter adjustments over several steps. In response, we introduce Embedded Merge & Split (EMS), a new interaction technique for direct adjustment of data grouping criteria. We demonstrate how the EMS technique can be designed to directly manipulate width and position in bar charts and histograms, as a means for adjustment of data grouping criteria. We also offer a set of design guidelines for supporting EMS. Finally, we present the results of two user studies, providing initial evidence that EMS can significantly reduce interaction time compared to WIMP-based technique and was subjectively preferred by participants.",,,,,youtube Z2rL6WF6TLY,10.1109/tvcg.2018.2865075,2018,2018,InfoVis,Estrel Hall C,Thursday,Interaction,2022-10-25,11:20:00 AM,11:40:00 AM
openaccessvis2018.csv,TVCG,TVCG,Smart Brushing for Parallel Coordinates,T),"Richard Roberts, Robert S Laramee, Gary A Smith, Paul Brookes, Tony D'Cruze",http://cs.swan.ac.uk/~csbob/research/callCenter/brushing/roberts18smart.pdf,"The Parallel Coordinates plot is a popular tool for the visualization of high-dimensional data. One of the main challenges when using parallel coordinates is occlusion and overplotting resulting from large data sets. Brushing is a popular approach to address these challenges. Since its conception, limited improvements have been made to brushing both in the form of visual design and functional interaction. We present a set of novel, smart brushing techniques that enhance the standard interactive brushing of a parallel coordinates plot. We introduce two new interaction concepts: Higher-order, sketch-based brushing, and smart, data-driven brushing. Higher-order brushes support interactive, flexible, n-dimensional pattern searches involving an arbitrary number of dimensions. Smart, data-driven brushing provides interactive, real-time guidance to the user during the brushing process based on derived meta-data. In addition, we implement a selection of novel enhancements and user options that complement the two techniques as well as enhance the exploration and analytical ability of the user. We demonstrate the utility and evaluate the results using a case study with a large, high-dimensional, real-world telecommunication data set and we report domain expert feedback from the data suppliers.",,,,,vimeo 289789480,10.1109/tvcg.2018.2808969,2018,2018,InfoVis,Estrel Hall C,Thursday,Interaction,2022-10-25,11:40:00 AM,12:00:00 PM
openaccessvis2018.csv,TVCG,TVCG,"Multidimensional Projection for Visual Analytics: Linking Techniques with Distortions, Tasks, and Layout Enrichment ",T),"Luis Gustavo Nonato, Michael Aupetit",http://www.lcad.icmc.usp.br/~nonato/pubs/mdp-survey.pdf,"Visual analysis of multidimensional data requires expressive and effective ways to reduce data dimensionality to encode them visually. Multidimensional projections (MDP) figure among the most important visualization techniques in this context, transforming multidimensional data into scatter plots whose visual patterns reflect some notion of similarity in the original data. However, MDP come with distortions that make these visual patterns not trustworthy, hindering users to infer actual data characteristics. Moreover, the patterns present in the scatter plots might not be enough to allow a clear understanding of multidimensional data, motivating the development of layout enrichment methodologies to operate together with MDP. This survey attempts to cover the main aspects of MDP as a visualization and visual analytic tool. It provides detailed analysis and taxonomies as to the organization of MDP techniques according to their main properties and traits, discussing the impact of such properties for visual perception and other human factors. The survey also approaches the different types of distortions that can result from MDP mappings and it overviews existing mechanisms to quantitatively evaluate such distortions. A qualitative analysis of the impact of distortions on the different analytic tasks performed by users when exploring multidimensional data through MDP is also presented. Guidelines for choosing the best MDP for an intended task are also provided as a result of this analysis. Finally, layout enrichment schemes to debunk MDP distortions and/or reveal relevant information not directly inferable from the scatter plot are reviewed and discussed in the light of new taxonomies. We conclude the survey providing future research axes to fill discovered gaps in this domain.",,,,,vimeo 289789153,10.1109/tvcg.2018.2846735,2018,2018,InfoVis,Estrel Hall C,Thursday,Interaction,2022-10-25,12:00:00 PM,12:20:00 PM
openaccessvis2018.csv,TVCG,TVCG,Exploration Strategies for Discovery of Interactivity in Visualizations,T),"Tanja Blascheck, Lindsay MacDonald Vermeulen, Jo Vermeulen, Charles Perin, Wesley Willett, Thomas Ertl, Sheelagh Carpendale",https://hal.archives-ouvertes.fr/hal-01705792/document,"We investigate how people discover the functionality of an interactive visualization that was designed for the general public. While interactive visualizations are increasingly available for public use, we still know little about how the general public discovers what they can do with these visualizations and what interactions are available. Developing a better understanding of this discovery process can help inform the design of visualizations for the general public, which in turn can help make data more accessible. To unpack this problem, we conducted a lab study in which participants were free to use their own methods to discover the functionality of a connected set of interactive visualizations of public energy data. We collected eye movement data and interaction logs as well as video and audio recordings. By analyzing this combined data, we extract exploration strategies that the participants employed to discover the functionality in these interactive visualizations. These exploration strategies illuminate possible design directions for improving the discoverability of a visualization's functionality.",,,http://innovis.cpsc.ucalgary.ca/supplemental/Exploration-Strategies/#data,,vimeo 289789025,10.1109/tvcg.2018.2802520,2018,2018,InfoVis,Estrel Hall C,Thursday,Interaction,2022-10-25,12:20:00 PM,12:40:00 PM
openaccessvis2018.csv,CG&A,CGA,OpenSpace: Changing the Narrative of Public Dissemination in Astronomical Visualization from What to How,,"Alexander Bock, Emil Axelsson, Carter Emmart, Masha Kuznetsova, Charles Hansen, Anders Ynnerman",http://www.sci.utah.edu/publications/Boc2018a/08370192.pdf,"This article presents the development of open-source software called OpenSpace that bridges the gap between scientific discoveries and public dissemination and thus paves the way for the next generation of science communication and data exploration. The article describes how the platform enables interactive presentations of dynamic and timevarying processes by domain experts to the general public. The concepts are demonstrated through four cases: Image acquisitions of the New Horizons and Rosetta spacecraft, the dissemination of space weather phenomena, and the display of highresolution planetary images. Each case has been presented at public events with great success. These cases highlight the details of data acquisition, rather than presenting the final results, showing the audience the value of supporting the efforts of the scientific discovery. ",,,,,vimeo 289785793,10.1109/mcg.2018.032421653,2018,2018,Other,Room III,Thursday,CG&A Session 2,2022-10-25,11:00:00 AM,11:20:00 AM
openaccessvis2018.csv,CG&A,CGA,Belle2VR: A Virtual-Reality Visualization of Subatomic Particle Physics in the Belle II Experiment,,"Zach Duer, Leo Piilonen, and George Glasson",,,,,,,vimeo 289785809,10.1109/mcg.2018.032421652,2018,2018,Other,Room III,Thursday,CG&A Session 2,2022-10-25,11:20:00 AM,11:40:00 AM
openaccessvis2018.csv,CG&A,CGA,Application-Driven Design: Help Students Understand Employment and See the ?Big Picture?,,"Li Liu, Deborah Silver, Karen Bemis",,,,,,,vimeo 289785826,10.1109/mcg.2018.032421656,2018,2018,Other,Room III,Thursday,CG&A Session 2,2022-10-25,11:40:00 AM,12:00:00 PM
openaccessvis2018.csv,CG&A,CGA,Management of Cerebral Aneurysm Descriptors based on an Automatic Ostium Extraction,,"Monique Meuschke, Tobias Gnther, Ralph Wickenh”fer, Markus Gross, Bernhard Preim, Kai Lawonn",https://cgl.ethz.ch/Downloads/Publications/Papers/2018/Meu18a/Meu18a.pdf,"We present a framework to manage cerebral aneurysms. Rupture risk evaluation is based on manually extracted descriptors, which is timeconsuming. Thus, we provide an automatic solution by considering several questions: How can expert knowledge be integrated? How should metadata be defined? Which interaction techniques are needed for data exploration?",,,,,vimeo 289785840,10.1109/mcg.2018.032421654,2018,2018,Other,Room III,Thursday,CG&A Session 2,2022-10-25,12:00:00 PM,12:20:00 PM
openaccessvis2018.csv,CG&A,CGA,Toward a Multimodal Diagnostic Exploratory Visualization of Focal Cortical Dysplasia,,"Shin-Ting Wu, Raphael Voltoline, Wallace S. Loos, J.A. Iv n Rubianes, Lionis S. Watanabe, B rbara J. Amorim, A. Carolina Coan, Fernando Cendes, Clarissa L. Yasuda",http://www.dca.fee.unicamp.br/projects/prosim/publications/journals/wu-loos-voltoline-rubianes-2017-3dmediv-draft.pdf,"Focal cortical dysplasia (FCD) is a malformation of cortical development and a common cause of pharmacoresistant epilepsy. Resective surgery of clear-cut lesions may be curative. However, the localization of the seizure focus and the evaluation of its spatial extent can be challenging in many situations. For concordance assessment, medical studies show the relevance of accurate correlation of multi-source imaging sequences. to improve the sensitivity and specificity of the evaluation. In this paper, we share the process we went through to reach our simple, but effective, solution for integrating multi-volume rendering into an exploratory visualization environment for the diagnosis of FCD. We focus on fetching of multiple data assigned to a sample when they are rendered. Knowing that the major diagnostic role of multiple volumes is to complement information, we demonstrate that appropriate geometric transformations in the texture space are sufficient for accomplishing this task. This allows us to fully implement our proposal in the OpenGL rendering pipeline and to easily integrate it into the existing visual diagnostic application. Both time performance and the visual quality of our proposal were evaluated with a set of clinical data volumes for assessing the potential practical impact of our solution in routine diagnostic use. ",,,,,vimeo 289785856,10.1109/mcg.2018.032421655,2018,2018,Other,Room III,Thursday,CG&A Session 2,2022-10-25,12:20:00 PM,12:40:00 PM
openaccessvis2018.csv,VAST,TVCG,ViBr: Visualizing Bipartite Relations at Scale with the Minimum Description Length Principle,J),"Gromit Yeuk-Yin Chan, Panpan Xu, Zeng Dai, Liu Ren",https://vgc.poly.edu/~yychan/papers/chan-vast2018.pdf,"Bipartite graphs model the key relations in many large scale real-world data: customers purchasing items, legislators voting for bills, people?s affiliation with different social groups, faults occurring in vehicles, etc. However, it is challenging to visualize large scale bipartite graphs with tens of thousands or even more nodes or edges. In this paper, we propose a novel visual summarization technique for bipartite graphs based on the minimum description length (MDL) principle. The method simultaneously groups the two different set of nodes and constructs aggregated bipartite relations with balanced granularity and precision. It addresses the key trade-off that often occurs for visualizing large scale and noisy data: acquiring a clear and uncluttered overview while maximizing the information content in it. We formulate the visual summarization task as a co-clustering problem and propose an efficient algorithm based on locality sensitive hashing (LSH) that can easily scale to large graphs under reasonable interactive time constraints that previous related methods cannot satisfy. The method leads to the opportunity of introducing a visual analytics framework with multiple levels-of-detail to facilitate interactive data exploration. In the framework, we also introduce a compact visual design inspired by adjacency list representation of graphs as the building block for a small multiples display to compare the bipartite relations for different subsets of data. We showcase the applicability and effectiveness of our approach by applying it on synthetic data with ground truth and performing case studies on real-world datasets from two application domains including roll-call vote record analysis and vehicle fault pattern analysis. Interviews with experts in the political science community and the automotive industry further highlight the benefits of our approach.",,,,,vimeo 289787354,10.1109/TVCG.2018.2864826,2018,2018,VAST,"Hall 1, Section C",Thursday,Graph and Image,2022-10-25,2:20:00 PM,2:40:00 PM
openaccessvis2018.csv,VAST,VAST,Segue: Overviewing Evolution Patterns of Egocentric Networks by Interactive Construction of Spatial Layouts,C),"Po-Ming Law, Yanhong Wu, Rahul Basole",https://osf.io/ah5y6/,"Getting the overall picture of how a large number of ego-networks evolve is a common yet challenging task. Existing techniques often require analysts to inspect the evolution patterns of ego-networks one after another. In this study, we explore an approach that allows analysts to interactively create spatial layouts in which each dot is a dynamic ego-network. These spatial layouts provide overviews of the evolution patterns of ego-networks, thereby revealing different global patterns such as trends, clusters and outliers in evolution patterns. To let analysts interactively construct interpretable spatial layouts, we propose a data transformation pipeline, with which analysts can adjust the spatial layouts and convert dynamic egonetworks into event sequences to aid interpretations of the spatial positions. Based on this transformation pipeline, we develop Segue, a visual analysis system that supports thorough exploration of the evolution patterns of ego-networks. Through two usage scenarios, we demonstrate how analysts can gain insights into the overall evolution patterns of a large collection of ego-networks by interactively creating different spatial layouts.",,https://osf.io/u4jxh/,,,vimeo 289788023,,2018,2018,VAST,"Hall 1, Section C",Thursday,Graph and Image,2022-10-25,2:40:00 PM,3:00:00 PM
openaccessvis2018.csv,VAST,TVCG,A Visual Analytics Framework for Spatiotemporal Trade Network Analysis,J),"Hong Wang, Yafeng Lu, Shade Shutters, Michael Steptoe, Feng Wang, Steven Landis, Ross Maciejewski",http://www.public.asu.edu/~hxwang/trade.pdf,"Economic globalization is increasing connectedness among regions of the world, creating complex interdependencies within various supply chains. Recent studies have indicated that changes and disruptions within such networks can serve as indicators for increased risks of violence and armed conflicts. This is especially true of countries that may not be able to compete for scarce commodities during supply shocks. Thus, network-induced vulnerability to supply disruption is typically exported from wealthier populations to disadvantaged populations. As such, researchers and stakeholders concerned with supply chains, political science, environmental studies, etc. need tools to explore the complex dynamics within global trade networks and how the structure of these networks relates to regional instability. However, the multivariate, spatiotemporal nature of the network structure creates a bottleneck in the extraction and analysis of correlations and anomalies for exploratory data analysis and hypothesis generation. Working closely with experts in political science and sustainability, we have developed a highly coordinated, multi-view framework that utilizes anomaly detection, network analytics, and spatiotemporal visualization methods for exploring the relationship between global trade networks and regional instability. Requirements for analysis and initial research questions to be investigated are elicited from domain experts, and a variety of visual encoding techniques for rapid assessment of analysis and correlations between trade goods, network patterns, and time series signatures are explored. We demonstrate the application of our framework through case studies focusing on armed conflicts in Africa, regional instability measures, and their relationship to international global trade.",,,,,vimeo 289787400,10.1109/TVCG.2018.2864844,2018,2018,VAST,"Hall 1, Section C",Thursday,Graph and Image,2022-10-25,3:00:00 PM,3:20:00 PM
openaccessvis2018.csv,TVCG,TVCG,A Semantic-based Method for Visualizing Large Image Collections,T),"Xiao Xie, Xiwen Cai, Junpei Zhou, Nan Cao, Yingcai Wu",http://zjuvis.org/files/imgvis.pdf,"Interactive visualization of large image collections is important and useful in many applications, such as personal album management and user profiling on images. However, most prior studies focus on using low-level visual features of images, such as texture and color histogram, to create visualizations without considering the more important semantic information embedded in images. This paper proposes a novel visual analytic system to analyze images in a semantic-aware manner. The system mainly comprises two components: a semantic information extractor and a visual layout generator. The semantic information extractor employs an image captioning technique based on convolutional neural network (CNN) to produce descriptive captions for images, which can be transformed into semantic keywords. The layout generator employs a novel co-embedding model to project images and the associated semantic keywords to the same 2D space. Inspired by the galaxy metaphor, we further turn the projected 2D space to a galaxy visualization of images, in which semantic keywords and images are visually encoded as stars and planets. Our system naturally supports multi-scale visualization and navigation, in which users can immediately see a semantic overview of an image collection and drill down for detailed inspection of a certain group of images. Users can iteratively refine the visual layout by integrating their domain knowledge into the co-embedding process. Two task-based evaluations are conducted to demonstrate the effectiveness of our system.",,,,,vimeo 289789441,10.1109/tvcg.2018.2835485,2018,2018,VAST,"Hall 1, Section C",Thursday,Graph and Image,2022-10-25,3:20:00 PM,3:40:00 PM
openaccessvis2018.csv,TVCG,TVCG,PhotoRecomposer: Interactive Photo Recomposition by Cropping,T),"Yuan Liang, Xiting Wang, Song-Hai Zhang, Shi-Min Hu, Shixia Liu",http://shixialiu.com/publications/photorecomposer/paper.pdf,"We present a visual analysis method for interactively recomposing a large number of photos based on example photos with high-quality composition. The recomposition method is formulated as a matching problem between photos. The key to this formulation is a new metric for accurately measuring the composition distance between photos. We have also developed an earth-mover-distancebased online metric learning algorithm to support the interactive adjustment of the composition distance based on user preferences. To better convey the compositions of a large number of example photos, we have developed a multi-level, example photo layout method to balance multiple factors such as compactness, aspect ratio, composition distance, stability, and overlaps. By introducing an EulerSmooth-based straightening method, the composition of each photos is clearly displayed. The effectiveness and usefulness of the method has been demonstrated by the experimental results, user study, and case studies.",,,,,vimeo 289788924,10.1109/tvcg.2017.2764895,2017,2018,VAST,"Hall 1, Section C",Thursday,Graph and Image,2022-10-25,3:40:00 PM,4:00:00 PM
openaccessvis2018.csv,InfoVis,TVCG,Mapping Color to Meaning in Colormap Data Visualizations,J),"Karen B. Schloss, Connor C. Gramazio, Allison T. Silverman, Madeline L. Parker, Audrey S. Wang",https://schlosslab.discovery.wisc.edu/wp-content/uploads/2018/09/SchlossGramazioSilvermanParkerWanginPress.pdf,"To interpret data visualizations, people must determine how visual features map onto concepts. For example, to interpret colormaps, people must determine how dimensions of color (e.g., lightness, hue) map onto quantities of a given measure (e.g., brain activity, correlation magnitude). This process is easier when the encoded mappings in the visualization match people's predictions of how visual features will map onto concepts, their inferred mappings. To harness this principle in visualization design, it is necessary to understand what factors determine people's <i>inferred mappings</i>. In this study, we investigated how inferred color-quantity mappings for colormap data visualizations were influenced by the background color. Prior literature presents seemingly conflicting accounts of how the background color affects inferred color-quantity mappings. The present results help resolve those conflicts, demonstrating that sometimes the background has an effect and sometimes it does not, depending on whether the colormap appears to vary in opacity. When there is no apparent variation in opacity, participants infer that darker colors map to larger quantities (<i>dark-is-more bias</i>). As apparent variation in opacity increases, participants become biased toward inferring that more opaque colors map to larger quantities (<i>opaque-is-more bias</i>). These biases work together on light backgrounds and conflict on dark backgrounds. Under such conflicts, the opaque-is-more bias can negate, or even supersede the dark-is-more bias. The results suggest that if a design goal is to produce colormaps that match people's inferred mappings and are robust to changes in background color, it is beneficial to use colormaps that will not appear to vary in opacity on any background color, and to encode larger quantities in darker colors.",,,https://schlosslab.discovery.wisc.edu/resources/,,vimeo 289784916,10.1109/tvcg.2018.2865147,2018,2018,InfoVis,"Hall 1, Section D",Thursday,Perception & Cognition 1,2022-10-25,2:20:00 PM,2:40:00 PM
openaccessvis2018.csv,InfoVis,TVCG,Optimizing Color Assignment for Perception of Class Separability in Multiclass Scatterplots,J),"Yunhai Wang, Xin Chen, Tong Ge, Chen Bao, Michael Sedlmair, Chi-Wing Fu, Oliver Deussen, Baoquan Chen",http://www.yunhaiwang.org/infovis18/color/vis-color.pdf,"Appropriate choice of colors significantly aids viewers in understanding the structures in multiclass scatterplots and becomes more important with a growing number of data points and groups. An appropriate color mapping is also an important parameter for the creation of an aesthetically pleasing scatterplot. Currently, users of visualization software routinely rely on color mappings that have been pre-defined by the software. A default color mapping, however, cannot ensure an optimal perceptual separability between groups, and sometimes may even lead to a misinterpretation of the data. In this paper, we present an effective approach for color assignment based on a set of given colors that is designed to optimize the perception of scatterplots. Our approach takes into account the spatial relationships, density, degree of overlap between point clusters, and also the background color. For this purpose, we use a genetic algorithm that is able to efficiently find good color assignments. We implemented an interactive color assignment system with three extensions of the basic method that incorporates top K suggestions, user-defined color subsets, and classes of interest for the optimization. To demonstrate the effectiveness of our assignment technique, we conducted a numerical study and a controlled user study to compare our approach with default color assignments; our findings were verified by two expert studies. The results show that our approach is able to support users in distinguishing cluster numbers faster and more precisely than default assignment methods.",http://www.color-assignment.net/,,,,vimeo 289785222,10.1109/tvcg.2018.2864912,2018,2018,InfoVis,"Hall 1, Section D",Thursday,Perception & Cognition 1,2022-10-25,2:40:00 PM,3:00:00 PM
openaccessvis2018.csv,InfoVis,TVCG,Looks Good To Me: Visualizations As Sanity Checks,J),"Michael Correll, Mingwei Li, Gordon L Kindlmann, Carlos Scheidegger",https://github.com/AlgebraicVis/SanityCheck/blob/master/InfoVis/preprint.pdf,"Famous examples such as Anscombe's Quartet highlight that one of the core benefits of visualizations is allowing people to discover visual patterns that might otherwise be hidden by summary statistics. This visual inspection is particularly important in exploratory data analysis, where analysts can use visualizations such as histograms and dot plots to identify data quality issues. Yet, these visualizations are driven by parameters such as histogram bin size or mark opacity that have a great deal of impact on the final visual appearance of the chart, but are rarely optimized to make important features visible. In this paper, we show that data flaws have varying impact on the visual features of visualizations, and that the adversarial or merely uncritical setting of design parameters of visualizations can obscure the visual signatures of these flaws. Drawing on the framework of Algebraic Visualization Design, we present the results of a crowdsourced study showing that common visualization types can appear to reasonably summarize distributional data while hiding large and important flaws such as missing data and extraneous modes. We make use of these results to propose additional best practices for visualizations of distributions for data quality tasks.",https://medium.com/@mcorrell/looks-good-to-me-visualizations-as-sanity-checks-6fd1ffa37ab9,https://github.com/AlgebraicVis/SanityCheck/tree/master/study,https://github.com/AlgebraicVis/SanityCheck/tree/master/study/data,,vimeo 289785290,10.1109/tvcg.2018.2864907,2018,2018,InfoVis,"Hall 1, Section D",Thursday,Perception & Cognition 1,2022-10-25,3:00:00 PM,3:20:00 PM
openaccessvis2018.csv,TVCG,TVCG,Is There a Robust Technique for Selecting Aspect Ratios in Line Charts?,T),"Yunhai Wang, Zeyu Wang, Lifeng Zhu, Jian Zhang, Chi-Wing Fu, Changhe Tu, Baoquan Chen, Zhanglin Cheng",http://www.yunhaiwang.org/bankto45/as-tvcg.pdf,"The aspect ratio of a line chart heavily influences the perception of the underlying data. Different methods explore different criteria in choosing aspect ratios, but so far, it was still unclear how to select aspect ratios appropriately for any given data. This paper provides a guideline for the user to choose aspect ratios for any input 1D curves by conducting an in-depth analysis of aspect ratio selection methods both theoretically and experimentally. By formulating several existing methods as line integrals, we explain their parameterization invariance. Moreover, we derive a new and improved aspect ratio selection method, namely the L1-LOR (local orientation resolution), with a certain degree of parameterization invariance. Furthermore, we connect different methods, including AL (arc length based method), the banking to 45ø principle, RV (resultant vector) and AS (average absolute slope), as well as L1-LOR and AO (average absolute orientation). We verify these connections by a comparative evaluation involving various data sets, and show that the selections by RV and L1-LOR are complementary to each other for most data. Accordingly, we propose the dual-scale banking technique that combines the strengths of RV and L1-LOR, and demonstrate its practicability using multiple real-world data sets.",,,,,vimeo 289789006,10.1109/tvcg.2017.2787113,2017,2018,InfoVis,"Hall 1, Section D",Thursday,Perception & Cognition 1,2022-10-25,3:20:00 PM,3:40:00 PM
openaccessvis2018.csv,InfoVis,TVCG,Image-based Aspect Ratio Selection,J),"Yunhai Wang, Zeyu Wang, Chi-Wing Fu, Hansj”rg Schmauder, Oliver Deussen, Daniel Weiskopf",http://www.yunhaiwang.org/infovis18/dbar/paper.pdf,"Selecting a good aspect ratio is crucial for effective 2D diagrams. There are several aspect ratio selection methods for function plots and line charts, but only few can handle general, discrete diagrams such as 2D scatter plots. However, these methods either lack a perceptual foundation or heavily rely on intermediate isoline representations, which depend on choosing the right isovalues and are time-consuming to compute. This paper introduces a general image-based approach for selecting aspect ratios for a wide variety of 2D diagrams, ranging from scatter plots and density function plots to line charts. Our approach is derived from Federer's co-area formula and a line integral representation that enable us to directly construct image-based versions of existing selection methods using density fields. In contrast to previous methods, our approach bypasses isoline computation, so it is faster to compute, while following the perceptual foundation to select aspect ratios. Furthermore, this approach is complemented by an anisotropic kernel density estimation to construct density fields, allowing us to more faithfully characterize data patterns, such as the subgroups in scatterplots or dense regions in time series. We demonstrate the effectiveness of our approach by quantitatively comparing to previous methods and revisiting a prior user study. Finally, we present extensions for ROI banking, multi-scale banking, and the application to image data.",,,,,vimeo 289784435,10.1109/TVCG.2018.2865266,2018,2018,InfoVis,"Hall 1, Section D",Thursday,Perception & Cognition 1,2022-10-25,3:40:00 PM,4:00:00 PM
openaccessvis2018.csv,SciVis,TVCG,Persistence Atlas for Critical Point Variability in Ensembles,J),"Guillaume Favelier, Noura Faraj, Brian Summa, Julien Tierny",https://arxiv.org/pdf/1807.11212.pdf,"This paper presents a new approach for the visualization and analysis of the spatial variability of features of interest represented by critical points in ensemble data. Our framework, called Persistence Atlas, enables the visualization of the dominant spatial patterns of critical points, along with statistics regarding their occurrence in the ensemble. The persistence atlas represents in the geometrical domain each dominant pattern in the form of a confidence map for the appearance of critical points. As a by-product, our method also provides 2-dimensional layouts of the entire ensemble, highlighting the main trends at a global level. Our approach is based on the new notion of Persistence Map, a measure of the geometrical density in critical points which leverages the robustness to noise of topological persistence to better emphasize salient features. We show how to leverage spectral embedding to represent the ensemble members as points in a low-dimensional Euclidean space, where distances between points measure the dissimilarities between critical point layouts and where statistical tasks, such as clustering, can be easily carried out. Further, we show how the notion of mandatory critical point can be leveraged to evaluate for each cluster confidence regions for the appearance of critical points. Most of the steps of this framework can be trivially parallelized and we show how to efficiently implement them. Extensive experiments demonstrate the relevance of our approach. The accuracy of the confidence regions provided by the persistence atlas is quantitatively evaluated and compared to a baseline strategy using an off-the-shelf clustering approach. We illustrate the importance of the persistence atlas in a variety of real-life datasets, where clear trends in feature layouts are identified and analyzed. We provide a lightweight VTK-based C++ implementation of our approach that can be used for reproduction purposes.",,,,,vimeo 290325207,10.1109/tvcg.2018.2864432,2018,2018,SciVis,Estrel A+B,Thursday,"Topology, Geometry, and Precision",2022-10-25,2:20:00 PM,2:40:00 PM
openaccessvis2018.csv,SciVis,TVCG,Probabilistic Asymptotic Decider for Topological Ambiguity Resolution in Level-Set Extraction for Uncertain 2D Data,J),"Tushar Athawale, Chris R. Johnson",http://tusharathawale.info/wp-content/uploads/2018/09/vis18ProbabilisticAsympDecider.pdf,"We present a framework for the analysis of uncertainty in isocontour extraction. The marching squares (MS) algorithm for isocontour reconstruction generates a linear topology that is consistent with hyperbolic curves of a piecewise bilinear interpolation. The saddle points of the bilinear interpolant cause topological ambiguity in isocontour extraction. The midpoint decider and the asymptotic decider are well-known mathematical techniques for resolving topological ambiguities. The latter technique investigates the data values at the cell saddle points for ambiguity resolution. The uncertainty in data, however, leads to uncertainty in underlying bilinear interpolation functions for the MS algorithm, and hence, their saddle points. In our work, we study the behavior of the asymptotic decider when data at grid vertices is uncertain. First, we derive closed-form distributions characterizing variations in the saddle point values for uncertain bilinear interpolants. The derivation assumes uniform and nonparametric noise models, and it exploits the concept of ratio distribution for analytic formulations. Next, the probabilistic asymptotic decider is devised for ambiguity resolution in uncertain data using distributions of the saddle point values derived in the first step. Finally, the confidence in probabilistic topological decisions is visualized using a colormapping technique. We demonstrate the higher accuracy and stability of the probabilistic asymptotic decider in uncertain data with regard to existing decision frameworks, such as deciders in the mean field and the probabilistic midpoint decider, through the isocontour visualization of synthetic and real datasets.",,,,,vimeo 290325318,10.1109/TVCG.2018.2864505,2018,2018,SciVis,Estrel A+B,Thursday,"Topology, Geometry, and Precision",2022-10-25,2:40:00 PM,3:00:00 PM
openaccessvis2018.csv,SciVis,TVCG,Hexahedral Mesh Structure Visualization and Evaluation,J),"Kaoji Cotrik Xu, Guoning Chen",http://www2.cs.uh.edu/~chengu/Publications/HexMesh/Vis2018_BaseComplexVis.pdf,"Understanding hexahedral (hex-) mesh structures is important for a number of hex-mesh generation and optimization tasks. However, due to various configurations of the singularities in a valid pure hex-mesh, the structure (or base complex) of the mesh can be arbitrarily complex. In this work, we present a first and effective method to help meshing practitioners understand the possible configurations in a valid 3D base complex for the characterization of their complexity. In particular, we propose a strategy to decompose the complex hex-mesh structure into multi-level sub-structures so that they can be studied separately, from which we identify a small set of the sub-structures that can most efficiently represent the whole mesh structure. Furthermore, from this set of sub-structures, we attempt to define the first metric for the quantification of the complexity of hex-mesh structure. To aid the exploration of the extracted multi-level structure information, we devise a visual exploration system coupled with a matrix view to help alleviate the common challenge of 3D data exploration (e.g., clutter and occlusion). We have applied our tool and metric to a large number of hex-meshes generated with different approaches to reveal different characteristics of these methods in terms of the mesh structures they can produce. We also use our metric to assess the existing structure simplification techniques in terms of their effectiveness.",,,,,vimeo 290327525,10.1109/tvcg.2018.2864827,2018,2018,SciVis,Estrel A+B,Thursday,"Topology, Geometry, and Precision",2022-10-25,3:00:00 PM,3:20:00 PM
openaccessvis2018.csv,SciVis,TVCG,Shared-Memory Parallel Computation of Morse-Smale Complexes with Improved Accuracy,J),"Attila Gyulassy, Peer-Timo Bremer, Valerio Pascucci",,,,,,,vimeo 290328033,10.1109/TVCG.2018.2864848,2018,2018,SciVis,Estrel A+B,Thursday,"Topology, Geometry, and Precision",2022-10-25,3:20:00 PM,3:40:00 PM
openaccessvis2018.csv,SciVis,TVCG,A Study of the Trade-off between Reduced Precision and Resolution for Scientific Data Analysis and Visualization,J),"Duong Hoang, Pavol Klacansky, Harsh Bhatia, Peer-Timo Bremer, Peter Lindstrom, Valerio Pascucci",,,,,,,vimeo 290328254,10.1109/TVCG.2018.2864853,2018,2018,SciVis,Estrel A+B,Thursday,"Topology, Geometry, and Precision",2022-10-25,3:40:00 PM,4:00:00 PM
openaccessvis2018.csv,SciVis,SciVis,An Organic Visual Metaphor for Public Understanding of Conditional Co-occurrences,,"Keshav Dasu, Takanori Fujiwara, Kwan-Liu Ma",,,,https://github.com/takanori-fujiwara/organic-visual-metaphor,,,vimeo 290328908,,2018,2018,SciVis Short Papers,Estrel Hall C,Thursday,"Visual Abstractions, Perceptual Study and Immersive Visualization",2022-10-25,2:20:00 PM,2:32:00 PM
openaccessvis2018.csv,SciVis,SciVis,VAPLI: Novel Visual Abstraction for Protein-Lipid Interactions,,"Naif Alharbi, Matthieu Chavent, Michael Krone, Robert S. Laramee",http://cs.swan.ac.uk/~csbob/research/mdv/interaction/alharbi18vapli.pdf,"Molecular visualization of molecular dynamics data commonly uses representative surfaces of varying resolution to depict protein molecules while a variety of geometric shapes, from lines to spheres, are often used to represent atoms and inter-atomic bonds. In general, the aim of molecular visualization is focused on efficiently rendering atoms or molecules themselves, while the interaction space between them is less explored. Furthermore, with naive approaches rendering every molecule, the particles overlap so that significant interaction details are obscured due to clutter. Contrary to common approaches, our work focuses on the interaction between lipids and proteins and the area in which this occurs, the - lipid - membrane. To do so, we introduce a novel abstract interaction space for Protein-Lipid Interaction (PLI). The cylindrical abstraction simplifies perception and computation of PLI. It does so by using a local projection of PLI onto a cylindrical geometry. This also addresses the challenge of visualizing complex, time-dependent interactions between these molecules. We propose a fast GPU-based implementation that maps lipid-constituents involved in the interaction onto the abstract protein interaction space. The tool provides interactive rendering of PLI for 336,260 particles over almost 2,000 time-steps. The result is a great simplification of this complex Protein-Lipid Interaction leading to both better perception and new insight for computational biologists",,,,,vimeo 290328550,,2018,2018,SciVis Short Papers,Estrel Hall C,Thursday,"Visual Abstractions, Perceptual Study and Immersive Visualization",2022-10-25,2:32:00 PM,2:44:00 PM
openaccessvis2018.csv,SciVis,SciVis,Color Interpolation for non-Euclidean Color Spaces,,"Max Zeyen, Tobias Post, Hans Hagen, James Ahrens, David Rogers, Roxana Bujack",,,,,,,vimeo 290328621,,2018,2018,SciVis Short Papers,Estrel Hall C,Thursday,"Visual Abstractions, Perceptual Study and Immersive Visualization",2022-10-25,2:45:00 PM,2:57:00 PM
openaccessvis2018.csv,SciVis,SciVis,VRGE: An Immersive Visualization Application for the Geosciences,,"David A. B. Hyde, Tyler R. Hall, Jef Caers",,,,,,,vimeo 290328472,,2018,2018,SciVis Short Papers,Estrel Hall C,Thursday,"Visual Abstractions, Perceptual Study and Immersive Visualization",2022-10-25,2:57:00 PM,3:09:00 PM
openaccessvis2018.csv,SciVis,SciVis,3De Interactive Lenses for Visualization in Virtual Environments,,"Roberta C. R. Mota, Allan Rocha, Julio D. Silva, Usman R. Alim, Ehud Sharlin",,,,,,,vimeo 290328419,,2018,2018,SciVis Short Papers,Estrel Hall C,Thursday,"Visual Abstractions, Perceptual Study and Immersive Visualization",2022-10-25,3:10:00 PM,3:22:00 PM
openaccessvis2018.csv,SciVis,SciVis,Toward A Deep Understanding of What Makes a Scientific Visualization Memorable,,"Rui Li, Jian Chen",https://arxiv.org/pdf/1808.00607.pdf,"We report results from a preliminary study exploring the memorability of spatial scientific visualizations, the goal of which is to understand the visual features that contribute to memorability. The evaluation metrics include three objective measures (entropy, feature congestion, the number of edges), four subjective ratings (clutter, the number of distinct colors, familiarity, and realism), and two sentiment ratings (interestingness and happiness). We curate 1142 scientific visualization (SciVis) images from the original 2231 images in published IEEE SciVis papers from 2008 to 2017 and compute memorability scores of 228 SciVis images from data collected on Amazon Mechanical Turk (MTurk). Results showed that the memorability of SciVis images is mostly correlated with clutter and the number of distinct colors. We further investigate the differences between scientific visualization and infographics as a means to understand memorability differences by data attributes.",,https://ivclexp.github.io/scivismemorability/#download,,,vimeo 290328799,,2018,2018,SciVis Short Papers,Estrel Hall C,Thursday,"Visual Abstractions, Perceptual Study and Immersive Visualization",2022-10-25,3:22:00 PM,3:34:00 PM
openaccessvis2018.csv,SciVis,SciVis,Ordering Perceptions about Perceptual Order,,"Roxana Bujack, Terece L Turton, David Rogers, James Ahrens",,,,,,,vimeo 290328692,,2018,2018,SciVis Short Papers,Estrel Hall C,Thursday,"Visual Abstractions, Perceptual Study and Immersive Visualization",2022-10-25,3:35:00 PM,3:47:00 PM
openaccessvis2018.csv,SciVis,SciVis,QuFlow: Visualizing Parameter Flow in Quantum Circuits for Understanding Quantum Computation,,"Siyuan Lin, Hao Jiang, Lingyun Sun",,,,,,,vimeo 290328716,,2018,2018,SciVis Short Papers,Estrel Hall C,Thursday,"Visual Abstractions, Perceptual Study and Immersive Visualization",2022-10-25,3:47:00 PM,3:59:00 PM
openaccessvis2018.csv,VAST,TVCG,RuleMatrix: Visualizing and Understanding Classifiers with Rules,J),"Yao Ming, Huamin Qu, Enrico Bertini",https://arxiv.org/pdf/1807.06228.pdf,"With the growing adoption of machine learning techniques, there is a surge of research interest towards making machine learning systems more transparent and interpretable. Various visualizations have been developed to help model developers understand, diagnose, and refine machine learning models. However, a large number of potential but neglected users are the domain experts with little knowledge of machine learning but are expected to work with machine learning systems. In this paper, we present an interactive visualization technique to help users with little expertise in machine learning to understand, explore and validate predictive models. By viewing the model as a black box, we extract a standardized rule-based knowledge representation from its input-output behavior. We design RuleMatrix, a matrix-based visualization of rules to help users navigate and verify the rules and the black-box model. We evaluate the effectiveness of RuleMatrix via two use cases and a usability study.",http://myaooo.com/projects/rule-matrix/,https://github.com/rulematrix/rule-matrix-py,,,vimeo 289787299,10.1109/TVCG.2018.2864812,2018,2018,VAST,"Hall 1, Section C",Thursday,Explainable ML,2022-10-25,4:20:00 PM,4:40:00 PM
openaccessvis2018.csv,VAST,TVCG,Seq2Seq-Vis: A Visual Debugging Tool for Sequence to Sequence Models,J),"Hendrik Strobelt, Sebastian Gehrmann, Michael Behrisch, Adam Perer, Hanspeter Pfister, Alexander M. Rush",https://arxiv.org/pdf/1804.09299.pdf,"Neural sequence-to-sequence models have proven to be accurate and robust for many sequence prediction tasks, and have become the standard approach for automatic translation of text. The models work with a five-stage blackbox pipeline that begins with encoding a source sequence to a vector space and then decoding out to a new target sequence. This process is now standard, but like many deep learning methods remains quite difficult to understand or debug. In this work, we present a visual analysis tool that allows interaction and ?what if?-style exploration of trained sequence-to-sequence models through each stage of the translation process. The aim is to identify which patterns have been learned, to detect model errors, and to probe the model with counterfactual scenario. We demonstrate the utility of our tool through several real-world sequence-to-sequence use cases on large-scale models.",,https://github.com/HendrikStrobelt/Seq2Seq-Vis,,,vimeo 289787650,10.1109/TVCG.2018.2865044,2018,2018,VAST,"Hall 1, Section C",Thursday,Explainable ML,2022-10-25,4:40:00 PM,5:00:00 PM
openaccessvis2018.csv,VAST,TVCG,Manifold: A Model-Agnostic Framework for Interpretation and Diagnosis of Machine Learning Models,J),"Jiawei Zhang, Yang Wang, Piero Molino, Lezhi Li, David Ebert",https://arxiv.org/pdf/1808.00196.pdf,"Interpretation and diagnosis of machine learning models have gained renewed interest in recent years with breakthroughs in new approaches. We present Manifold, a framework that utilizes visual analysis techniques to support interpretation, debugging, and comparison of machine learning models in a more transparent and interactive manner. Conventional techniques usually focus on visualizing the internal logic of a specific model type (i.e., deep neural networks), lacking the ability to extend to a more complex scenario where different model types are integrated. To this end, Manifold is designed as a generic framework that does not rely on or access the internal logic of the model and solely observes the input (i.e., instances or features) and the output (i.e., the predicted result and probability distribution). We describe the workflow of Manifold as an iterative process consisting of three major phases that are commonly involved in the model development and diagnosis process: inspection (hypothesis), explanation (reasoning), and refinement (verification). The visual components supporting these tasks include a scatterplot-based visual summary that overviews the models? outcome and a customizable tabular view that reveals feature discrimination. We demonstrate current applications of the framework on the classification and regression tasks and discuss other potential machine learning use scenarios where Manifold can be applied.",,,,,vimeo 289787203,10.1109/tvcg.2018.2864499,2018,2018,VAST,"Hall 1, Section C",Thursday,Explainable ML,2022-10-25,5:00:00 PM,5:20:00 PM
openaccessvis2018.csv,VAST,TVCG,Visual Analytics for Topic Model Optimization based on User-Steerable Speculative Execution,J),"Mennatallah El-Assady, Fabian Sperrle, Oliver Deussen, Daniel Keim, Christopher Collins",http://graphics.uni-konstanz.de/publikationen/ElAssady2018VisualAnalytic/visualanalyticstopic.pdf,"To effectively assess the potential consequences of human interventions in model-driven analytics systems, we establish the concept of speculative execution as a visual analytics paradigm for creating user-steerable preview mechanisms. This paper presents an explainable, mixed-initiative topic modeling framework that integrates speculative execution into the algorithmic decisionmaking process. Our approach visualizes the model-space of our novel incremental hierarchical topic modeling algorithm, unveiling its inner-workings. We support the active incorporation of the user?s domain knowledge in every step through explicit model manipulation interactions. In addition, users can initialize the model with expected topic seeds, the backbone priors. For a more targeted optimization, the modeling process automatically triggers a speculative execution of various optimization strategies, and requests feedback whenever the measured model quality deteriorates. Users compare the proposed optimizations to the current model state and preview their effect on the next model iterations, before applying one of them. This supervised human-in-the-loop process targets maximum improvement for minimum feedback and has proven to be effective in three independent studies that confirm topic model quality improvements.",,,,,vimeo 289787264,10.1109/tvcg.2018.2864769,2018,2018,VAST,"Hall 1, Section C",Thursday,Explainable ML,2022-10-25,5:20:00 PM,5:40:00 PM
openaccessvis2018.csv,VAST,TVCG,VIS4ML: An Ontology for Visual Analytics Assisted Machine Learning,J),"Dominik Sacha, Matthias Kraus, Daniel Keim, Min Chen",https://bib.dbvis.de/uploadedFiles/TVCG2864838.pdf,"While many VA workflows make use of machine-learned models to support analytical tasks, VA workflows have become increasingly important in understanding and improving Machine Learning (ML) processes. In this paper, we propose an ontology (VIS4ML) for a subarea of VA, namely ?VA-assisted ML?. The purpose of VIS4ML is to describe and understand existing VA workflows used in ML as well as to detect gaps in ML processes and the potential of introducing advanced VA techniques to such processes. Ontologies have been widely used to map out the scope of a topic in biology, medicine, and many other disciplines. We adopt the scholarly methodologies for constructing VIS4ML, including the specification, conceptualization, formalization, implementation, and validation of ontologies. In particular, we reinterpret the traditional VA pipeline to encompass model-development workflows. We introduce necessary definitions, rules, syntaxes, and visual notations for formulating VIS4ML and make use of semantic web technologies for implementing it in the Web Ontology Language (OWL). VIS4ML captures the high-level knowledge about previous workflows where VA is used to assist in ML. It is consistent with the established VA concepts and will continue to evolve along with the future developments in VA and ML. While this ontology is an effort for building the theoretical foundation of VA, it can be used by practitioners in real-world applications to optimize model-development workflows by systematically examining the potential benefits that can be brought about by either machine or human capabilities. Meanwhile, VIS4ML is intended to be extensible and will continue to be updated to reflect future advancements in using VA for building high-quality data-analytical models or for building such models rapidly",,,,,vimeo 289787814,10.1109/TVCG.2018.2864838,2018,2018,VAST,"Hall 1, Section C",Thursday,Explainable ML,2022-10-25,5:40:00 PM,6:00:00 PM
openaccessvis2018.csv,InfoVis,TVCG,Mitigating the Attraction Effect with Visualizations,J),"Evanthia Dimara, Gilles Bailly, Anastasia Bezerianos, Steven Franconeri",https://hal.inria.fr/hal-01845004v2/document,"Human decisions are prone to biases, and this is no less true for decisions made within data visualizations. Bias mitigation strategies often focus on the person, by educating people about their biases, typically with little success. We focus instead on the system, presenting the first evidence that altering the design of an interactive visualization tool can mitigate a strong bias ? the attraction effect. Participants viewed 2D scatterplots where choices between superior alternatives were affected by the placement of other suboptimal points. We found that highlighting the superior alternatives weakened the bias, but did not eliminate it. We then tested an interactive approach where participants completely removed locally dominated points from the view, inspired by the elimination by aspects strategy in the decision-making literature. This approach strongly decreased the bias, leading to a counterintuitive suggestion: tools that allow removing inappropriately salient or distracting data from a view may help lead users to make more rational decisions.",,https://aviz.fr/deletion,https://aviz.fr/deletion,,vimeo 289784657,10.1109/TVCG.2018.2865233,2018,2018,InfoVis,"Hall 1, Section D",Thursday,Perception & Cognition 2,2022-10-25,4:20:00 PM,4:40:00 PM
openaccessvis2018.csv,InfoVis,TVCG,Face to Face: Evaluating Visual Comparison,J),"Brian David Ondov, Nicole Jardine, Niklas Elmqvist, Steven Franconeri",http://users.umiacs.umd.edu/~elm/projects/face2face/face2face.pdf,"Data are often viewed as a single set of values, but those values frequently must be compared with another set. The existing evaluations of designs that facilitate these comparisons tend to be based on intuitive reasoning, rather than quantifiable measures. We build on this work with a series of crowdsourced experiments that use low-level perceptual comparison tasks that arise frequently in comparisons within data visualizations (e.g., which value changes the most between the two sets of data?). Participants completed these tasks across a variety of layouts: overlaid, two arrangements of juxtaposed small multiples, mirror-symmetric small multiples, and animated transitions. A staircase procedure sought the difficulty level (e.g., value change delta) that led to equivalent accuracy for each layout. Confirming prior intuition, we observe high levels of performance for overlaid versus standard small multiples. However, we also find performance improvements for both mirror symmetric small multiples and animated transitions. While some results are incongruent with common wisdom in data visualization, they align with previous work in perceptual psychology, and thus have potentially strong implications for visual comparison designs.",,,,,vimeo 289785372,10.1109/tvcg.2018.2864884,2018,2018,InfoVis,"Hall 1, Section D",Thursday,Perception & Cognition 2,2022-10-25,4:40:00 PM,5:00:00 PM
openaccessvis2018.csv,TVCG,TVCG,Task-Based Effectiveness of Basic Visualizations,T),"Bahador Saket, Alex Endert, €agatay Demiralp",https://arxiv.org/pdf/1709.08546.pdf,"Visualizations of tabular data are widely used; understanding their effectiveness in different task and data contexts is fundamental to scaling their impact. However, little is known about how basic tabular data visualizations perform across varying data analysis tasks. In this paper, we report results from a crowdsourced experiment to evaluate the effectiveness of five small scale (5-34 data points) two-dimensional visualization types?Table, Line Chart, Bar Chart, Scatterplot, and Pie Chart?across ten common data analysis tasks using two datasets. We find the effectiveness of these visualization types significantly varies across task, suggesting that visualization design would benefit from considering context-dependent effectiveness. Based on our findings, we derive recommendations on which visualizations to choose based on different tasks. We finally train a decision tree on the data we collected to drive a recommender, showcasing how to effectively engineer experimental user data into practical visualization systems.",,,https://github.com/gtvalab/ChartsEffectiveness/tree/master/Raw-Data,,vimeo 289789506,10.1109/tvcg.2018.2829750,2018,2018,InfoVis,"Hall 1, Section D",Thursday,Perception & Cognition 2,2022-10-25,5:00:00 PM,5:20:00 PM
openaccessvis2018.csv,InfoVis,TVCG,At a Glance: Approximate Entropy as a Measure of Line Chart Visualization Complexity,J),"Eugene Wu, Remco Chang, Abigail Mosca, Gabriel Ryan",http://arxiv.org/abs/1811.03180,"When inspecting information visualizations under time critical settings, such as emergency response or monitoring the heart rate in a surgery room, the user only has a small amount of time to view the visualization ""at a glance"". In these settings, it is important to provide a quantitative measure of the visualization to understand whether or not the visualization is too ""complex"" toaccurately judge at a glance. This paper proposes Pixel Approximate Entropy (PAE), which adapts the approximate entropy statistical measure commonly used to quantify regularity and unpredictability in time-series data, as a measure of visual complexity for linecharts. We show that PAE is correlated with user-perceived chart complexity, and that increased chart PAE correlates with reduced judgement accuracy. ?We also find that the correlation between PAE values and participants? judgment increases when the user has less time to examine the line charts.",,https://github.com/cudbg/pae,,,vimeo 289784475,10.1109/TVCG.2018.2865264,2018,2018,InfoVis,"Hall 1, Section D",Thursday,Perception & Cognition 2,2022-10-25,5:20:00 PM,5:40:00 PM
openaccessvis2018.csv,TVCG,TVCG,Correlation Judgment and Visualization Features: A Comparative Study,T),"Fumeng Yang, Lane Harrison, Ronald A. Rensink, Steven Franconeri, Remco Chang",https://github.com/Fumeng-Yang/VisualFeature_TVCG/blob/master/paper/VF_preprint.pdf,"Recent visualization research efforts have incorporated experimental techniques and perceptual models from the vision science community. Perceptual laws such as Weber's law, for example, have been used to model the perception of correlation in scatterplots. While this thread of research has progressively refined the modeling of the perception of correlation in scatterplots, it remains unclear as to why such perception can be modeled using relatively simple functions, e.g., linear and log-linear. In this paper, we investigate a longstanding hypothesis that people use visual features in a chart as a proxy for statistical measures like correlation. For a given scatterplot, we extract 49 candidate visual features and evaluate which best align with existing models and participant judgments. The results support the hypothesis that people attend to a small number of visual features when discriminating correlation in scatterplots. We discuss how this result may account for prior conflicting findings, and how visual features provide a baseline for future model-based approaches in visualization evaluation and design.",,,,,vimeo 289789613,10.1109/tvcg.2018.2810918,2018,2018,InfoVis,"Hall 1, Section D",Thursday,Perception & Cognition 2,2022-10-25,5:40:00 PM,6:00:00 PM
openaccessvis2018.csv,SciVis,TVCG,Firefly: Illumination Drones for Interactive Visualization,J),"Sergej Stoppel, Magnus Paulson Erga, Stefan Bruckner",https://vis.uib.no/wp-content/papercite-data/pdfs/VIS2018-Firefly.pdf,"Light specification in three dimensional scenes is a complex problem and several approaches have been presented that aim to automate this process. However, there are many scenarios where a static light setup is insufficient, as the scene content and camera position may change. Simultaneous manual control over the camera and light position imposes a high cognitive load on the user. To address this challenge, we introduce a novel approach for automatic scene illumination with Fireflies. Fireflies are intelligent virtual light drones that illuminate the scene by traveling on a closed path. The Firefly path automatically adapts to changes in the scene based on an outcome-oriented energy function. To achieve interactive performance, we employ a parallel rendering pipeline for the light path evaluations. We provide a catalog of energy functions for various application scenarios and discuss the applicability of our method on several examples.",,,,,video https://vis.uib.no/wp-content/papercite-data/vids/FinalVideo.mp4,10.1109/TVCG.2018.2864656,2018,2018,SciVis,Estrel Hall A+B,Thursday,Interaction and Multivariate Data,2022-10-25,4:20:00 PM,4:40:00 PM
openaccessvis2018.csv,SciVis,TVCG,CoDDA: A Flexible Copula-based Distribution Driven Analysis Framework for Large-Scale Multivariate Data,J),"Subhashis Hazarika, Soumya Dutta, Han-Wei Shen, Jen-Ping Chen",,,,,,,vimeo 290325658,10.1109/tvcg.2018.2864801,2018,2018,SciVis,Estrel Hall A+B,Thursday,Interaction and Multivariate Data,2022-10-25,4:40:00 PM,5:00:00 PM
openaccessvis2018.csv,SciVis,TVCG,"Details-First, Show Context, Overview Last: Supporting Exploration of Viscous Fingers in Large-Scale Ensemble Simulations ",J),"Timothy Basil Luciani, Andrew T Burks, Cassiano Sugiyama, Jonathan Komperda, Liz G.Elisabeta Marai",https://www.evl.uic.edu/documents/detailsfirst_ieee2018.pdf,"Visualization research often seeks designs that first establish an overview of the data, in accordance to the information seeking mantra: ?Overview first, zoom and filter, then details on demand ?. However, in computational fluid dynamics (CFD), as well as in other domains, there are many situations where such a spatial overview is not relevant or practical for users, for example when the experts already have a good mental overview of the data, or when an analysis of a large overall structure may not be related to the specific, information-driven tasks of users. Using scientific workflow theory and, as a vehicle, the problem of viscous finger evolution, we advocate an alternative model that allows domain experts to explore features of interest first, then explore the context around those features, and finally move to a potentially unfamiliar summarization overview. In a model instantiation, we show how a computational back-end can identify and track over time low-level, small features, then be used to filter the context of those features while controlling the complexity of the visualization, and finally to summarize and compare simulations. We demonstrate the effectiveness of this approach with an online web-based exploration of a total volume of data approaching half a billion seven-dimensional data points, and report supportive feedback provided by domain experts with respect to both the instantiation and the theoretical model.",,,,,vimeo 290328058,10.1109/TVCG.2018.2864849,2018,2018,SciVis,Estrel Hall A+B,Thursday,Interaction and Multivariate Data,2022-10-25,5:00:00 PM,5:20:00 PM
openaccessvis2018.csv,TVCG,TVCG,A Model of Spatial Directness in Interactive Visualization,T),"Stefan Bruckner, Tobias Isenberg, Timo Ropinski, Alexander Wiebel",https://hal.inria.fr/hal-01813889/document,"We discuss the concept of directness in the context of spatial interaction with visualization. In particular, we propose a model that allows practitioners to analyze and describe the spatial directness of interaction techniques, ultimately to be able to better understand interaction issues that may affect usability. To reach these goals, we distinguish between different types of directness. Each type of directness depends on a particular mapping between different spaces, for which we consider the data space, the visualization space, the output space, the user space, the manipulation space, and the interaction space. In addition to the introduction of the model itself, we also show how to apply it to several real-world interaction scenarios in visualization, and thus discuss the resulting types of spatial directness, without recommending either more direct or more indirect interaction techniques. In particular, we will demonstrate descriptive and evaluative usage of the proposed model, and also briefly discuss its generative usage.",,,,,vimeo 289789140,10.1109/tvcg.2018.2848906,2018,2018,SciVis,Estrel Hall A+B,Thursday,Interaction and Multivariate Data,2022-10-25,5:20:00 PM,5:40:00 PM
openaccessvis2018.csv,TVCG,TVCG,Decal-Lenses: Interactive Lenses on Surfaces for Multivariate Visualization,T),"Allan Rocha, Julio Daniel Silva, Usman R. Alim, Sheelagh Carpendale, Mario Costa Sousa",http://pages.cpsc.ucalgary.ca/~acarocha/projects/decal_lenses/files/camera_ready.pdf,"We present decal-lenses, a new interaction technique that extends the concept of magic lenses to augment and manage multivariate visualizations on arbitrary surfaces. Our object-space lenses follow the surface geometry and allow the user to change the point of view during data exploration while maintaining a spatial reference to positions where one or more lenses were placed. Each lens delimits specific regions of the surface where one or more attributes can be selected or combined. Similar to 2D lenses, the user interacts with our lenses in real-time, switching between different attributes within the lens context. The user can also visualize the surface data representations from the point of view of each lens by using local cameras. To place lenses on surfaces of intricate geometry, such as the human brain, we introduce the concept of support surfaces for designing interaction techniques. Support surfaces provide a way to place and interact with the lenses while avoiding holes and occluded regions during data exploration. We further extend decal-lenses to arbitrary regions using brushing and lassoing operations. We discuss the applicability of our technique and present several examples where our lenses can be useful to create a customized exploration of multivariate data on surfaces. ",,,,,vimeo 295735599,10.1109/tvcg.2018.2850781,2018,2018,SciVis,Estrel Hall A+B,Thursday,Interaction and Multivariate Data,2022-10-25,5:40:00 PM,6:00:00 PM
openaccessvis2018.csv,SciVis,SciVis,Cluster-Based Visualization for Merger Tree Data: The Challenge of Missing Expectations,,"Annie Preston, Kwan-Liu Ma",,,,,,,vimeo 290328886,,2018,2018,SciVis Short Papers,Estrel Hall C,Thursday,"Flow, Astrophysics, and Computationally Intensive Data Visualization",2022-10-25,4:20:00 PM,4:32:00 PM
openaccessvis2018.csv,SciVis,SciVis,Visualization of Uncertainty for Computationally Intensive Simulations Using High Fidelity Emulators,,"Ayan Biswas, Earl Lawrence, James Ahrens",http://ayanbiswas.net/vis18m-sub1022-cam-i7.pdf,"Visualization of high-fidelity scientific simulations with high-dimensional inputs and outputs is an important task. Existing high-dimensional data visualization approaches generally assume a substantial amount of data are available or can be generated as needed. However, many of these simulations can be very computationally intensive, taking minutes or hours to run. Analysis and visualization of such expensive simulations poses a challenge. Statistical emulators are frequently used to approximate simulations for statistical analyses. In this work, we propose a visualization tool for an emulator of the simulator and describe how emulators can be used to create effective visualization systems. We choose Gaussian process emulators for this purpose as they enable fast and accurate prediction with uncertainty information. Using these predictions, we design a system that enables visualization of high-dimensional input and output spaces of complex physics simulations. Users of our system can get a detailed understanding of the uncertainties associated with the emulator predictions in both input and output space for a high-dimensional simulation.",,,,,vimeo 290328642,,2018,2018,SciVis Short Papers,Estrel Hall C,Thursday,"Flow, Astrophysics, and Computationally Intensive Data Visualization",2022-10-25,4:32:00 PM,4:44:00 PM
openaccessvis2018.csv,SciVis,SciVis,A Lagrangian Method for Extracting Eddy Boundaries in the Red Sea and the Gulf of Aden,,"Anke Friederici, Habib Toye, Ibrahim Hoteit, Tino Weinkauf, Holger Theisel, Markus Hadwiger",http://www.medvis-award.de/visual/files/publications/2018/Friederici_2018_VIS_paper.pdf,"Mesoscale ocean eddies play a major role for both the intermixing of water and the transport of biological mass. This makes the identification and tracking of their shape, location and deformation over time highly important for a number of applications. While eddies maintain a roughly circular shape in the free ocean, the narrow basins of the Red Sea and Gulf of Aden lead to the formation of irregular eddy shapes that existing methods struggle to identify. We propose the following model: Inside an eddy, particles rotate around a common core and thereby remain at a constant distance under a certain parametrization. The transition to the more unpredictable flow on the outside can thus be identified as the eddy boundary. We apply this algorithm on a realistic simulation of the Red Sea circulation, where we are able to identify the shape of irregular eddies robustly and more coherently than previous methods. We visualize the eddies as tubes in space-time to enable the analysis of their movement and deformation over several weeks.",,,,,video http://vccvisualization.org/publications/2018_friederici_redseaeddies.mp4,,2018,2018,SciVis Short Papers,Estrel Hall C,Thursday,"Flow, Astrophysics, and Computationally Intensive Data Visualization",2022-10-25,4:45:00 PM,4:57:00 PM
openaccessvis2018.csv,SciVis,SciVis,FTLE Ridge Lines for Long Integration Times,,"Thomas Wilde, Christian R”ssl, Holger Theisel",http://www.medvis-award.de/visual/files/publications/2018/Wilde_2018_VISb.pdf,"We present an approach to the extraction of FTLE ridges for 2D unsteady vector fields under long integration times. This is a hard problem because such FTLE ridges tend to be sharp and close to each other. The main feature of our approach is that it does not only use an FTLE sampling at the desired final integration time but incorporates samples from prior integration times as well. With this additional information, the new method produces more and finer ridge lines than previous approaches. Based on this output, we can consider FTLE ridge statistics. We test the approach on synthetic benchmarks and real-world data sets.",,,,,vimeo 290328753,,2018,2018,SciVis Short Papers,Estrel Hall C,Thursday,"Flow, Astrophysics, and Computationally Intensive Data Visualization",2022-10-25,4:57:00 PM,5:09:00 PM
openaccessvis2018.csv,SciVis,SciVis,Ocean Current Segmentation at Different Depths and Correlation with Temperature in a MPAS-Ocean Simulation,,"Petra Gospodnetic, Divya Banesh, Philip Wolfram, Mark Petersen, Hans Hagen, James Ahrens, Markus Rauhut",,,,,,,vimeo 290328665,,2018,2018,SciVis Short Papers,Estrel Hall C,Thursday,"Flow, Astrophysics, and Computationally Intensive Data Visualization",2022-10-25,5:10:00 PM,5:22:00 PM
openaccessvis2018.csv,SciVis,SciVis,"TimeTubes: Automatic Extraction of Observable Blazar Features from Long-Term, Multi-Dimensional Datasets",,"Naoko Sawada, Masanori Nakayama, Makoto Uemura, Issei Fujishiro",,,,,,,vimeo 290328934,,2018,2018,SciVis Short Papers,Estrel Hall C,Thursday,"Flow, Astrophysics, and Computationally Intensive Data Visualization",2022-10-25,5:22:00 PM,5:34:00 PM
openaccessvis2018.csv,SciVis,SciVis,aflak: Pluggable Visual Programming Environment with Quick Feedback Loop Tuned for Astrophysical Observations,,"Malik Olivier Boussejra, Kazuya Matsubayashi, Yuriko Takeshima, Shunya Takekawa, Rikuo Uchiki, Makoto Uemura, Issei Fujishiro",,,,,,,vimeo 290328343,,2018,2018,SciVis Short Papers,Estrel Hall C,Thursday,"Flow, Astrophysics, and Computationally Intensive Data Visualization",2022-10-25,5:35:00 PM,5:47:00 PM
openaccessvis2018.csv,SciVis,SciVis,Biclusters based Visual Exploration of Multivariate Scientific Data,,"Xiangyang He, Yubo Tao, Qirui Wang, Hai Lin",http://www.cad.zju.edu.cn/home/ybtao/papers/SciVis18_Biclusters.pdf,"This paper proposes a co-analysis framework based on biclusters, i.e., two subsets of variables and voxels with close scalar-value relationships, to guide the visual exploration process of multivariate data. We first automatically extract all meaningful biclusters, each of which only contains voxels with a similar scalar-value pattern over a subset of variables. These biclusters are organized according to their variable sets, and further grouped by a similarity metric to reduce redundancy and encourage diversity during visual exploration. Biclusters are visually represented in coordinated views to facilitate interactive exploration of multivariate data from the similarity between biclusters and the correlation of scalar values with different variables. Experiments demonstrate the effectiveness of our framework in exploring local relationships among variables, biclusters and scalar values in the data.",,,,,vimeo 290328582,,2018,2018,SciVis Short Papers,Estrel Hall C,Thursday,"Flow, Astrophysics, and Computationally Intensive Data Visualization",2022-10-25,5:47:00 PM,6:00:00 PM
openaccessvis2018.csv,VAST,TVCG,MAQUI: Interweaving Queries and Pattern Mining for Recursive Event Sequence Exploration,J),"Po-Ming Law, Zhicheng Liu, Sana Malik, Rahul Basole",https://osf.io/tg7w5/,"Exploring event sequences by defining queries alone or by using mining algorithms alone is often not sufficient to support analysis. Analysts often interweave querying and mining in a recursive manner during event sequence analysis: sequences extracted as query results are used for mining patterns, patterns generated are incorporated into a new query for segmenting the sequences, and the resulting segments are mined or queried again. To support flexible analysis, we propose a framework that describes the process of interwoven querying and mining. Based on this framework, we developed MAQUI, a Mining And Querying User Interface that enables recursive event sequence exploration. To understand the efficacy of MAQUI, we conducted two case studies with domain experts. The findings suggest that the capability of interweaving querying and mining helps the participants articulate their questions and gain novel insights from their data.",,https://osf.io/w5e62/,,,vimeo 289787863,10.1109/TVCG.2018.2864886,2018,2018,VAST,"Hall 1, Section C",Friday,"Event, Sequence, and ML",2022-10-26,9:00:00 AM,9:20:00 AM
openaccessvis2018.csv,VAST,TVCG,iForest: Interpreting Random Forests via Visual Analytics,J),"Xun Zhao, Yanhong Wu, Dik Lun Lee, Weiwei Cui",http://zhaoxun.me/publication/iForest.pdf,"As an ensemble model that consists of many independent decision trees, random forests generate predictions by feeding the input to internal trees and summarizing their outputs. The ensemble nature of the model helps random forests outperform any individual decision tree. However, it also leads to a poor model interpretability, which significantly hinders the model from being used in fields that require transparent and explainable predictions, such as medical diagnosis and financial fraud detection. The interpretation challenges stem from the variety and complexity of the contained decision trees. Each decision tree has its unique structure and properties, such as the features used in the tree and the feature threshold in each tree node. Thus, a data input may lead to a variety of decision paths. To understand how a final prediction is achieved, it is desired to understand and compare all decision paths in the context of all tree structures, which is a huge challenge for any users. In this paper, we propose a visual analytic system aiming at interpreting random forest models and predictions. In addition to providing users with all the tree information, we summarize the decision paths in random forests, which eventually reflects the working mechanism of the model and reduces users? mental burden of interpretation. To demonstrate the effectiveness of our system, two usage scenarios and a qualitative user study are conducted.",,,,,vimeo 289787165,10.1109/tvcg.2018.2864475,2018,2018,VAST,"Hall 1, Section C",Friday,"Event, Sequence, and ML",2022-10-26,9:20:00 AM,9:40:00 AM
openaccessvis2018.csv,VAST,TVCG,Visual Progression Analysis of Event Sequence Data,J),"Shunan Guo, Zhuochen Jin, David Gotz, Fan Du, Hongyuan Zha, Nan Cao",http://gotz.web.unc.edu/files/2018/08/2018_VAST_EventThread_V2_Preprint.pdf,"Event sequence data is common to a broad range of application domains, from security to health care to scholarly communication. This form of data captures information about the progression of events for an individual entity (e.g., a computer network device; a patient; an author) in the form of a series of time-stamped observations. Moreover, each event is associated with an event type (e.g., a computer login attempt, or a hospital discharge). Analyses of event sequence data have been shown to help reveal important temporal patterns, such as clinical paths resulting in improved outcomes, or an understanding of common career trajectories for scholars. Moreover, recent research has demonstrated a variety of techniques designed to overcome methodological challenges such as large volumes of data and high dimensionality. However, the effective identication and analysis of latent stages of progression, which can allow for variation within different but similarly evolving event sequences, remain a signicant challenge with important real-world motivations. In this paper, we propose an unsupervised stage analysis algorithm to identify semantically meaningful progression stages as well as the critical events which help dene those stages. The algorithm follows three key steps: (1) event representation estimation, (2) event sequence warping and alignment, and (3) sequence segmentation. We also present a novel visualization system, ET2 , which interactively illustrates the results of the stage analysis algorithm to help reveal evolution patterns across stages. Finally, we report three forms of evaluation for ET2 : (1) case studies with two real-world datasets, (2) interviews with domain expert users, and (3) a performance evaluation on the progression analysis algorithm and the visualization design",,,,,vimeo 289787414,10.1109/TVCG.2018.2864885,2018,2018,VAST,"Hall 1, Section C",Friday,"Event, Sequence, and ML",2022-10-26,9:40:00 AM,10:00:00 AM
openaccessvis2018.csv,TVCG,TVCG,StreamExplorer: A Multi-Stage System for Visually Exploring Events in Social Streams,T),"Yingcai Wu, Zhutian Chen, Guodao Sun, Xiao Xie, Nan Cao, Shixia Liu, Weiwei Cui",http://zjuvis.org/files/streamexplorer.pdf,"Analyzing social streams is important for many applications, such as crisis management. However, the considerable diversity, increasing volume, and high dynamics of social streams of large events continue to be significant challenges that must be overcome to ensure effective exploration. We propose a novel framework by which to handle complex social streams on a budget PC. This framework features two components: 1) an online method to detect important time periods (i.e., subevents), and 2) a tailored GPU-assisted Self-Organizing Map (SOM) method, which clusters the tweets of subevents stably and efficiently. Based on the framework, we present StreamExplorer to facilitate the visual analysis, tracking, and comparison of a social stream at three levels. At a macroscopic level, StreamExplorer uses a new glyph-based timeline visualization, which presents a quick multi-faceted overview of the ebb and flow of a social stream. At a mesoscopic level, a map visualization is employed to visually summarize the social stream from either a topical or geographical aspect. At a microscopic level, users can employ interactive lenses to visually examine and explore the social stream from different perspectives. Two case studies and a task-based evaluation are used to demonstrate the effectiveness and usefulness of StreamExplorer.",,,,,vimeo 289788908,10.1109/tvcg.2017.2764459,2017,2018,VAST,"Hall 1, Section C",Friday,"Event, Sequence, and ML",2022-10-26,10:00:00 AM,10:20:00 AM
openaccessvis2018.csv,VAST,TVCG,Duet: Helping Data Analysis Novices Conduct Pairwise Comparisons by Minimal Specification,J),"Po-Ming Law, Rahul Basole, Yanhong Wu",https://osf.io/rzk49/,"Data analysis novices often encounter barriers in executing low-level operations for pairwise comparisons. They may also run into barriers in interpreting the artifacts (e.g., visualizations) created as a result of the operations. We developed Duet, a visual analysis system designed to help data analysis novices conduct pairwise comparisons by addressing execution and interpretation barriers. To reduce the barriers in executing low-level operations during pairwise comparison, Duet employs minimal specication: when one object group (i.e. a group of records in a data table) is specied, Duet recommends object groups that are similar to or different from the specied one; when two object groups are specied, Duet recommends similar and different attributes between them. To lower the barriers in interpreting its recommendations, Duet explains the recommended groups and attributes using both visualizations and textual descriptions. We conducted a qualitative evaluation with eight participants to understand the effectiveness of Duet. The results suggest that minimal specication is easy to use and Duet's explanations are helpful for interpreting the recommendations despite some usability issues.",,https://github.com/terrancelaw/Duet/tree/master,,,vimeo 289787850,10.1109/TVCG.2018.2864526,2018,2018,VAST,"Hall 1, Section C",Friday,"Event, Sequence, and ML",2022-10-26,10:20:00 AM,10:40:00 AM
openaccessvis2018.csv,InfoVis,TVCG,Visualizing Uncertain Tropical Cyclone Predictions using Representative Samples from Ensembles of Forecast Tracks,J),"Le Liu, Lace M. K. Padilla, Sarah Creem-Regehr, Donald House",http://lacepadilla.com/Downloads/publications/Liuetal_2018.pdf,"A common approach to sampling the space of a prediction is the generation of an ensemble of potential outcomes, where the ensemble's distribution reveals the statistical structure of the prediction space. For example, the US National Hurricane Center generates multiple day predictions for a storm's path, size, and wind speed, and then uses a Monte Carlo approach to sample this prediction into a large ensemble of potential storm outcomes. Various forms of summary visualizations are generated from such an ensemble, often using spatial spread to indicate its statistical characteristics. However, studies have shown that changes in the size of such summary glyphs, representing changes in the uncertainty of the prediction, are frequently confounded with other attributes of the phenomenon, such as its size or strength. In addition, simulation ensembles typically encode multivariate information, which can be difficult or confusing to include in a summary display. This problem can be overcome by directly displaying the ensemble as a set of annotated trajectories, however this solution will not be effective if ensembles are densely overdrawn or structurally disorganized. We propose to overcome these difficulties by selectively sampling the original ensemble, constructing a smaller representative and spatially well organized ensemble. This can be drawn directly as a set of paths that implicitly reveals the underlying spatial uncertainty distribution of the prediction. Since this approach does not use a visual channel to encode uncertainty, additional information can more easily be encoded in the display without leading to visual confusion. To demonstrate our argument, we describe the development of a visualization for ensembles of tropical cyclone forecast tracks, explaining how their spatial and temporal predictions, as well as other crucial storm characteristics such as size and intensity, can be clearly revealed. We verify the effectiveness of this visualization approach through a cognitive study exploring how storm damage estimates are affected by the density of tracks drawn, and by the presence or absence of annotating information on storm size and intensity.",,https://osf.io/hy3ba/,https://osf.io/hy3ba/,,vimeo 289784601,10.1109/TVCG.2018.2865193,2018,2018,InfoVis,"Hall 1, Section D",Friday,Uncertainty & Error,2022-10-26,9:00:00 AM,9:20:00 AM
openaccessvis2018.csv,InfoVis,TVCG,Hypothetical Outcome Plots Help Untrained Observers Judge Trends in Ambiguous Data,J),"Alex Kale, Francis Nguyen, Matthew Kay, Jessica Hullman",http://users.eecs.northwestern.edu/~jhullman/hops_jobs_pfs.pdf,"Animated representations of outcomes drawn from distributions (hypothetical outcome plots, or HOPs) are used in the media and other public venues to communicate uncertainty. HOPs greatly improve multivariate probability estimation over conventional static uncertainty visualizations and leverage the ability of the visual system to quickly, accurately, and automatically process the summary statistical properties of ensembles. However, it is unclear how well HOPs support applied tasks resembling real world judgments posed in uncertainty communication. We identify and motivate an appropriate task to investigate realistic judgments of uncertainty in the public domain through a qualitative analysis of uncertainty visualizations in the news. We contribute two crowdsourced experiments comparing the effectiveness of HOPs, error bars, and line ensembles for supporting perceptual decision-making from visualized uncertainty. Participants infer which of two possible underlying trends is more likely to have produced a sample of time series data by referencing uncertainty visualizations which depict the two trends with variability due to sampling error. By modeling each participant's accuracy as a function of the level of evidence presented over many repeated judgments, we find that observers are able to correctly infer the underlying trend in samples conveying a lower level of evidence when using HOPs rather than static aggregate uncertainty visualizations as a decision aid. Modeling approaches like ours contribute theoretically grounded and richly descriptive accounts of user perceptions to visualization evaluation.",https://medium.com/@uwdata/hypothetical-outcome-plots-hops-help-users-separate-signal-from-noise-870d4e2b75d7,,https://github.com/kalealex/jobs-report-hops,https://osf.io/8cte3/registrations/,vimeo 289785258,10.1109/tvcg.2018.2864909,2018,2018,InfoVis,"Hall 1, Section D",Friday,Uncertainty & Error,2022-10-26,9:20:00 AM,9:40:00 AM
openaccessvis2018.csv,InfoVis,TVCG,In Pursuit of Error: A Survey of Uncertainty Visualization Evaluation,J),"Jessica Hullman, Xiaoli Qiao, Michael Correll, Alex Kale, Matthew Kay",https://github.com/jhullman/uncertaintyVisEval/blob/master/uncertainty_vis_eval.pdf,"Understanding and accounting for uncertainty is critical to effectively reasoning about visualized data. However, evaluating the impact of an uncertainty visualization is complex due to the difficulties that people have interpreting uncertainty and the challenge of defining correct behavior with uncertainty information. Currently, evaluators of uncertainty visualization must rely on general purpose visualization evaluation frameworks which can be ill-equipped to provide guidance with the unique difficulties of assessing judgments under uncertainty. To help evaluators navigate these complexities, we present a taxonomy for characterizing decisions made in designing an evaluation of an uncertainty visualization. Our taxonomy differentiates six levels of decisions that comprise an uncertainty visualization evaluation: the behavioral targets of the study, expected effects from an uncertainty visualization, evaluation goals, measures, elicitation techniques, and analysis approaches. Applying our taxonomy to 86 user studies of uncertainty visualizations, we find that existing evaluation practice, particularly in visualization research, focuses on Performance and Satisfaction-based measures that assume more predictable and statistically-driven judgment behavior than is suggested by research on human judgment and decision making. We reflect on common themes in evaluation practice concerning the interpretation and semantics of uncertainty, the use of confidence reporting, and a bias toward evaluating performance as accuracy rather than decision quality. We conclude with a concrete set of recommendations for evaluators designed to reduce the mismatch between the conceptualization of uncertainty in visualization versus other fields.",,https://github.com/jhullman/uncertaintyVisEval,,,vimeo 289785271,10.1109/tvcg.2018.2864889,2018,2018,InfoVis,"Hall 1, Section D",Friday,Uncertainty & Error,2022-10-26,9:40:00 AM,10:00:00 AM
openaccessvis2018.csv,InfoVis,TVCG,Where's my data? Evaluating Visualizations with Missing Data,J),"Hayeong Song, Danielle Albers Szafir",http://cmci.colorado.edu/visualab/papers/song_VIS_2018.pdf,Many real-world datasets are incomplete due to factors such as data collection failures or misalignments between fused datasets. Visualizations of incomplete datasets should allow analysts to draw conclusions from their data while effectively reasoning about the quality of the data and resulting conclusions. We conducted a pair of crowdsourced studies to measure how the methods used to impute and visualize missing data may influence analysts' perceptions of data quality and their confidence in their conclusions. Our experiments used different design choices for line graphs and bar charts to estimate averages and trends in incomplete time series datasets. Our results provide preliminary guidance for visualization designers to consider when working with incomplete data in different domains and scenarios.,,,http://cmci.colorado.edu/visualab/MissingData/,,vimeo 289785184,10.1109/TVCG.2018.2864914,2018,2018,InfoVis,"Hall 1, Section D",Friday,Uncertainty & Error,2022-10-26,10:00:00 AM,10:20:00 AM
openaccessvis2018.csv,InfoVis,TVCG,A Framework for Externalizing Implicit Error Using Visualization,J),"Nina McCurdy, Julie Gerdes, Miriah Meyer",http://sci.utah.edu/~vdl/papers/2018_infovis_IE-Framework.pdf,"This paper presents a framework for externalizing and analyzing expert knowledge about discrepancies in data through the use of visualization. Grounded in an 18-month design study with global health experts, the framework formalizes the notion of data discrepancies as implicit error, both in global health data and more broadly. We use the term implicit error to describe measurement error that is inherent to and pervasive throughout a dataset, but that isn't explicitly accounted for or defined. Instead, implicit error exists in the minds of experts, is mainly qualitative, and is accounted for subjectively during expert interpretation of the data. Externalizing knowledge surrounding implicit error can assist in synchronizing, validating, and enhancing interpretation, and can inform error analysis and mitigation. The framework consists of a description of implicit error components that are important for downstream analysis, along with a process model for externalizing and analyzing implicit error using visualization. As a second contribution, we provide a rich, reflective, and verifiable description of our research process as an exemplar summary toward the ongoing inquiry into ways of increasing the validity and transferability of design study research.",,https://github.com/visdesignlab/IEFramework,,,vimeo 289785202,10.1109/tvcg.2018.2864913,2018,2018,InfoVis,"Hall 1, Section D",Friday,Uncertainty & Error,2022-10-26,10:20:00 AM,10:40:00 AM
openaccessvis2018.csv,SciVis,TVCG,Exploring Time-Varying Multivariate Volume Data Using Matrix of Isosurface Similarity Maps,J),"Jun Tao, Martin Imre, Chaoli Wang, Nitesh V Chawla, Hanqi Guo, G”khan Sever, Seung Hyun Kim",https://www3.nd.edu/~cwang11/research/vis18-mism.pdf,"We present a novel visual representation and interface named the matrix of isosurface similarity maps (MISM) for effective exploration of large time-varying multivariate volumetric data sets. MISM synthesizes three types of similarity maps (i.e., self, temporal, and variable similarity maps) to capture the essential relationships among isosurfaces of different variables and time steps. Additionally, it serves as the main visual mapping and navigation tool for examining the vast number of isosurfaces and exploring the underlying time-varying multivariate data set. We present temporal clustering, variable grouping, and interactive filtering to reduce the huge exploration space of MISM. In conjunction with the isovalue and isosurface views, MISM allows users to identify important isosurfaces or isosurface pairs and compare them over space, time, and value range. More importantly, we introduce path recommendation that suggests, animates, and compares traversal paths for effectively exploring MISM under varied criteria and at different levels-of-detail. A silhouette-based method is applied to render multiple surfaces of interest in a visually succinct manner. We demonstrate the effectiveness of our approach with case studies of several time-varying multivariate data sets and an ensemble data set, and evaluate our work with two domain experts.",,,,,vimeo 290325769,10.1109/tvcg.2018.2864808,2018,2018,SciVis,Estrel Hall C,Friday,Time-varying Data,2022-10-26,9:00:00 AM,9:20:00 AM
openaccessvis2018.csv,SciVis,TVCG,Visual Analysis of Spatio-temporal Relations of Pairwise Attributes in Unsteady Flow,J),"Marzieh Berenjkoub, Rodolfo Ostilla Monico, Robert S. Laramee, Guoning Chen",,,,,,,vimeo 290325964,10.1109/tvcg.2018.2864817,2018,2018,SciVis,Estrel Hall C,Friday,Time-varying Data,2022-10-26,9:20:00 AM,9:40:00 AM
openaccessvis2018.csv,SciVis,TVCG,Time-Dependent Flow seen through Approximate Observer Killing Fields,J),"Markus Hadwiger, Matej Mlejnek, Thomas Theussl, Peter Rautek",http://vccvisualization.org/publications/2018_hadwiger_killingobservers.pdf,"Flow fields are usually visualized relative to a global observer, i.e., a single frame of reference. However, often no global frame can depict all flow features equally well. Likewise, objective criteria for detecting features such as vortices often use either a global reference frame, or compute a separate frame for each point in space and time. We propose the first general framework that enables choosing a smooth trade-off between these two extremes. Using global optimization to minimize specific differential geometric properties, we compute a time-dependent observer velocity field that describes the motion of a continuous field of observers adapted to the input flow. This requires developing the novel notion of an observed time derivative. While individual observers are restricted to rigid motions, overall we compute an approximate Killing field, corresponding to almost-rigid motion. This enables continuous transitions between different observers. Instead of focusing only on flow features, we furthermore develop a novel general notion of visualizing how all observers jointly perceive the input field. This in fact requires introducing the concept of an observation time, with respect to which a visualization is computed. We develop the corresponding notions of observed stream, path, streak, and time lines. For efficiency, these characteristic curves can be computed using standard approaches, by first transforming the input field accordingly. Finally, we prove that the input flow perceived by the observer field is objective. This makes derived flow features, such as vortices, objective as well.",,https://github.com/vccvisualization/killingobservers,,,vimeo 290327432,10.1109/tvcg.2018.2864839,2018,2018,SciVis,Estrel Hall C,Friday,Time-varying Data,2022-10-26,9:40:00 AM,10:00:00 AM
openaccessvis2018.csv,TVCG,TVCG,An Exploratory Framework for Cyclone Identification and Tracking,T),"Akash Anil Valsangkar, Joy Merwin Monteiro, Vidya Narayanan, Ingrid Hotz, Vijay Natarajan",https://vgl.csa.iisc.ac.in/pdf/pub/CycloneTrackingTVCG_Akash.pdf,"Analyzing depressions plays an important role in meteorology, especially in the study of cyclones. In particular, the study of the temporal evolution of cyclones requires a robust depression tracking framework. To cope with this demand we propose a pipeline for the exploration of cyclones and their temporal evolution. This entails a generic framework for their identification and tracking. The fact that depressions and cyclones are not well-defined objects and their shape and size characteristics change over time makes this task especially challenging. Our method combines the robustness of topological approaches and the detailed tracking information from optical flow analysis. At first cyclones are identified within each time step based on well-established topological concepts. Then candidate tracks are computed from an optical flow field. These tracks are clustered within a moving time window to distill dominant coherent cyclone movements, which are then forwarded to a final tracking step. In contrast to previous methods our method requires only a few intuitive parameters. An integration into an exploratory framework helps in the study of cyclone movement by identifying smooth, representative tracks. Multiple case studies demonstrate the effectiveness of the method in tracking cyclones, both in the northern and southern hemisphere",,,,,youtube DLv-EKwZjSI,10.1109/tvcg.2018.2810068,2018,2018,SciVis,Estrel Hall C,Friday,Time-varying Data,2022-10-26,10:00:00 AM,10:20:00 AM
openaccessvis2018.csv,TVCG,TVCG,Popup-Plots: Warping Temporal Data Visualization,T),"Johanna Schmidt, Dominik Fleischmann, Bernhard Preim, Norbert Brandle, Gabriel Mistelbauer",,,,,,,vimeo 289789393,10.1109/tvcg.2018.2841385,2018,2018,SciVis,Estrel Hall C,Friday,Time-varying Data,2022-10-26,10:20:00 AM,10:40:00 AM
openaccessvis2019.csv,VAST,TVCG,FlowSense: A Natural Language Interface for Visual Data Exploration within a Dataflow System,,"Bowen Yu, Claudio T. Silva",https://arxiv.org/pdf/1908.00681.pdf,"Dataflow visualization systems enable flexible visual data exploration by allowing the user to construct a dataflow diagram that composes query and visualization modules to specify system functionality. However learning dataflow diagram usage presents overhead that often discourages the user. In this work we design FlowSense, a natural language interface for dataflow visualization systems that utilizes state-of-the-art natural language processing techniques to assist dataflow diagram construction. FlowSense employs a semantic parser with special utterance tagging and special utterance placeholders to generalize to different datasets and dataflow diagrams. It explicitly presents recognized dataset and diagram special utterances to the user for dataflow context awareness. With FlowSense the user can expand and adjust dataflow diagrams more conveniently via plain English. We apply FlowSense to the VisFlow subset-flow visualization system to enhance its usability. We evaluate FlowSense by one case study with domain experts on a real-world data analysis problem and a formal user study.",,,,,vimeo 360154533,10.1109/TVCG.2019.2934668,2019,2019,Other,Ballroom ABC,Tuesday,VIS Best Paper Awards,2022-10-22,,
openaccessvis2019.csv,InfoVis,TVCG,Data Changes Everything: Challenges and Opportunities in Data Visualization Design Handoff,,"Jagoda Walny, Christian Frisson, Mieka West, Doris Kosminsky, S?ren Knudsen, Sheelagh Carpendale, Wesley Willett",https://arxiv.org/pdf/1908.00192.pdf,"Complex data visualization design projects often entail collaboration between people with different visualization-related skills. For example, many teams include both designers who create new visualization designs and developers who implement the resulting visualization software. We identify gaps between data characterization tools, visualization design tools, and development platforms that pose challenges for designer-developer teams working to create new data visualizations. While it is common for commercial interaction design tools to support collaboration between designers and developers, creating data visualizations poses several unique challenges that are not supported by current tools. In particular, visualization designers must characterize and build an understanding of the underlying data, then specify layouts, data encodings, and other data-driven parameters that will be robust across many different data values. In larger teams, designers must also clearly communicate these mappings and their dependencies to developers, clients, and other collaborators. We report observations and reflections from five large multidisciplinary visualization design projects and highlight six data-specific visualization challenges for design specification and handoff. These challenges include adapting to changing data, anticipating edge cases in data, understanding technical challenges, articulating data-dependent interactions, communicating data mappings, and preserving the integrity of data mappings across iterations. Based on these observations, we identify opportunities for future tools for prototyping, testing, and communicating data-driven designs, which might contribute to more successful and collaborative data visualization design.",,,,,vimeo 360483702,10.1109/TVCG.2019.2934538,2019,2019,Other,Ballroom ABC,Tuesday,VIS Best Paper Awards,2022-10-22,,
openaccessvis2019.csv,SciVis,TVCG,InSituNet: Deep Image Synthesis for Parameter Space Exploration of Ensemble Simulations,,"Wenbin He, Junpeng Wang, Hanqi Guo, Ko-Chih Wang, Han-Wei Shen, Mukund Raj, Youssef S. G. Nashed, Tom Peterka",https://arxiv.org/pdf/1908.00407.pdf,"We propose InSituNet, a deep learning based surrogate model to support parameter space exploration for ensemble simulations that are visualized in situ. In situ visualization, generating visualizations at simulation time, is becoming prevalent in handling large-scale simulations because of the I/O and storage constraints. However, in situ visualization approaches limit the flexibility of post-hoc exploration because the raw simulation data are no longer available. Although multiple image-based approaches have been proposed to mitigate this limitation, those approaches lack the ability to explore the simulation parameters. Our approach allows flexible exploration of parameter space for large-scale ensemble simulations by taking advantage of the recent advances in deep learning. Specifically, we design InSituNet as a convolutional regression model to learn the mapping from the simulation and visualization parameters to the visualization results. With the trained model, users can generate new images for different simulation parameters under various visualization settings, which enables in-depth analysis of the underlying ensemble simulations. We demonstrate the effectiveness of InSituNet in combustion, cosmology, and ocean simulations through quantitative and qualitative evaluations.",,,,,vimeo 359998980,10.1109/TVCG.2019.2934312,2019,2019,Other,Ballroom ABC,Tuesday,VIS Best Paper Awards,2022-10-22,,
openaccessvis2019.csv,Short,Short,Periphery Plots for Contextualizing Heterogeneous Time-Based Charts,,"Bryce Morrow, Trevor Manz, Arlene E. Chung, Nils Gehlenborg, David Gotz",https://arxiv.org/pdf/1906.07637.pdf,"Patterns in temporal data can often be found across different scales, such as days, weeks, and months, making effective visualization of time-based data challenging. Here we propose a new approach for providing focus and context in time-based charts to enable interpretation of patterns across time scales. Our approach employs a focus zone with a time and a second axis, that can either represent quantities or categories, as well as a set of adjacent periphery plots that can aggregate data along the time, value, or both dimensions. We present a framework for periphery plots and describe two use cases that demonstrate the utility of our approach.",,,,,vimeo 363453522,,,2019,Other,Ballroom ABC,Tuesday,VIS Best Paper Awards,2022-10-22,,
openaccessvis2019.csv,VAST,TVCG,NNVA: Neural Network Assisted Visual Analysis of Yeast Cell Polarization Simulation,,"Subhashis Hazarika, Haoyu Li, Ko-Chih Wang, Han-Wei Shen, Ching-Shan Chou",https://arxiv.org/pdf/1904.09044.pdf,"Complex computational models are often designed to simulate real-world physical phenomena in many scientific disciplines. However, these simulation models tend to be computationally very expensive and involve a large number of simulation input parameters, which need to be analyzed and properly calibrated before the models can be applied for real scientific studies. We propose a visual analysis system to facilitate interactive exploratory analysis of high-dimensional input parameter space for a complex yeast cell polarization simulation. The proposed system can assist the computational biologists, who designed the simulation model, to visually calibrate the input parameters by modifying the parameter values and immediately visualizing the predicted simulation outcome without having the need to run the original expensive simulation for every instance. Our proposed visual analysis system is driven by a trained neural network-based surrogate model as the backend analysis framework. In this work, we demonstrate the advantage of using neural networks as surrogate models for visual analysis by incorporating some of the recent advances in the field of uncertainty quantification, interpretability and explainability of neural network-based models. We utilize the trained network to perform interactive parameter sensitivity analysis of the original simulation as well as recommend optimal parameter configurations using the activation maximization framework of neural networks. We also facilitate detail analysis of the trained network to extract useful insights about the simulation model, learned by the network, during the training process. We performed two case studies, and discovered multiple new parameter configurations, which can trigger high cell polarization results in the original simulation model. We evaluated our results by comparing with the original simulation model outcomes as well as the findings from previous parameter analysis performed by our experts.",,,,,vimeo 360155766,10.1109/TVCG.2019.2934591,2019,2019,VAST,Ballroom A,Tuesday,A Tour of VAST,2022-10-22,,
openaccessvis2019.csv,VAST,TVCG,Supporting Analysis of Dimensionality Reduction Results with Contrastive Learning,,"Takanori Fujiwara, Oh-Hyun Kwon, Kwan-Liu Ma",https://arxiv.org/pdf/1905.03911.pdf,"Dimensionality reduction (DR) is frequently used for analyzing and visualizing high-dimensional data as it provides a good first glance of the data. However, to interpret the DR result for gaining useful insights from the data, it would take additional analysis effort such as identifying clusters and understanding their characteristics. While there are many automatic methods (e.g., density-based clustering methods) to identify clusters, effective methods for understanding a cluster?s characteristics are still lacking. A cluster can be mostly characterized by its distribution of feature values. Reviewing the original feature values is not a straightforward task when the number of features is large. To address this challenge, we present a visual analytics method that effectively highlights the essential features of a cluster in a DR result. To extract the essential features, we introduce an enhanced usage of contrastive principal component analysis (cPCA). Our method, called ccPCA (contrasting clusters in PCA), can calculate each feature?s relative contribution to the contrast between one cluster and other clusters. With ccPCA, we have created an interactive system including a scalable visualization of clusters? feature contributions. We demonstrate the effectiveness of our method and system with case studies using several publicly available datasets.",,,,,vimeo 360484919,10.1109/TVCG.2019.2934251,2019,2019,VAST,Ballroom A,Tuesday,A Tour of VAST,2022-10-22,,
openaccessvis2019.csv,VAST,TVCG,The What-If Tool: Interactive Probing of Machine Learning Models,,"James Wexler, Mahima Pushkarna, Tolga Bolukbasi, Martin Wattenberg, Fernanda Viegas, Jimbo Wilson",https://arxiv.org/pdf/1907.04135.pdf,"A key challenge in developing and deploying Machine Learning (ML) systems is understanding their performance across a wide range of inputs. To address this challenge, we created the What-If Tool, an open-source application that allows practitioners to probe, visualize, and analyze ML systems, with minimal coding. The What-If Tool lets practitioners test performance in hypothetical situations, analyze the importance of different data features, and visualize model behavior across multiple models and subsets of input data. It also lets practitioners measure systems according to multiple ML fairness metrics. We describe the design of the tool, and report on real-life usage at different organizations.",,,,,vimeo 360154686,10.1109/TVCG.2019.2934619,2019,2019,VAST,Ballroom A,Tuesday,A Tour of VAST,2022-10-22,,
openaccessvis2019.csv,VAST,TVCG,Understanding the Role of Alternatives in Data Analysis Practices,,"Jiali Liu, Nadia Boukhelifa, James Eagan",https://hal.telecom-paristech.fr/hal-02182349/document,"Data workers are people who perform data analysis activities as a part of their daily work but do not formally identify as data scientists. They come from various domains and often need to explore diverse sets of hypotheses and theories, a variety of data sources, algorithms, methods, tools, and visual designs. Taken together, we call these alternatives. To better understand and characterize the role of alternatives in their analyses, we conducted semi-structured interviews with 12 data workers with different types of expertise. We conducted four types of analyses to understand 1) why data workers explore alternatives; 2) the different notions of alternatives and how they fit into the sensemaking process; 3) the high-level processes around alternatives; and 4) their strategies to generate, explore, and manage those alternatives. We find that participants? diverse levels of domain and computational expertise, experience with different tools, and collaboration within their broader context play an important role in how they explore these alternatives. These findings call out the need for more attention towards a deeper understanding of alternatives and the need for better tools to facilitate the exploration, interpretation, and management of alternatives. Drawing upon these analyses and findings, we present a framework based on participants? 1) degree of attention, 2) abstraction level, and 3) analytic processes. We show how this framework can help understand how data workers consider such alternatives in their analyses and how tool designers might create tools to better support them.",,,,,vimeo 360155794,10.1109/TVCG.2019.2934593,2019,2019,VAST,Ballroom A,Tuesday,A Tour of VAST,2022-10-22,,
openaccessvis2019.csv,VAST,TVCG,VASABI: Doing User Behaviour Analytics through Interactive Visual Hierarchical User Profiles,,"Phong H. Nguyen, Rafael Henkin, Siming Chen, Natalia Andrienko, Gennady Andrienko, Olivier Thonnard, Cagatay Turkay",http://openaccess.city.ac.uk/id/eprint/22591/1/vasabi___VAST_2019.pdf,"User behaviour analytics (UBA) systems offer sophisticated models that capture users? behaviour over time with an aim to identify fraudulent activities that do not match their profiles. Making decisions based on such systems; however, requires an in-depth understanding of user behaviour both at an individual and at a group level where a group can consist of users with similar roles. We present a visual analytics approach to help analysts gain a comprehensive, multifaceted understanding of user behaviour at multiple levels. We take a user-centred approach to design a visual analytics framework supporting the analysis of collections of users and the numerous sessions of activities they conduct within digital applications. The framework is centred around the concept of hierarchical user profiles, where the profiles are built based on features derived from sessions they perform and visualised with task-informed designs to facilitate interactive exploration and investigation. We also present techniques to extract user tasks that summarise the behaviour and to cluster users according to these tasks to construct hierarchical user profiles. We externalise a series of analysis goals and tasks, and evaluate our methods through use cases conducted with experts. We observe that with the aid of interactive visual hierarchical user profiles, analysts were able to conduct exploratory and investigative analysis effectively, and able to understand the characteristics of user behaviour to make informed decisions whilst evaluating suspicious users and activities.",,,,,vimeo 360156177,,2019,2019,VAST,Ballroom A,Tuesday,A Tour of VAST,2022-10-22,,
openaccessvis2019.csv,InfoVis,TVCG,Criteria for Rigor in Visualization Design Study,,"Miriah Meyer, Jason Dykes",https://arxiv.org/pdf/1907.08495.pdf,"We develop a new perspective on research conducted through visualization design study that emphasizes design as a method of inquiry and the broad range of knowledge-contributions achieved through it as multiple, subjective, and socially constructed. From this interpretivist position we explore the nature of visualization design study and develop six criteria for rigor. We propose that rigor is established and judged according to the extent to which visualization design study research and its reporting are INFORMED , REFLEXIVE , ABUNDANT , PLAUSIBLE , RESONANT, and TRANSPARENT. This perspective and the criteria were constructed through a four-year engagement with the discourse around rigor and the nature of knowledge in social science, information systems, and design. We suggest methods from cognate disciplines that can support visualization researchers in meeting these criteria during the planning, execution, and reporting of design study. Through a series of deliberately provocative questions, we explore implications of this new perspective for design study research in visualization, concluding that as a discipline, visualization is not yet well positioned to embrace, nurture, and fully benefit from a rigorous, interpretivist approach to design study. The perspective and criteria we present are intended to stimulate dialogue and debate around the nature of visualization design study and the broader underpinnings of the discipline.",,,,,vimeo 361976920,,2019,2019,InfoVis,Ballroom B,Tuesday,Provocations,2022-10-22,,
openaccessvis2019.csv,InfoVis,TVCG,Data by proxy ? material traces as autographic visualizations,,Dietmar Offenhuber,https://arxiv.org/pdf/1907.05454.pdf,"Information visualization limits itself, per definition, to the domain of symbolic information. This paper discusses arguments why the field should also consider forms of data that are not symbolically encoded, including physical traces and material indicators. Continuing a provocation presented by Pat Hanrahan in his 2004 IEEE Vis capstone address, this paper compares physical traces to visualizations and describes the techniques and visual practices for producing, revealing, and interpreting them. By contrasting information visualization with a speculative counter model of autographic visualization, this paper examines the design principles for material data. Autographic visualization addresses limitations of information visualization, such as the inability to directly reflect the material circumstances of data generation. The comparison between the two models allows probing the epistemic assumptions behind information visualization and uncovers linkages with the rich history of scientific visualization and trace reading. The paper begins by discussing the gap between data visualizations and their corresponding phenomena and proceeds by investigating how material visualizations can bridge this gap. It contextualizes autographic visualization with paradigms such as data physicalization and indexical visualization and grounds it in the broader theoretical literature of semiotics, science and technology studies (STS), and the history of scientific representation. The main section of the paper proposes a foundational design vocabulary for autographic visualization and offers examples of how citizen scientists already use autographic principles in their displays, which seem to violate the canonical principles of information visualization but succeed at fulfilling other rhetorical purposes in evidence construction. The paper concludes with a discussion of the limitations of autographic visualization, a roadmap for the empirical investigation of trace perception, and thoughts about how information visualization and autographic visualization techniques can contribute to each other",,,,,vimeo 360050094,,2019,2019,InfoVis,Ballroom B,Tuesday,Provocations,2022-10-22,,
openaccessvis2019.csv,InfoVis,TVCG,Design by Immersion: A Transdisciplinary Approach to Problem-Driven Visualizations,,"Kyle Wm Hall, Adam James Bradley, Uta Hinrichs, Samuel Huron, Jo Wood, Christopher Collins, Sheelagh Carpendale",https://arxiv.org/pdf/1908.00559.pdf,"While previous work exists on how to conduct and disseminate insights from problem-driven visualization projects and design studies, the literature does not address how to accomplish these goals in transdisciplinary teams in ways that advance all disciplines involved. In this paper we introduce and define a new methodological paradigm we call design by immersion, which provides an alternative perspective on problem-driven visualization work. Design by immersion embeds transdisciplinary experiences at the center of the visualization process by having visualization researchers participate in the work of the target domain (or domain experts participate in visualization research). Based on our own combined experiences of working on cross-disciplinary, problemdriven visualization projects, we present six case studies that expose the opportunities that design by immersion enables, including (1) exploring new domain-inspired visualization design spaces, (2) enriching domain understanding through personal experiences, and (3) building strong transdisciplinary relationships. Furthermore, we illustrate how the process of design by immersion opens up a diverse set of design activities that can be combined in different ways depending on the type of collaboration, project, and goals. Finally, we discuss the challenges and potential pitfalls of design by immersion.",,,,,vimeo 360483922,,2019,2019,InfoVis,Ballroom B,Tuesday,Provocations,2022-10-22,,
openaccessvis2019.csv,InfoVis,TVCG,What is Interaction for Data Visualization?,,"Evanthia Dimara, Charles Perin",https://hal.archives-ouvertes.fr/hal-02197062/document,"Interaction is fundamental to data visualization, but what ?interaction? means in the context of visualization is ambiguous and confusing. We argue that this confusion is due to a lack of consensual definition. To tackle this problem, we start by synthesizing an inclusive view of interaction in the visualization community ? including insights from information visualization, visual analytics and scientific visualization, as well as the input of both senior and junior visualization researchers. Once this view takes shape, we look at how interaction is defined in the field of human-computer interaction (HCI). By extracting commonalities and differences between the views of interaction in visualization and in HCI, we synthesize a definition of interaction for visualization. Our definition is meant to be a thinking tool and inspire novel and bolder interaction design practices. We hope that by better understanding what interaction in visualization is and what it can be, we will enrich the quality of interaction in visualization systems and empower those who use them.",,,https://osf.io/ej7xg,,vimeo 360445743,10.1109/TVCG.2019.2934283,2019,2019,InfoVis,Ballroom B,Tuesday,Provocations,2022-10-22,,
openaccessvis2019.csv,InfoVis,TVCG,Why Authors Don't Visualize Uncertainty,,Jessica Hullman,https://arxiv.org/pdf/1908.01697.pdf,"Clear presentation of uncertainty is an exception rather than rule in media articles, data-driven reports, and consumer applications, despite proposed techniques for communicating sources of uncertainty in data. This work considers, Why do so many visualization authors choose not to visualize uncertainty? I contribute a detailed characterization of practices, associations, and attitudes related to uncertainty communication among visualization authors, derived from the results of surveying 90 authors who regularly create visualizations for others as part of their work, and interviewing thirteen influential visualization designers. My results highlight challenges that authors face and expose assumptions and inconsistencies in beliefs about the role of uncertainty in visualization. In particular, a clear contradiction arises between authors? acknowledgment of the value of depicting uncertainty and the norm of omitting direct depiction of uncertainty. To help explain this contradiction, I present a rhetorical model of uncertainty omission in visualization-based communication. I also adapt a formal statistical model of how viewers judge the strength of a signal in a visualization to visualization-based communication, to argue that uncertainty communication necessarily reduces degrees of freedom in viewers? statistical inferences. I conclude with recommendations for how visualization research on uncertainty communication could better serve practitioners? current needs and values while deepening understanding of assumptions that reinforce uncertainty omission.",,,,,vimeo 360050405,10.1109/TVCG.2019.2934287,2019,2019,InfoVis,Ballroom B,Tuesday,Provocations,2022-10-22,,
openaccessvis2019.csv,SciVis,TVCG,High-throughput feature extraction for measuring attributes of deforming open cell foams,,"Steve Petruzza, Attila Gyulassy, Samuel Leventhal, Jackson Baglino, Michael Czabaj, Ashely Spears, Valerio Pascucci",,,,,,,vimeo 359999616,,2019,2019,SciVis,Ballroom C,Tuesday,Scalar Topology,2022-10-22,,
openaccessvis2019.csv,SciVis,TVCG,Progressive Wasserstein Barycenters of Persistence Diagrams,,"Jules Vidal, Joseph Budin, Julien Tierny",https://arxiv.org/pdf/1907.04565.pdf,"This paper presents an efficient algorithm for the progressive approximation of Wasserstein barycenters of persistence diagrams, with applications to the visual analysis of ensemble data. Given a set of scalar fields, our approach enables the computation of a persistence diagram which is representative of the set, and which visually conveys the number, data ranges and saliences of the main features of interest found in the set. Such representative diagrams are obtained by computing explicitly the discrete Wasserstein barycenter of the set of persistence diagrams, a notoriously computationally intensive task. In particular, we revisit efficient algorithms for Wasserstein distance approximation [12,51] to extend previous work on barycenter estimation [94]. We present a new fast algorithm, which progressively approximates the barycenter by iteratively increasing the computation accuracy as well as the number of persistent features in the output diagram. Such a progressivity drastically improves convergence in practice and allows to design an interruptible algorithm, capable of respecting computation time constraints. This enables the approximation of Wasserstein barycenters within interactive times. We present an application to ensemble clustering where we revisit the k-means algorithm to exploit our barycenters and compute, within execution time constraints, meaningful clusters of ensemble data along with their barycenter diagram. Extensive experiments on synthetic and real-life data sets report that our algorithm converges to barycenters that are qualitatively meaningful with regard to the applications, and quantitatively comparable to previous techniques, while offering an order of magnitude speedup when run until convergence (without time constraint). Our algorithm can be trivially parallelized to provide additional speedups in practice on standard workstations. We provide a lightweight C++ implementation of our approach that can be used to reproduce our results",,,,,vimeo 360007493,10.1109/TVCG.2019.2934256,2019,2019,SciVis,Ballroom C,Tuesday,Scalar Topology,2022-10-22,,
openaccessvis2019.csv,SciVis,TVCG,The Effect of Data Transformations on Scalar Field Topological Analysis of High-Order FEM Solutions,,"Ashok Jallepalli, Joshua A. Levine, Mike Kirby",https://arxiv.org/pdf/1907.07224.pdf,"High-order finite element methods (HO-FEM) are gaining popularity in the simulation community due to their success in solving complex flow dynamics. There is an increasing need to analyze the data produced as output by these simulations. Simultaneously, topological analysis tools are emerging as powerful methods for investigating simulation data. However, most of the current approaches to topological analysis have had limited application to HO-FEM simulation data for two reasons. First, the current topological tools are designed for linear data (polynomial degree one), but the polynomial degree of the data output by these simulations is typically higher (routinely up to polynomial degree six). Second, the simulation data and derived quantities of the simulation data have discontinuities at element boundaries, and these discontinuities do not match the input requirements for the topological tools. One solution to both issues is to transform the high-order data to achieve low-order, continuous inputs for topological analysis. Nevertheless, there has been little work evaluating the possible transformation choices and their downstream effect on the topological analysis. We perform an empirical study to evaluate two commonly used data transformation methodologies along with the recently introduced L-SIAC filter for processing high-order simulation data. Our results show diverse behaviors are possible. We offer some guidance about how best to consider a pipeline of topological analysis of HO-FEM simulations with the currently available implementations of topological analysis.",,,,,vimeo 359999206,10.1109/TVCG.2019.2934338,2019,2019,SciVis,Ballroom C,Tuesday,Scalar Topology,2022-10-22,,
openaccessvis2019.csv,SciVis,TVCG,Toward Localized Topological Data Structures: Querying the Forest for the Tree,,"Pavol Klacansky, Attila Gyulassy, Peer-Timo Bremer, Valerio Pascucci",,,,,,,vimeo 359998742,10.1109/TVCG.2019.2934257,2019,2019,SciVis,Ballroom C,Tuesday,Scalar Topology,2022-10-22,,
openaccessvis2019.csv,TVCG,TVCG,Edit Distance between Merge Trees,,"Raghavendra Sridharamurthy, Talha Bin Masood, Adhitya Kamakshidasan, Vijay Natarajan",,,,,,,vimeo 364568965,10.1109/TVCG.2018.2873612,,2019,SciVis,Ballroom C,Tuesday,Scalar Topology,2022-10-22,,
openaccessvis2019.csv,InfoVis,TVCG,Construct-A-Vis: Free-Form Visualization Creation for Children,,"Fearn Bishop, Johannes Zagermann, Ulrike Pfeil, Gemma Sanderson, Harald Reiterer, Uta Hinrichs",https://research-repository.st-andrews.ac.uk/bitstream/handle/10023/18228/Construct_A_Vis_InfoVis_2019.pdf,"Building data analysis skills is part of modern elementary school curricula. Recent research has explored how to facilitate children's understanding of visual data representations through completion exercises which highlight links between concrete and abstract mappings. This approach scaffolds visualization activities by presenting a target visualization to children. But how can we engage children in more free-form visual data mapping exercises that are driven by their own mapping ideas? How can we scaffold a creative exploration of visualization techniques and mapping possibilities? We present Construct-A-Vis, a tablet-based tool designed to explore the feasibility of free-form and constructive visualization activities with elementary school children. Construct-A-Vis provides adjustable levels of scaffolding visual mapping processes. It can be used by children individually or as part of collaborative activities. Findings from a study with elementary school children using Construct-A-Vis individually and in pairs highlight the potential of this free-form constructive approach, as visible in children's diverse visualization outcomes and their critical engagement with the data and mapping processes. Based on our study ndings we contribute insights into the design of free-form visualization tools for children, including the role of tool-based scaffolding mechanisms and shared interactions to guide visualization activities with children.",,,,,vimeo 360050203,,2019,2019,InfoVis,Ballroom A,Wednesday,(De)Construction,2022-10-23,,
openaccessvis2019.csv,InfoVis,TVCG,Critical Reflections of Visualization Authoring Systems,,"Arvind Satyanarayan, Bongshin Lee, Donghao Ren, Jeffrey Heer, John Stasko, John R Thompson, Matthew Brehmer, Zhicheng Liu",https://arxiv.org/pdf/1907.13568.pdf,"An emerging generation of visualization authoring systems support expressive information visualization without textual programming. As they vary in their visualization models, system architectures, and user interfaces, it is challenging to directly compare these systems using traditional evaluative methods. Recognizing the value of contextualizing our decisions in the broader design space, we present critical reflections on three systems we developed? Lyra, Data Illustrator, and Charticulator. This paper surfaces knowledge that would have been daunting within the constituent papers of these three systems. We compare and contrast their (previously unmentioned) limitations and trade-offs between expressivity and learnability. We also reflect on common assumptions that we made during the development of our systems, thereby informing future research directions in visualization authoring systems.",,,,,,,2019,2019,InfoVis,Ballroom A,Wednesday,(De)Construction,2022-10-23,,
openaccessvis2019.csv,InfoVis,TVCG,Decoding Complex Visualizations in Science Museums ? An Empirical Study,,"Joyce Ma, Kwan-Liu Ma, Jennifer Frazier",https://arxiv.org/pdf/1907.13193.pdf,"This study describes a detailed analysis of museum visitors? decoding process as they used a visualization designed to support exploration of a large, complex dataset. Quantitative and qualitative analyses revealed that it took, on average, 43 seconds for visitors to decode enough of the visualization to see patterns and relationships in the underlying data represented, and 54 seconds to arrive at their first correct data interpretation. Furthermore, visitors decoded throughout and not only upon initial use of the visualization. The study analyzed think-aloud data to identify issues visitors had mapping the visual representations to their intended referents, examine why they occurred, and consider if and how these decoding issues were resolved. The paper also describes how multiple visual encodings both helped and hindered decoding and concludes with implications on the design and adaptation of visualizations for informal science learning venues.",,,,,,,2019,2019,InfoVis,Ballroom A,Wednesday,(De)Construction,2022-10-23,,
openaccessvis2019.csv,InfoVis,TVCG,Investigating Direct Manipulation of Graphical Encodings as a Method for User Interaction,,"Bahador Saket, Samuel Huron, Charles Perin, Alex Endert",https://arxiv.org/pdf/1908.00679.pdf,"We investigate direct manipulation of graphical encodings as a method for interacting with visualizations. There is an increasing interest in developing visualization tools that enable users to perform operations by directly manipulating graphical encodings rather than external widgets such as checkboxes and sliders. Designers of such tools must decide which direct manipulation operations should be supported, and identify how each operation can be invoked. However, we lack empirical guidelines for how people convey their intended operations using direct manipulation of graphical encodings. We address this issue by conducting a qualitative study that examines how participants perform 15 operations using direct manipulation of standard graphical encodings. From this study, we 1) identify a list of strategies people employ to perform each operation, 2) observe commonalities in strategies across operations, and 3) derive implications to help designers leverage direct manipulation of graphical encoding as a method for user interaction.",,,,,vimeo 360445782,,2019,2019,InfoVis,Ballroom A,Wednesday,(De)Construction,2022-10-23,,
openaccessvis2019.csv,SciVis,TVCG,Artifact-Based Rendering: Harnessing Natural and Traditional Visual Media for More Expressive and Engaging 3D Visualizations,,"Seth A Johnson, Francesca Samsel, Greg Abram, Daniel Olson, Andrew Solis, Bridger Herman, Philip Wolfram, Christophe Langlet, Daniel F. Keefe",https://arxiv.org/pdf/1907.13178.pdf,"We introduce Artifact-Based Rendering (ABR), a framework of tools, algorithms, and processes that makes it possible to produce real, data-driven 3D scientific visualizations with a visual language derived entirely from colors, lines, textures, and forms created using traditional physical media or found in nature. A theory and process for ABR is presented to address three current needs: (i) designing better visualizations by making it possible for non-programmers to rapidly design and critique many alternative data-to-visual mappings; (ii) expanding the visual vocabulary used in scientific visualizations to depict increasingly complex multivariate data; (iii) bringing a more engaging, natural, and human-relatable handcrafted aesthetic to data visualization. New tools and algorithms to support ABR include front-end applets for constructing artifact-based colormaps, optimizing 3D scanned meshes for use in data visualization, and synthesizing textures from artifacts. These are complemented by an interactive rendering engine with custom algorithms and interfaces that demonstrate multiple new visual styles for depicting point, line, surface, and volume data. A within-the-research-team design study provides early evidence of the shift in visualization design processes that ABR is believed to enable when compared to traditional scientific visualization systems. Qualitative user feedback on applications to climate science and brain imaging support the utility of ABR for scientific discovery and public communication.",,,,,vimeo 359998878,10.1109/TVCG.2019.2934260,2019,2019,SciVis,Ballroom A,Wednesday,(De)Construction,2022-10-23,,
openaccessvis2019.csv,VAST,VAST,Origraph: Interactive Network Wrangling,,"Alex Bigelow, Carolina Nobre, Miriah Meyer, Alexander Lex",https://arxiv.org/pdf/1812.06337.pdf,"Networks are a natural way of thinking about many datasets. The data on which a network is based, however, is rarely collected in a form that suits the analysis process, making it necessary to create and reshape networks. Data wrangling is widely acknowledged to be a critical part of the data analysis pipeline, yet interactive network wrangling has received little attention in the visualization research community. In this paper, we discuss a set of operations that are important for wrangling network datasets and introduce a visual data wrangling tool, Origraph, that enables analysts to apply these operations to their datasets. Key operations include creating a network from source data such as tables, reshaping a network by introducing new node or edge classes, filtering nodes or edges, and deriving new node or edge attributes. Our tool, Origraph, enables analysts to execute these operations with little to no programming, and to immediately visualize the results. Origraph provides views to investigate the network model, a sample of the network, and node and edge attributes. In addition, we introduce interfaces designed to aid analysts in specifying arguments for sensible network wrangling operations. We demonstrate the usefulness of Origraph in two Use Cases: first, we investigate gender bias in the film industry, and then the influence of money on the political support for the war in Yemen.",https://origraph.github.io/,,,,vimeo 360154783,,2019,2019,VAST,Ballroom A,Wednesday,(De)Construction,2022-10-23,,
openaccessvis2019.csv,InfoVis,TVCG,A Comparative Evaluation of Animation and Small Multiples for Trend Visualization on Mobile Phones,,"Matthew Brehmer, Bongshin Lee, Petra Isenberg, Eun Kyoung Choe",https://arxiv.org/pdf/1907.03919.pdf,"We compare the efficacy of animated and small multiples variants of scatterplots on mobile phones for comparing trends in multivariate datasets. Visualization is increasingly prevalent in mobile applications and mobile-first websites, yet there is little prior visualization research dedicated to small displays. In this paper, we build upon previous experimental research carried out on larger displays that assessed animated and non-animated variants of scatterplots. Incorporating similar experimental stimuli and tasks, we conducted an experiment where 96 crowdworker participants performed nine trend comparison tasks using their mobile phones. We found that those using a small multiples design consistently completed tasks in less time, albeit with slightly less confidence than those using an animated design. The accuracy results were more task-dependent, and we further interpret our results according to the characteristics of the individual tasks, with a specific focus on the trajectories of target and distractor data items in each task. We identify cases that appear to favor either animation or small multiples, providing new questions for further experimental research and implications for visualization design on mobile devices. Lastly, we provide a reflection on our evaluation methodology",,,https://github.com/microsoft/MobileTrendVis/tree/master/data_analysis/1217_data,,vimeo 360049784,10.1109/TVCG.2019.2934397,2019,2019,InfoVis,Ballroom B,Wednesday,Animation and Sports,2022-10-23,,
openaccessvis2019.csv,InfoVis,TVCG,A Comparison of Visualizations for Identifying Correlation Over Time and Space,,"Vanessa Pe¤a-Araya, Emmanuel Pietriga, Anastasia Bezerianos",https://arxiv.org/pdf/1907.06399.pdf,"Observing the relationship between two or more variables over space and time is essential in many domains. For instance, looking, for different countries, at the evolution of both the life expectancy at birth and the fertility rate will give an overview of their demographics. The choice of visual representation for such multivariate data is key to enabling analysts to extract patterns and trends. Prior work has compared geo-temporal visualization techniques for a single thematic variable that evolves over space and time, or for two variables at a specific point in time. But how effective visualization techniques are at communicating correlation between two variables that evolve over space and time remains to be investigated. We report on a study comparing three techniques that are representative of different strategies to visualize geo-temporal multivariate data: either juxtaposing all locations for a given time step, or juxtaposing all time steps for a given location; and encoding thematic attributes either using symbols overlaid on top of map features, or using visual channels of the map features themselves. Participants performed a series of tasks that required them to identify if two variables were correlated over time and if there was a pattern in their evolution. Tasks varied in granularity for both dimensions: time (all time steps, a subrange of steps, one step only) and space (all locations, locations in a subregion, one location only). Our results show that a visualization?s effectiveness depends strongly on the task to be carried out. Based on these findings we present a set of design guidelines about geo-temporal visualization techniques for communicating correlation.",,,http://ilda.saclay.inria.fr/spacetimecorr/experiment/,,vimeo 360050071,,2019,2019,InfoVis,Ballroom B,Wednesday,Animation and Sports,2022-10-23,,
openaccessvis2019.csv,InfoVis,TVCG,Common Fate for Animated Transitions in Visualization,,"Amira Chalbi, Jacob Ritchie, Deokgun Park, Jungu Choi, Nicolas Roussel, Niklas Elmqvist, Fanny Chevalier",https://osf.io/zsv9t/,"The Law of Common Fate from Gestalt psychology states that visual objects moving with the same velocity along paralleltrajectories will be perceived by a human observer as grouped.  However, the concept ofcommon fateis much broader than merevelocity; in this paper we explore how common fate results from coordinated changes in luminance and size. We present results froma crowdsourced graphical perception study where we asked workers to make perceptual judgments on a series of trials involving fourgraphical objects under the influence of conflicting static and dynamic visual factors (position, size and luminance) used in conjunction.Our results yield the following rankings for visual grouping: motion>(dynamic luminance, size, luminance); dynamic size>(dynamicluminance, position); and dynamic luminance>size. We also conducted a follow-up experiment to evaluate the three dynamic visualfactors in a more ecologically valid setting, using both a Gapminder-like animated scatterplot and a thematic map of election data.The results indicate that in practice the relative grouping strengths of these factors may depend on various parameters including thevisualization characteristics and the underlying data. We discuss design implications for animated transitions in data visualization.",,,https://osf.io/3zkhv/,,vimeo 360484281,10.1109/TVCG.2019.2934288,2019,2019,InfoVis,Ballroom B,Wednesday,Animation and Sports,2022-10-23,,
openaccessvis2019.csv,VAST,TVCG,CourtTime: Generating Actionable Insights into Tennis Matches Using Visual Analytics,,"Thomas E. Polk, Dominik J„ckle, Johannes H„uáler, Jing Yang",https://kops.uni-konstanz.de/bitstream/handle/123456789/46446/CourtTime__Generating_Actionable_Insights_into_Amateur_Tennis_Matches_Using_Visual_Analytics%20%28with%20acknowledgements%29.pdf?sequence=1&isAllowed=y,"Tennis players and coaches of all proficiency levels seek to understand and improve their play. Summary statistics alone are inadequate to provide the insights players need to improve their games. Spatio-temporal data capturing player and ball movements is likely to provide the actionable insights needed to identify player strengths, weaknesses, and strategies. To fully utilize this spatio-temporal data, we need to integrate it with domain-relevant context meta-data. In this paper, we propose CourtTime, a novel approach to perform data-driven visual analysis of individual tennis matches. Our visual approach introduces a novel visual metaphor, namely 1-D Space-Time Charts that enable the analysis of single points at a glance based on small multiples. We also employ user-driven sorting and clustering techniques and a layout technique that aligns the last few shots in a point to facilitate shot pattern discovery. We discuss the usefulness of CourtTime via an extensive case study and report on feedback from an amateur tennis player and three tennis coaches.",,,,,vimeo 360155110,10.1109/TVCG.2019.2934243,2019,2019,VAST,Ballroom B,Wednesday,Animation and Sports,2022-10-23,,
openaccessvis2019.csv,VAST,TVCG,Tac-Simur: Visual Analytics for Tactic-based Match Simulation of Table Tennis,,"Jiachen Wang, Kejian Zhao, Dazhen Deng, Anqi Cao, Xiao Xie, Zheng Zhou, Hui Zhang, Yingcai Wu",,,,,,,vimeo 360154177,,2019,2019,VAST,Ballroom B,Wednesday,Animation and Sports,2022-10-23,,
openaccessvis2019.csv,TVCG,TVCG,COPE: Interactive Exploration of Co-occurrence Patterns in Spatial Time Series,,"Jie Li, Siming Chen, Kang Zhang, Gennady Andrienko, Natalia Andrienko",http://openaccess.city.ac.uk/id/eprint/20131/1/V1.63%20minor%20review-final.pdf,"Spatial time series is a common type of data dealt with in many domains, such as economic statistics and environmental science. There have been many studies focusing on finding and analyzing various kinds of events in time series; the term ?event? refers to significant changes or occurrences of particular patterns formed by consecutive attribute values. We focus on a further step in event analysis: discover temporal relationship patterns between event locations, i.e., repeated cases when there is a specific temporal relationship (same time, before, or after) between events occurring at two locations. This can provide important clues for understanding the formation and spreading mechanisms of events and interdependencies among spatial locations. We propose a visual exploration framework COPE (Co-Occurrence Pattern Exploration), which allows users to extract events of interest from data and detect various co-occurrence patterns among them. Case studies and expert reviews were conducted to verify the effectiveness and scalability of COPE using two real-world datasets.",,,,,vimeo 364567978,,,2019,VAST,Ballroom B,Wednesday,Animation and Sports,2022-10-23,,
openaccessvis2019.csv,InfoVis,TVCG,"Biased Average Position Estimates in Line and Bar Graphs: Underestimation, Overestimation, and Perceptual Pull",,"Cindy Xiong, Cristina R Ceja, Casimir Ludwig, Steven Franconeri",https://arxiv.org/pdf/1908.00073.pdf,"In visual depictions of data, position (i.e., the vertical height of a line or a bar) is believed to be the most precise way to encode information compared to other encodings (e.g., hue). Not only are other encodings less precise than position, but they can also be prone to systematic biases (e.g., color category boundaries can distort perceived differences between hues). By comparison, position?s high level of precision may seem to protect it from such biases. In contrast, across three empirical studies, we show that while position may be a precise form of data encoding, it can also produce systematic biases in how values are visually encoded, at least for reports of average position across a short delay. In displays with a single line or a single set of bars, reports of average positions were significantly biased, such that line positions were underestimated and bar positions were overestimated. In displays with multiple data series (i.e., multiple lines and/or sets of bars), this systematic bias still persisted. We also observed an effect of ?perceptual pull?, where the average position estimate for each series was ?pulled? toward the other. These findings suggest that, although position may still be the most precise form of visual data encoding, it can also be systematically biased.",,,,,vimeo 360049835,10.1109/TVCG.2019.2934400,2019,2019,InfoVis,Ballroom C,Tuesday,Bias & Patterns,2022-10-22,,
openaccessvis2019.csv,InfoVis,TVCG,Measures of the benefit of direct encoding of data deltas for data pair relation perception,,"Christine Nothelfer, Steven Franconeri",https://osf.io/jup9a,"The power of data visualization is not to convey absolute values of individual data points, but to allow the exploration of relations (increases or decreases in a data value) among them. One approach to highlighting these relations is to explicitly encode the numeric differences (deltas) between data values. Because this approach removes the context of the individual data values, it is important to measure how much of a performance improvement it actually offers, especially across differences in encodings and tasks, to ensure that it is worth adding to a visualization design. Across 3 different tasks, we measured the increase in visual processing efficiency for judging the relations between pairs of data values, from when only the values were shown, to when the deltas between the values were explicitly encoded, across position and length visual feature encodings (and slope encodings in Experiments 1 & 2). In Experiment 1, the participant?s task was to locate a pair of data values with a given relation (e.g., Find the ?small bar to the left of a tall bar? pair) among pairs of the opposite relation, and we measured processing efficiency from the increase in response times as the number of pairs increased. In Experiment 2, the task was to judge which of two relation types was more prevalent in a briefly presented display of 10 data pairs (e.g., Are there more ?small bar to the left of a tall bar? pairs or more ?tall bar to the left of a small bar? pairs?). In the final experiment, the task was to estimate the average delta within a briefly presented display of 6 data pairs (e.g., What is the average bar height difference across all ?small bar to the left of a tall bar? pairs?). Across all three experiments, visual processing of relations between data value pairs was significantly better when directly encoded as deltas rather than implicitly between individual data points, and varied substantially depending on the task (improvement ranged from 25% to 95%). Considering the ubiquity of bar charts and dot plots, relation perception for individual data values is highly inefficient, and confirms the need for alternative designs that provide not only absolute values, but also direct encoding of critical relationships between those values.",,,,,vimeo 360049981,,2019,2019,InfoVis,Ballroom C,Tuesday,Bias & Patterns,2022-10-22,,
openaccessvis2019.csv,TVCG,TVCG,A Task-based Taxonomy of Cognitive Biases for Information Visualization,,"Evanthia Dimara, Steven Franconeri, Catherine Plaisant, Anastasia Bezerianos, Pierre Dragicevic",https://hal.sorbonne-universite.fr/hal-01868738v2/document,"Information visualization designers strive to design data displays that allow for efficient exploration, analysis, and communication of patterns in data, leading to informed decisions. Unfortunately, human judgment and decision making are imperfect and often plagued by cognitive biases. There is limited empirical research documenting how these biases affect visual data analysis activities. Existing taxonomies are organized by cognitive theories that are hard to associate with visualization tasks. Based on a survey of the literature we propose a task-based taxonomy of 154 cognitive biases organized in 7 main categories. We hope the taxonomy will help visualization researchers relate their design to the corresponding possible biases, and lead to new research that detects and addresses biased judgment and decision making in data visualization.",,,,,vimeo 364568413,10.1109/TVCG.2018.2872577,,2019,InfoVis,Ballroom C,Tuesday,Bias & Patterns,2022-10-22,,
openaccessvis2019.csv,TVCG,TVCG,The Curse of Knowledge in Visual Data Communication,,"Cindy Xiong, Lisanne van Weelden, Steven Franconeri",https://osf.io/xc7e8,"A viewer can extract many potential patterns from any set of visualized data values. But that means that two people can see different patterns in the same visualization, potentially leading to miscommunication. Here, we show that when people are primed to see one pattern in the data as visually salient, they believe that na‹ve viewers will experience the same visual salience. Participants were told one of multiple backstories about political events that affected public polling data, before viewing a graph that depicted those data. One pattern in the data was particularly visually salient to them given the backstory that they heard. They then predicted what na‹ve viewers would most visually salient on the visualization. They were strongly influenced by their own knowledge, despite explicit instructions to ignore it, predicting that others would find the same patterns to be most visually salient. This result reflects a psychological phenomenon known as the curse of knowledge, where an expert struggles to re-create the state of mind of a novice. The present findings show that the curse of knowledge also plagues the visual perception of data, explaining why people can fail to connect with audiences when they communicate patterns in data.",,,http://visualthinking.psych.northwestern.edu/VisualizationCurse2018/Results/,,vimeo 364568644,10.1109/TVCG.2019.2917689,,2019,InfoVis,Ballroom C,Tuesday,Bias & Patterns,2022-10-22,,
openaccessvis2019.csv,VAST,TVCG,Evaluating Perceptual Bias During Geometric Scaling of Scatterplots,,"Yating Wei, Honghui Mei, Ying Zhao, Shuyue Zhou, Bingru Lin, Haojin Jiang, Wei Chen",https://arxiv.org/pdf/1908.00403.pdf,"Scatterplots are frequently scaled to fit display areas in multi-view and multi-device data analysis environments. A common method used for scaling is to enlarge or shrink the entire scatterplot together with the inside points synchronously and proportionally. This process is called geometric scaling. However, geometric scaling of scatterplots may cause a perceptual bias, that is, the perceived and physical values of visual features may be dissociated with respect to geometric scaling. For example, if a scatterplot is projected from a laptop to a large projector screen, then observers may feel that the scatterplot shown on the projector has fewer points than that viewed on the laptop. This paper presents an evaluation study on the perceptual bias of visual features in scatterplots caused by geometric scaling. The study focuses on three fundamental visual features (i.e., numerosity, correlation, and cluster separation) and three hypotheses that are formulated on the basis of our experience. We carefully design three controlled experiments by using well-prepared synthetic data and recruit participants to complete the experiments on the basis of their subjective experience. With a detailed analysis of the experimental results, we obtain a set of instructive findings. First, geometric scaling causes a bias that has a linear relationship with the scale ratio. Second, no significant difference exists between the biases measured from normally and uniformly distributed scatterplots. Third, changing the point radius can correct the bias to a certain extent. These findings can be used to inspire the design decisions of scatterplots in various scenarios.",,,,,vimeo 360154646,10.1109/TVCG.2019.2934208,2019,2019,VAST,Ballroom C,Tuesday,Bias & Patterns,2022-10-22,,
openaccessvis2019.csv,VAST,VAST,FDive: Learning Relevance Models using Pattern-based Similarity Measures,,"Frederik L. Dennig, Thomas E. Polk, Zudi Lin, Tobias Schreck, Hanspeter Pfister, Michael Behrisch",https://arxiv.org/pdf/1907.12489.pdf,"The detection of interesting patterns in large high-dimensional datasets is difficult because of their dimensionality and pattern complexity. Therefore, analysts require automated support for the extraction of relevant patterns. In this paper, we present FDIVE, a visual active learning system that helps to create visually explorable relevance models, assisted by learning a pattern-based similarity. We use a small set of user-provided labels to rank similarity measures, consisting of feature descriptor and distance function combinations, by their ability to distinguish relevant from irrelevant data. Based on the best-ranked similarity measure, the system calculates an interactive Self-Organizing Map-based relevance model, which classifies data according to the cluster affiliation. It also automatically prompts further relevance feedback to improve its accuracy. Uncertain areas, especially near the decision boundaries, are highlighted and can be refined by the user. We evaluate our approach by comparison to state-of-the-art feature selection techniques and demonstrate the usefulness of our approach by a case study classifying electron microscopy images of brain cells. The results show that FDIVE enhances both the quality and understanding of relevance models and can thus lead to new insights for brain research.",,,,,vimeo 360155013,,2019,2019,VAST,Ballroom C,Tuesday,Bias & Patterns,2022-10-22,,
openaccessvis2019.csv,InfoVis,TVCG,Color Crafting: Automating the Construction of Designer Quality Color Ramps,,"Stephen Smart, Keke Wu, Danielle Albers Szafir",https://arxiv.org/pdf/1908.00629.pdf,"Visualizations often encode numeric data using sequential and diverging color ramps. Effective ramps use colors that are sufficiently discriminable, align well with the data, and are aesthetically pleasing. Designers rely on years of experience to create high-quality color ramps. However, it is challenging for novice visualization developers that lack this experience to craft effective ramps as most guidelines for constructing ramps are loosely defined qualitative heuristics that are often difficult to apply. Our goal is to enable visualization developers to readily create effective color encodings using a single seed color. We do this using an algorithmic approach that models designer practices by analyzing patterns in the structure of designer-crafted color ramps. We construct these models from a corpus of 222 expert-designed color ramps, and use the results to automatically generate ramps that mimic designer practices. We evaluate our approach through an empirical study comparing the outputs of our approach with designer-crafted color ramps. Our models produce ramps that support accurate and aesthetically pleasing visualizations at least as well as designer ramps and that outperform conventional mathematical approaches.",,,https://osf.io/b5wjc/,,vimeo 360050339,10.1109/TVCG.2019.2934284,2019,2019,InfoVis,Ballroom B,Friday,Color,2022-10-25,,
openaccessvis2019.csv,InfoVis,TVCG,Estimating color-concept associations from image statistics,,"Ragini Rathore, Zachary Leggon, Laurent Lessard, Karen Schloss",https://arxiv.org/pdf/1908.00220.pdf,"To interpret the meanings of colors in visualizations of categorical information, people must determine how distinct colors correspond to different concepts. This process is easier when assignments between colors and concepts in visualizations match people?s expectations, making color palettes semantically interpretable. Efforts have been underway to optimize color palette design for semantic interpretablity, but this requires having good estimates of human color-concept associations. Obtaining these data from humans is costly, which motivates the need for automated methods. We developed and evaluated a new method for automatically estimating color-concept associations in a way that strongly correlates with human ratings. Building on prior studies using Google Images, our approach operates directly on Google Image search results without the need for humans in the loop. Specifically, we evaluated several methods for extracting raw pixel content of the images in order to best estimate color-concept associations obtained from human ratings. The most effective method extracted colors using a combination of cylindrical sectors and color categories in color space. We demonstrate that our approach can accurately estimate average human color-concept associations for different fruits using only a small set of images. The approach also generalizes moderately well to more complicated recycling-related concepts of objects that can appear in any color.",,,,,vimeo 360050505,,2019,2019,InfoVis,Ballroom B,Friday,Color,2022-10-25,,
openaccessvis2019.csv,TVCG,TVCG,The Effect of Color Scales on Climate Scientists? Objective and Subjective Performance in Spatial Data Analysis Tasks,,"Aritra Dasgupta, Jorge Poco, Bernice Rogowitz, Kyungsik Han, Enrico Bertini, Claudio T. Silva",,,,,,,vimeo 364568438,,,2019,InfoVis,Ballroom B,Friday,Color,2022-10-25,,
openaccessvis2019.csv,TVCG,TVCG,Measuring and Modeling the Feature Detection Threshold Functions of Colormaps,,"Colin Ware, Terece L. Turton, Roxana Bujack, Francesca Samsel, Piyush Shrivastava, David H. Rogers",,,,,,,vimeo 364569128,,,2019,SciVis,Ballroom B,Friday,Color,2022-10-25,,
openaccessvis2019.csv,TVCG,TVCG,Measuring the Effects of Scalar and Spherical Colormaps on Ensembles of DMRI Tubes,,"Jian Chen, Guohao Zhang, Wesley Chiou, David H. Laidlaw, Alexander P. Auchus",https://arxiv.org/pdf/1810.07882.pdf,"We report empirical study results on the color encoding of ensemble scalar and orientation to visualize diffusion magnetic resonance imaging (DMRI) tubes. The experiment tested six scalar colormaps for average fractional anisotropy (FA) tasks (grayscale, blackbody, diverging, isoluminant-rainbow, extended-blackbody, and coolwarm) and four three-dimensional (3D) directional encodings for tract tracing tasks (uniform gray, absolute, eigenmap, and Boy?s surface embedding). We found that extended-blackbody, coolwarm, and blackbody remain the best three approaches for identifying ensemble average in 3D. Isoluminant-rainbow coloring led to the same ensemble mean accuracy as other colormaps. However, more than 50% of the answers consistently had higher estimates of the ensemble average, independent of the mean values. Hue, not luminance, influences ensemble estimates of mean values. For ensemble orientation-tracing tasks, we found that the Boy?s surface embedding (greatest spatial resolution and contrast) and absolute color (lowest spatial resolution and contrast) schemes led to more accurate answers than the eigenmaps scheme (medium resolution and contrast), acting as the uncanny-valley phenomenon of visualization design in terms of accuracy",,,,,vimeo 365399042,10.1109/TVCG.2019.2898438,,2019,SciVis,Ballroom B,Friday,Color,2022-10-25,,
openaccessvis2019.csv,InfoVis,TVCG,A Deep Generative Model for Graph Layout,,"Oh-Hyun Kwon, Kwan-Liu Ma",https://arxiv.org/pdf/1904.12225.pdf,"Different layouts can characterize different aspects of the same graph. Finding a ?good? layout of a graph is thus an important task for graph visualization. In practice, users often visualize a graph in multiple layouts by using different methods and varying parameter settings until they find a layout that best suits the purpose of the visualization. However, this trial-and-error process is often haphazard and time-consuming. To provide users with an intuitive way to navigate the layout design space, we present a technique to systematically visualize a graph in diverse layouts using deep generative models. We design an encoder-decoder architecture to learn a model from a collection of example layouts, where the encoder represents training examples in a latent space and the decoder produces layouts from the latent space. In particular, we train the model to construct a two-dimensional latent space for users to easily explore and generate various layouts. We demonstrate our approach through quantitative and qualitative evaluations of the generated layouts. The results of our evaluations show that our model is capable of learning and generalizing abstract concepts of graph layouts, not just memorizing the training examples. In summary, this paper presents a fundamentally new approach to graph visualization where a machine learning model learns to visualize a graph from examples without manually-defined heuristics.",http://kwonoh.net/dgl/,,,,vimeo 360049688,10.1109/TVCG.2019.2934396,2019,2019,InfoVis,Ballroom B,Wednesday,Drawing Nodes and Edges,2022-10-23,,
openaccessvis2019.csv,InfoVis,TVCG,DeepDrawing: A Deep Learning Approach to Graph Drawing,,"Yong Wang, Zhihua Jin, Qianwen Wang, Weiwei Cui, Tengfei Ma, Huamin Qu",https://arxiv.org/pdf/1907.11040.pdf,"Node-link diagrams are widely used to facilitate network explorations. However, when using a graph drawing technique to visualize networks, users often need to tune different algorithm-specific parameters iteratively by comparing the corresponding drawing results in order to achieve a desired visual effect. This trial and error process is often tedious and time-consuming, especially for non-expert users. Inspired by the powerful data modelling and prediction capabilities of deep learning techniques, we explore the possibility of applying deep learning techniques to graph drawing. Specifically, we propose using a graph-LSTM-based approach to directly map network structures to graph drawings. Given a set of layout examples as the training dataset, we train the proposed graph-LSTM-based model to capture their layout characteristics. Then, the trained model is used to generate graph drawings in a similar style for new networks. We evaluated the proposed approach on two special types of layouts (i.e., grid layouts and star layouts) and two general types of layouts (i.e., ForceAtlas2 and PivotMDS) in both qualitative and quantitative ways. The results provide support for the effectiveness of our approach. We also conducted a time cost assessment on the drawings of small graphs with 20 to 50 nodes. We further report the lessons we learned and discuss the limitations and future work.",,,,,vimeo 360049919,10.1109/TVCG.2019.2934798,2019,2019,InfoVis,Ballroom B,Wednesday,Drawing Nodes and Edges,2022-10-23,,
openaccessvis2019.csv,InfoVis,TVCG,Interactive Structure-aware Blending of Diverse Edge Bundling Visualizations,,"Yunhai Wang, Mingliang Xue, Yanyan Wang, Xinyuan Yan, Baoquan Chen, Chi-Wing Fu, Christophe Hurter",,,,,,,vimeo 360050223,10.1109/TVCG.2019.2934805,2019,2019,InfoVis,Ballroom B,Wednesday,Drawing Nodes and Edges,2022-10-23,,
openaccessvis2019.csv,InfoVis,TVCG,Persistent Homology Guided Force-Directed Graph Layouts,,"Ashley Suh, Mustafa Hajij, Bei Wang, Carlos Scheidegger, Paul Rosen",https://arxiv.org/pdf/1712.05548.pdf,"Graphs are commonly used to encode relationships among entities, yet their abstractness makes them difficult to analyze. Node-link diagrams are popular for drawing graphs, and force-directed layouts provide a flexible method for node arrangements that use local relationships in an attempt to reveal the global shape of the graph. However, clutter and overlap of unrelated structures can lead to confusing graph visualizations. This paper leverages the persistent homology features of an undirected graph as derived information for interactive manipulation of force-directed layouts. We first discuss how to efficiently extract 0-dimensional persistent homology features from both weighted and unweighted undirected graphs. We then introduce the interactive persistence barcode used to manipulate the force-directed graph layout. In particular, the user adds and removes contracting and repulsing forces generated by the persistent homology features, eventually selecting the set of persistent homology features that most improve the layout. Finally, we demonstrate the utility of our approach across a variety of synthetic and real datasets",,,,,vimeo 360050009,,2019,2019,InfoVis,Ballroom B,Wednesday,Drawing Nodes and Edges,2022-10-23,,
openaccessvis2019.csv,TVCG,TVCG,Graph Drawing by Stochastic Gradient Descent,,"Jonathan X. Zheng, Samraat Pawar, Dan F. M. Goodman",https://arxiv.org/pdf/1710.04626.pdf,"A popular method of force-directed graph drawing is multidimensional scaling using graph-theoretic distances as input. We present an algorithm to minimize its energy function, known as stress, by using stochastic gradient descent (SGD) to move a single pair of vertices at a time. Our results show that SGD can reach lower stress levels faster and more consistently than majorization, without needing help from a good initialization. We then show how the unique properties of SGD make it easier to produce constrained layouts than previous approaches. We also show how SGD can be directly applied within the sparse stress approximation of Ortmann et al. [1], making the algorithm scalable up to large graphs.",,,,,vimeo 364569741,,,2019,InfoVis,Ballroom B,Wednesday,Drawing Nodes and Edges,2022-10-23,,
openaccessvis2019.csv,TVCG,TVCG,The Effect of Edge Bundling and Seriation on Sensemaking of Biclusters in Bipartite Graphs,,"Maoyuan Sun, Jian Zhao, Hao Wu, Kurt Luther, Chris North, Naren Ramakrishnan",,,,,,,vimeo 364567994,,,2019,VAST,Ballroom B,Wednesday,Drawing Nodes and Edges,2022-10-23,,
openaccessvis2019.csv,InfoVis,TVCG,Uncertainty-Aware Principal Component Analysis,,"Jochen G”rtler, Thilo Spinner, Dirk Streeb, Daniel Weiskopf, Oliver Deussen",https://arxiv.org/pdf/1905.01127.pdf,"We present a technique to perform dimensionality reduction on data that is subject to uncertainty. Our method is a generalization of traditional principal component analysis (PCA) to multivariate probability distributions. In comparison to non-linear methods, linear dimensionality reduction techniques have the advantage that the characteristics of such probability distributions remain intact after projection. We derive a representation of the PCA sample covariance matrix that respects potential uncertainty in each of the inputs, building the mathematical foundation of our new method: uncertainty-aware PCA. In addition to the accuracy and performance gained by our approach over sampling-based strategies, our formulation allows us to perform sensitivity analysis with regard to the uncertainty in the data. For this, we propose factor traces as a novel visualization that enables to better understand the influence of uncertainty on the chosen principal components. We provide multiple examples of our technique using real-world datasets. As a special case, we show how to propagate multivariate normal distributions through PCA in closed form. Furthermore, we discuss extensions and limitations of our approach.",,,,,vimeo 360050141,,2019,2019,InfoVis,Ballroom A,Thursday,Ensembles & Uncertainty,2022-10-24,,
openaccessvis2019.csv,SciVis,TVCG,A Structural Average of Labeled Merge Trees for Uncertainty Visualization,,"Lin Yan, Yusu Wang, Elizabeth Munch, Ellen Gasparovic, Bei Wang",https://arxiv.org/pdf/1908.00113.pdf,"Physical phenomena in science and engineering are frequently modeled using scalar fields. In scalar field topology, graph-based topological descriptors such as merge trees, contour trees, and Reeb graphs are commonly used to characterize topological changes in the (sub)level sets of scalar fields. One of the biggest challenges and opportunities to advance topology-based visualization is to understand and incorporate uncertainty into such topological descriptors to effectively reason about their underlying data. In this paper, we study a structural average of a set of labeled merge trees and use it to encode uncertainty in data. Specifically, we compute a 1-center tree that minimizes its maximum distance to any other tree in the set under a well-defined metric called the interleaving distance. We provide heuristic strategies that compute structural averages of merge trees whose labels do not fully agree. We further provide an interactive visualization system that resembles a numerical calculator that takes as input a set of merge trees and outputs a tree as their structural average. We also highlight structural similarities between the input and the average and incorporate uncertainty information for visual exploration. We develop a novel measure of uncertainty, referred to as consistency, via a metric-space view of the input trees. Finally, we demonstrate an application of our framework through merge trees that arise from ensembles of scalar fields. Our work is the first to employ interleaving distances and consistency to study a global, mathematically rigorous, structural average of merge trees in the context of uncertainty visualization.",,,,,vimeo 359998912,10.1109/TVCG.2019.2934242,2019,2019,SciVis,Ballroom A,Thursday,Ensembles & Uncertainty,2022-10-24,,
openaccessvis2019.csv,SciVis,TVCG,Multiscale Visual Drilldown for the Analysis of Large Ensembles of Multi-Body Protein Complexes,,"Katarina Furmanova, Adam Jur?¡k, Barbora Kozlikova, Helwig Hauser, Jan By?ka",https://arxiv.org/pdf/1907.04112.pdf,"When studying multi-body protein complexes, biochemists use computational tools that can suggest hundreds or thousands of their possible spatial configurations. However, it is not feasible to experimentally verify more than only a very small subset of them. In this paper, we propose a novel multiscale visual drilldown approach that was designed in tight collaboration with proteomic experts, enabling a systematic exploration of the configuration space. Our approach takes advantage of the hierarchical structure of the data ? from the whole ensemble of protein complex configurations to the individual configurations, their contact interfaces, and the interacting amino acids. Our new solution is based on interactively linked 2D and 3D views for individual hierarchy levels and at each level, we offer a set of selection and filtering operations enabling the user to narrow down the number of configurations that need to be manually scrutinized. Furthermore, we offer a dedicated filter interface, which provides the users with an overview of the applied filtering operations and enables them to examine their impact on the explored ensemble. This way, we maintain the history of the exploration process and thus enable the user to return to an earlier point of the exploration. We demonstrate the effectiveness of our approach on two case studies conducted by collaborating proteomic experts.",,,,,vimeo 359999233,10.1109/TVCG.2019.2934333,2019,2019,SciVis,Ballroom A,Thursday,Ensembles & Uncertainty,2022-10-24,,
openaccessvis2019.csv,TVCG,TVCG,eFESTA: Ensemble Feature Exploration with Surface Density Estimates,,"Wenbin He, Hanqi Guo, Han-Wei Shen, Tom Peterka",,,,,,,vimeo 364569031,10.1109/TVCG.2018.2879866,,2019,SciVis,Ballroom A,Thursday,Ensembles & Uncertainty,2022-10-24,,
openaccessvis2019.csv,TVCG,TVCG,Visualization and Visual Analysis of Ensemble Data: A Survey,,"Junpeng Wang, Subhashis Hazarika, Cheng Li, Han-Wei Shen",,,,,,,vimeo 364569796,,,2019,SciVis,Ballroom A,Thursday,Ensembles & Uncertainty,2022-10-24,,
openaccessvis2019.csv,TVCG,TVCG,Exploring the Sensitivity of Choropleths under Attribute Uncertainty,,"Zhaosong Huang, Yafeng Lu, Elizabeth A. Mack, Wei Chen, Ross Maciejewski",,,,,,,vimeo 364568169,10.1109/TVCG.2019.2892483,,2019,VAST,Ballroom A,Thursday,Ensembles & Uncertainty,2022-10-24,,
openaccessvis2019.csv,InfoVis,TVCG,Toward Objective Evaluation of Working Memory in Visualizations: A Case Study Using Pupillometry and a Dual-Task Paradigm,,"Lace M. K. Padilla, Spencer Castro, P. Samuel Quinan, Ian T. Ruginski, Sarah Creem-Regehr",https://osf.io/zj6tp/,"Cognitive science has established widely used and validated procedures for evaluating working memory in numerous applied domains, but surprisingly few studies have employed these methodologies to assess claims about the impacts of visualizations on working memory. The lack of information visualization research that uses validated procedures for measuring working memory may be due, in part, to the absence of cross-domain methodological guidance tailored explicitly to the unique needs of visualization research. This paper presents a set of clear, practical, and empirically validated methods for evaluating working memory during visualization tasks and provides readers with guidance in selecting an appropriate working memory evaluation paradigm. As a case study, we illustrate multiple methods for evaluating working memory in a visual-spatial aggregation task with geospatial data. The results show that the use of dual-task experimental designs (simultaneous performance of several tasks compared to single-task performance) and pupil dilation can reveal working memory demands associated with task difficulty and dual-tasking. In a dual-task experimental design, measures of task completion times and pupillometry revealed the working memory demands associated with both task difficulty and dual-tasking. Pupillometry demonstrated that participants? pupils were significantly larger when they were completing a more difficult task and when multitasking. We propose that researchers interested in the relative differences in working memory between visualizations should consider a converging methods approach, where physiological measures and behavioral measures of working memory are employed to generate a rich evaluation of visualization effort.",,,https://osf.io/6u8em/,,vimeo 360050392,10.1109/TVCG.2019.2934286,2019,2019,InfoVis,Ballroom A,Wednesday,Evaluation & Reproducibility,2022-10-23,,
openaccessvis2019.csv,InfoVis,TVCG,VisTA: Towards Using Visual Analytics to Support the Investigation of Think-Aloud Sessions,,"Mingming Fan, Ke Wu, Jian Zhao, Yue Li, Winter Wei, Khai Truong",,,,,,,,,2019,2019,InfoVis,Ballroom A,Wednesday,Evaluation & Reproducibility,2022-10-23,,
openaccessvis2019.csv,TVCG,TVCG,Embedding Meta-Information into Visualizations,,"Alok Hota, Jian Huang",,,,,,,vimeo 364569334,,,2019,SciVis,Ballroom A,Wednesday,Evaluation & Reproducibility,2022-10-23,,
openaccessvis2019.csv,TVCG,TVCG,On Evaluating Runtime Performance of Interactive Visualizations,,"Valentin Bruder, Christoph Mller, Steffen Frey, Thomas Ertl",,,,,,,vimeo 364569107,10.1109/TVCG.2019.2898435,,2019,SciVis,Ballroom A,Wednesday,Evaluation & Reproducibility,2022-10-23,,
openaccessvis2019.csv,VAST,TVCG,The Validity and Generalizability of Summative Evaluation Methods in Visual Analytics,,"Mosab Khayat, Morteza Karimzadeh, David Ebert, Arif Ghafoor",https://arxiv.org/pdf/1907.13314.pdf,"Many evaluation methods have been used to assess the usefulness of Visual Analytics (VA) solutions. These methods stem from a variety of origins with different assumptions and goals, which cause confusion about their proofing capabilities. Moreover, the lack of discussion about the evaluation processes may limit our potential to develop new evaluation methods specialized for VA. In this paper, we present an analysis of evaluation methods that have been used to summatively evaluate VA solutions. We provide a survey and taxonomy of the evaluation methods that have appeared in the VAST literature in the past two years. We then analyze these methods in terms of validity and generalizability of their findings, as well as the feasibility of using them. We propose a new metric called summative quality to compare evaluation methods according to their ability to prove usefulness, and make recommendations for selecting evaluation methods based on their summative quality in the VA domain.",,,,,vimeo 360155500,,2019,2019,VAST,Ballroom A,Wednesday,Evaluation & Reproducibility,2022-10-23,,
openaccessvis2019.csv,TVCG,TVCG,An Analysis of Automated Visual Analysis Classification: Interactive Visualization Task Inference of Cancer Genomics Domain Experts,,"Connor C. Gramazio, Jeff Huang, David H. Laidlaw",,,,,,,vimeo 364568057,,,2019,VAST,Ballroom A,Wednesday,Evaluation & Reproducibility,2022-10-23,,
openaccessvis2019.csv,SciVis,TVCG,Dynamic Nested Tracking Graphs,,"Jonas Lukasczyk, Christoph Garth, Tim Biedert, Ross Maciejewski, Gunther H. Weber, Heike Leitte",,,,,,,vimeo 359999289,,2019,2019,SciVis,Ballroom B,Tuesday,Features and Topology,2022-10-22,,
openaccessvis2019.csv,SciVis,TVCG,Extraction and Visual Analysis of Potential Vorticity Banners around the Alps,,"Robin Bader, Michael Sprenger, Nikolina Ban, Stefan Rdishli, Christoph Sch„r, Tobias Gnther",,,,,,,vimeo 359998953,10.1109/TVCG.2019.2934310,2019,2019,SciVis,Ballroom B,Tuesday,Features and Topology,2022-10-22,,
openaccessvis2019.csv,SciVis,TVCG,Multi-Scale Topological Analysis of Asymmetric Tensor Fields on Surfaces,,"Fariba Khan, Lawrence Roy, Eugene Zhang, Botong Qu, Shih-Hsuan Hung, Harry Yeh, Robert S. Laramee, Yue Zhang",,,,,,,vimeo 359999144,10.1109/TVCG.2019.2934314,2019,2019,SciVis,Ballroom B,Tuesday,Features and Topology,2022-10-22,,
openaccessvis2019.csv,SciVis,TVCG,Vector Field Topology of Time-Dependent Flows in a Steady Reference Frame,,"Irene Baeza Rojo, Tobias Gnther",,,,,,,vimeo 359999444,10.1109/TVCG.2019.2934375,2019,2019,SciVis,Ballroom B,Tuesday,Features and Topology,2022-10-22,,
openaccessvis2019.csv,TVCG,TVCG,Feature Tracking by Two-Step Optimization,,"Andrea Schnorr, Dirk N. Helmrich, Dominik Denker, Torsten W. Kuhlen, Bernd Hentschel",,,,,,,vimeo 364569076,10.1109/TVCG.2018.2883630,,2019,SciVis,Ballroom B,Tuesday,Features and Topology,2022-10-22,,
openaccessvis2019.csv,VAST,TVCG,Scalable Topological Data Analysis and Visualization for Interpreting Data-Driven Models in Scientific Applications,,"Shusen Liu, Di Wang, Dan Maljovec, Rushil Anirudh, Jayaraman J. Thiagarajan, Sam Ade Jacobs, Brian C. Van Essen, David Hysom, Jae-Seung Yeom, Jim Gaffney, J. Luc Peterson, Peter B. Robinson, Harsh Bhatia, Valerio Pascucci, Brian K. Spears, Peer-Timo Bremer",https://arxiv.org/pdf/1907.08325.pdf,"With the rapid adoption of machine learning techniques for large-scale applications in science and engineering comes the convergence of two grand challenges in visualization. First, the utilization of black box models (e.g., deep neural networks) calls for advanced techniques in exploring and interpreting model behaviors. Second, the rapid growth in computing has produced enormous datasets that require techniques that can handle millions or more samples. Although some solutions to these interpretability challenges have been proposed, they typically do not scale beyond thousands of samples, nor do they provide the high-level intuition scientists are looking for. Here, we present the first scalable solution to explore and analyze high-dimensional functions often encountered in the scientific data analysis pipeline. By combining a new streaming neighborhood graph construction, the corresponding topology computation, and a novel data aggregation scheme, namely <em>topology aware datacubes</em>, we enable interactive exploration of both the topological and the geometric aspect of high-dimensional data. Following two use cases from high-energy-density (HED) physics and computational biology, we demonstrate how these capabilities have led to crucial new insights in both applications.",,,,,vimeo 360155819,,2019,2019,VAST,Ballroom B,Tuesday,Features and Topology,2022-10-22,,
openaccessvis2019.csv,SciVis,TVCG,Accelerated Monte Carlo Rendering of Finite-Time Lyapunov Exponents,,"Irene Baeza Rojo, Markus Gross, Tobias Gnther",,,,,,,vimeo 359999098,10.1109/TVCG.2019.2934313,2019,2019,SciVis,Ballroom C,Wednesday,Flow,2022-10-23,,
openaccessvis2019.csv,SciVis,TVCG,Analysis of the Near-Wall Flow in a Turbine Cascade by Splat Visualization,,"Baldwin Nsonga, Gerik Scheuermann, Stefan Gumhold, Jordi Ventosa-Molina, Denis Koschichow, Jochen Fr”hlich",https://arxiv.org/pdf/1907.09904.pdf,"Turbines are essential components of jet planes and power plants. Therefore, their efficiency and service life are of central engineering interest. In the case of jet planes or thermal power plants, the heating of the turbines due to the hot gas flow is critical. Besides effective cooling, it is a major goal of engineers to minimize heat transfer between gas flow and turbine by design. Since it is known that splat events have a substantial impact on the heat transfer between flow and immersed surfaces, we adapt a splat detection and visualization method to a turbine cascade simulation in this case study. Because splat events are small phenomena, we use a direct numerical simulation resolving the turbulence in the flow as the base of our analysis. The outcome shows promising insights into splat formation and its relation to vortex structures. This may lead to better turbine design in the future.",,,,,vimeo 359999261,,2019,2019,SciVis,Ballroom C,Wednesday,Flow,2022-10-23,,
openaccessvis2019.csv,TVCG,TVCG,Detection and Visualization of Splat and Antisplat Events in Turbulent Flows,,"Baldwin Nsonga, Martin Niemann, Jochen Fr”hlich, Joachim Staib, Stefan Gumhold, Gerik Scheuermann",,,,,,,vimeo 364569430,10.1109/TVCG.2019.2920157,,2019,SciVis,Ballroom C,Wednesday,Flow,2022-10-23,,
openaccessvis2019.csv,TVCG,TVCG,Extreme-Scale Stochastic Particle Tracing for Uncertain Unsteady Flow Visualization and Analysis,,"Hanqi Guo, Wenbin He, Sangmin Seo, Han-Wei Shen, Emil Mihai Constantinescu, Chunhui Liu, Tom Peterka",,,,,,,vimeo 364568821,,,2019,SciVis,Ballroom C,Wednesday,Flow,2022-10-23,,
openaccessvis2019.csv,TVCG,TVCG,FlowNet: A Deep Learning Framework for Clustering and Selection of Streamlines and Stream Surfaces,,"Jun Han, Jun Tao, Chaoli Wang",,,,,,,vimeo 364569054,10.1109/TVCG.2018.2880207,,2019,SciVis,Ballroom C,Wednesday,Flow,2022-10-23,,
openaccessvis2019.csv,TVCG,TVCG,Hyper-Objective Vortices,,"Tobias Gnther, Holger Theisel",,,,,,,vimeo 364568933,10.1109/TVCG.2018.2868760,,2019,SciVis,Ballroom C,Wednesday,Flow,2022-10-23,,
openaccessvis2019.csv,TVCG,TVCG,"A Visual Analytics System for Exploring, Monitoring, and Forecasting Road Traffic Congestion",,"Chunggi Lee, Yeonjun Kim, Seungmin Jin, Dongmin Kim, Ross Maciejewski, David Ebert, Sungahn Ko",,,,,,,vimeo 364568300,10.1109/TVCG.2019.2922597,,2019,VAST,Ballroom C,Thursday,Geovisualization,2022-10-24,,
openaccessvis2019.csv,InfoVis,TVCG,SmartCube: An Adaptive Data Management Architecture for the Real-Time Visualization of Spatiotemporal Datasets,,"Can Liu, Cong Wu, Hanning Shao, Xiaoru Yuan",,,,,,,vimeo 360050463,,2019,2019,InfoVis,Ballroom C,Thursday,Geovisualization,2022-10-24,,
openaccessvis2019.csv,TVCG,TVCG,Real-Time Exploration of Large Spatiotemporal Datasets based on Order Statistics,,"C¡cero L. Pahins, Nivan Ferreira, Jo?o L. Comba",,,,,,,vimeo 364569181,10.1109/TVCG.2019.2914446,,2019,SciVis,Ballroom C,Thursday,Geovisualization,2022-10-24,,
openaccessvis2019.csv,VAST,TVCG,AirVis: Visual Analytics of Air Pollution Propagation,,"Zikun Deng, Di Weng, Jiahui Chen, Ren Liu, Zhibin Wang, Jie Bao, Yu Zheng, Yingcai Wu",,,,,,,vimeo 360154598,10.1109/TVCG.2019.2934670,2019,2019,VAST,Ballroom C,Thursday,Geovisualization,2022-10-24,,
openaccessvis2019.csv,VAST,TVCG,OD Morphing: balancing simplicity with faithfulness for OD bundling,,"Yan Lyu, Xu Liu, Hanyi Chen, Arpan Mangal, Brian Lim, Kai Liu, Chao Chen",,,,,,,vimeo 360154344,,2019,2019,VAST,Ballroom C,Thursday,Geovisualization,2022-10-24,,
openaccessvis2019.csv,TVCG,TVCG,Semantics-Space-Time Cube: A Conceptual Framework for Systematic Analysis of Texts in Space and Time,,"Jie Li, Siming Chen, Wei Chen, Gennady Andrienko, Natalia Andrienko",http://openaccess.city.ac.uk/id/eprint/21109/1/semantics-space-time.R1.pdf,"We propose an approach to analyzing data in which texts are associated with spatial and temporal references with the aim to understand how the text semantics vary over space and time. To represent the semantics, we apply probabilistic topic modeling. After extracting a set of topics and representing the texts by vectors of topic weights, we aggregate the data into a data cube with the dimensions corresponding to the set of topics, the set of spatial locations (e.g., regions), and the time divided into suitable intervals according to the scale of the planned analysis. Each cube cell corresponds to a combination (topic, location, time interval) and contains aggregate measures characterizing the subset of the texts concerning this topic and having the spatial and temporal references within these location and interval. Based on this structure, we systematically describe the space of analysis tasks on exploring the interrelationships among the three heterogeneous information facets, semantics, space, and time. We introduce the operations of projecting and slicing the cube, which are used to decompose complex tasks into simpler subtasks. We then present a design of a visual analytics system intended to support these subtasks. To reduce the complexity of the user interface, we apply the principles of structural, visual, and operational uniformity while respecting the specific properties of each facet. The aggregated data are represented in three parallel views corresponding to the three facets and providing different complementary perspectives on the data. The views have similar look-and-feel to the extent allowed by the facet specifics. Uniform interactive operations applicable to any view support establishing links between the facets. The uniformity principle is also applied in supporting the projecting and slicing operations on the data cube. We evaluate the feasibility and utility of the approach by applying it in two analysis scenarios using geolocated social media data for studying people?s reactions to social and natural events of different spatial and temporal scales.",,,,,vimeo 364568102,,,2019,VAST,Ballroom C,Thursday,Geovisualization,2022-10-24,,
openaccessvis2019.csv,TVCG,TVCG,MARVisT: Authoring Glyph-based Visualization in Mobile Augmented Reality,,"Zhutian Chen, Yijia Su, Yifang Wang, Qianwen Wang, Huamin Qu, Yingcai Wu",,,,,,,vimeo 364568467,10.1109/TVCG.2019.2892415,,2019,InfoVis,Ballroom B,Wednesday,Immersion and Virtual Environments,2022-10-23,,
openaccessvis2019.csv,InfoVis,TVCG,Designing for Mobile and Immersive Visual Analytics in the Field,,"Matt Whitlock, Keke Wu, Danielle Albers Szafir",https://arxiv.org/pdf/1908.00680.pdf,"Data collection and analysis in the field is critical for operations in domains such as environmental science and public safety. However, field workers currently face data- and platform-oriented issues in efficient data collection and analysis in the field, such as limited connectivity, screen space, and attentional resources. In this paper, we explore how visual analytics tools might transform field practices by more deeply integrating data into these operations. We use a design probe coupling mobile, cloud, and immersive analytics components to guide interviews with ten experts from five domains to explore how visual analytics could support data collection and analysis needs in the field. The results identify shortcomings of current approaches and target scenarios and design considerations for future field analysis systems. We embody these findings in FieldView, an extensible, open-source prototype designed to support critical use cases for situated field analysis. Our findings suggest the potential for integrating mobile and immersive technologies to enhance data?s utility for various field operations and new directions for visual analytics tools to transform fieldwork.",,,,,vimeo 360050322,10.1109/TVCG.2019.2934282,2019,2019,InfoVis,Ballroom B,Wednesday,Immersion and Virtual Environments,2022-10-23,,
openaccessvis2019.csv,InfoVis,TVCG,Evaluating an Immersive Space-Time Cube Geovisualization for Intuitive Trajectory Data Exploration,,"Jorge A. Wagner, Wolfgang Stuerzlinger, Luciana Nedel",https://arxiv.org/pdf/1908.00580.pdf,"A Space-Time Cube enables analysts to clearly observe spatio-temporal features in movement trajectory datasets in geovisualization. However, its general usability is impacted by a lack of depth cues, a reported steep learning curve, and the requirement for efficient 3D navigation. In this work, we investigate a Space-Time Cube in the Immersive Analytics domain. Based on a review of previous work and selecting an appropriate exploration metaphor, we built a prototype environment where the cube is coupled to a virtual representation of the analyst?s real desk, and zooming and panning in space and time are intuitively controlled using mid-air gestures. We compared our immersive environment to a desktop-based implementation in a user study with 20 participants across 7 tasks of varying difficulty, which targeted different user interface features. To investigate how performance is affected in the presence of clutter, we explored two scenarios with different numbers of trajectories. While the quantitative performance was similar for the majority of tasks, large differences appear when we analyze the patterns of interaction and consider subjective metrics. The immersive version of the Space-Time Cube received higher usability scores, much higher user preference, and was rated to have a lower mental workload, without causing participants discomfort in 25-minute-long VR sessions.",,,,,vimeo 360049740,,2019,2019,InfoVis,Ballroom B,Wednesday,Immersion and Virtual Environments,2022-10-23,,
openaccessvis2019.csv,InfoVis,TVCG,The Impact of Immersion on Cluster Identification Tasks,,"Matthias Kraus, Niklas Kai Weiler, Daniela Oelke, Johannes Kehrer, Daniel Keim, Johannes Fuchs",,,,,,,vimeo 360049662,,2019,2019,InfoVis,Ballroom B,Wednesday,Immersion and Virtual Environments,2022-10-23,,
openaccessvis2019.csv,InfoVis,TVCG,"There Is No Spoon: Evaluating Performance, Space Use, and Presence with Expert Domain Users in Immersive Analytics",,"Andrea Batch, Andrew Cunningham, Maxime Cordeil, Niklas Elmqvist, Tim Dwyer, Bruce H Thomas, Kim Marriott",https://osf.io/wzqbu,"Immersive analytics turns the very space surrounding the user into a canvas for data analysis, supporting human cognitive abilities in myriad ways. We present the results of a design study, contextual inquiry, and longitudinal evaluation involving professional economists using a Virtual Reality (VR) system for multidimensional visualization to explore actual economic data. Results from our preregistered evaluation highlight the varied use of space depending on context (exploration vs. presentation), the organization of space to support work, and the impact of immersion on navigation and orientation in the 3D analysis space.",,,,https://osf.io/jhnuc/,vimeo 360050033,,2019,2019,InfoVis,Ballroom B,Wednesday,Immersion and Virtual Environments,2022-10-23,,
openaccessvis2019.csv,SciVis,TVCG,Deadeye Visualization Revisited: Investigation of Preattentiveness and Applicability in Virtual Environments,,"Andrey Krekhov, Sebastian Cmentowski, Andre Waschk, Jens Krueger",https://arxiv.org/pdf/1907.04702.pdf,"Visualizations rely on highlighting to attract and guide our attention. To make an object of interest stand out independently from a number of distractors, the underlying visual cue, e.g., color, has to be preattentive. In our prior work, we introduced Deadeye as an instantly recognizable highlighting technique that works by rendering the target object for one eye only. In contrast to prior approaches, Deadeye excels by not modifying any visual properties of the target. However, in the case of 2D visualizations, the method requires an additional setup to allow dichoptic presentation, which is a considerable drawback. As a follow-up to requests from the community, this paper explores Deadeye as a highlighting technique for 3D visualizations, because such stereoscopic scenarios support dichoptic presentation out of the box. Deadeye suppresses binocular disparities for the target object, so we cannot assume the applicability of our technique as a given fact. With this motivation, the paper presents quantitative evaluations of Deadeye in VR, including configurations with multiple heterogeneous distractors as an important robustness challenge. After confirming the preserved preattentiveness (all average accuracies above 90 %) under such real-world conditions, we explore VR volume rendering as an example application scenario for Deadeye. We depict a possible workflow for integrating our technique, conduct an exploratory survey to demonstrate benefits and limitations, and finally provide related design implications",,,,,vimeo 359999349,10.1109/TVCG.2019.2934370,2019,2019,SciVis,Ballroom B,Wednesday,Immersion and Virtual Environments,2022-10-23,,
openaccessvis2019.csv,TVCG,TVCG,Eiffel: Evolutionary Flow Map for Influence Graph Visualization,,"Yucheng Huang, Lei Shi, Yue Su, Yifan Hu, Hanghang Tong, Chaoli Wang, Tong Yang, Deyun Wang, Shuo Liang",,,,,,,vimeo 364568698,10.1109/TVCG.2019.2906900,,2019,InfoVis,Ballroom A,Friday,Influencers,2022-10-25,,
openaccessvis2019.csv,VAST,TVCG,Galex: Exploring the Evolution and Intersection of Disciplines,,"Zeyu Li, Changhong Zhang, Shichao Jia, Jiawan Zhang",,,,,,,vimeo 360154945,10.1109/TVCG.2019.2934667,2019,2019,VAST,Ballroom A,Friday,Influencers,2022-10-25,,
openaccessvis2019.csv,VAST,TVCG,"MetricsVis: A Visual Analytics Framework for Evaluating Individual, Team, and Organization Performance",,"Jieqiong Zhao, Morteza Karimzadeh, Luke Snyder, Cittayong Surakitbanharn, Zhenyu Cheryl Qian, David Ebert",https://arxiv.org/pdf/1907.13601.pdf,"Evaluating employee performance in organizations with varying workloads and tasks is challenging. Specifically, it is important to understand how quantitative measurements of employee achievements relate to supervisor expectations, what the main drivers of good performance are, and how to combine these complex and flexible performance evaluation metrics into an accurate portrayal of organizational performance in order to identify shortcomings and improve overall productivity. To facilitate this process, we summarize common organizational performance analyses into four visual exploration task categories. Additionally, we develop MetricsVis, a visual analytics system composed of multiple coordinated views to support the dynamic evaluation and comparison of individual, team, and organizational performance in public safety organizations. MetricsVis provides four primary visual components to expedite performance evaluation: (1) a priority adjustment view to support direct manipulation on evaluation metrics; (2) a reorderable performance matrix to demonstrate the details of individual employees; (3) a group performance view that highlights aggregate performance and individual contributions for each group; and (4) a projection view illustrating employees with similar specialties to facilitate shift assignments and training. We demonstrate the usability of our framework with two case studies from medium-sized law enforcement agencies and highlight its broader applicability to other domains.",,,,,vimeo 360156150,,2019,2019,VAST,Ballroom A,Friday,Influencers,2022-10-25,,
openaccessvis2019.csv,VAST,VAST,Influence Flowers of Academic Entities,,"Minjeong Shin, Alexander Soen, Benjamin T. Readshaw, Stephen Michael Blackburn, Mitchell Whitelaw, Lexing Xie",https://arxiv.org/pdf/1907.12748.pdf,"We present the Influence Flower, a new visual metaphor for the influence profile of academic entities, including people, projects, institutions, conferences, and journals. While many tools <em>quantify influence</em>, we aim to expose <em>the flow of influence between entities</em>. The Influence Flower is an ego-centric graph, with a query entity placed in the centre. The petals are styled to reflect the strength of influence to and from other entities of the same or different type. For example, one can break down the incoming and outgoing influences of a research lab by research topics. The Influence Flower uses a recent snapshot of Microsoft Academic Graph, consisting of 212 million authors, their 176 million publications, and 1.2 billion citations. An interactive web app, Influence Map, is constructed around this central metaphor for searching and curating visualisations. We also propose a visual comparison method that highlights change in influence patterns over time. We demonstrate through several case studies that the Influence Flower supports data-driven inquiries about the following: researchers? careers over time; paper(s) and projects, including those with delayed recognition; the interdisciplinary profile of a research institution; and the shifting topical trends in conferences. We also use this tool on influence data beyond academic citations, by contrasting the academic and Twitter activities of a researcher",http://influencemap.ml/,,,,vimeo 360155315,,2019,2019,VAST,Ballroom A,Friday,Influencers,2022-10-25,,
openaccessvis2019.csv,TVCG,TVCG,WeSeer: Visual Analysis for Better Information Cascade Prediction of WeChat Articles,,"Quan Li, Ziming Wu, Lingling Yi, Kristanto Sean N, Huamin Qu, Xiaojuan Ma",https://arxiv.org/pdf/1808.09068.pdf,"Social media, such as Facebook and WeChat, empowers millions of users to create, consume, and disseminate online information on an unprecedented scale. The abundant information on social media intensifies the competition of WeChat Public Official Articles (i.e., posts) for gaining user attention due to the zero-sum nature of attention. Therefore, only a small portion of information tends to become extremely popular while the rest remains unnoticed or quickly disappears. Such a typical ?long-tail? phenomenon is very common in social media. Thus, recent years have witnessed a growing interest in predicting the future trend in the popularity of social media posts and understanding the factors that influence the popularity of the posts. Nevertheless, existing predictive models either rely on cumbersome feature engineering or sophisticated parameter tuning, which are difficult to understand and improve. In this paper, we study and enhance a point process-based model by incorporating visual reasoning to support communication between the users and the predictive model for a better prediction result. The proposed system supports users to uncover the working mechanism behind the model and improve the prediction accuracy accordingly based on the insights gained. We use realistic WeChat articles to demonstrate the effectiveness of the system and verify the improved model on a large scale of WeChat articles. We also elicit and summarize the feedback from WeChat domain experts.",,,,,vimeo 364571456,10.1109/TVCG.2018.2867776,,2019,VAST,Ballroom A,Friday,Influencers,2022-10-25,,
openaccessvis2019.csv,VAST,TVCG,R-Map: A Map Metaphor for Visualizing Information Reposting Process in Social Media,,"Shuai Chen, Sihang Li, Siming Chen, Xiaoru Yuan",,,,,,,vimeo 360155374,10.1109/TVCG.2019.2934263,2019,2019,VAST,Ballroom A,Friday,Influencers,2022-10-25,,
openaccessvis2019.csv,InfoVis,TVCG,DataShot: Automatic Generation of Fact Sheet from Tabular Data,,"Yun Wang, Zhida Sun, Haidong Zhang, Weiwei Cui, Ke Xu, Xiaojuan Ma, Dongmei Zhang",,,,,,,vimeo 360049797,,2019,2019,InfoVis,Ballroom C,Thursday,Infographics & Storytelling,2022-10-24,,
openaccessvis2019.csv,InfoVis,TVCG,Text-to-Viz: Automatic Generation of Infographics from Natural Language Statements,,"Weiwei Cui, Xiaoyu Zhang, Yun Wang, He Huang, Bei Chen, Lei Fang, Haidong Zhang, Jian-Guang Lou, Dongmei Zhang",https://arxiv.org/pdf/1907.09091.pdf,"Combining data content with visual embellishments, infographics can effectively deliver messages in an engaging and memorable manner. Various authoring tools have been proposed to facilitate the creation of infographics. However, creating a professional infographic with these authoring tools is still not an easy task, requiring much time and design expertise. Therefore, these tools are generally not attractive to casual users, who are either unwilling to take time to learn the tools or lacking in proper design expertise to create a professional infographic. In this paper, we explore an alternative approach: to automatically generate infographics from natural language statements. We first conducted a preliminary study to explore the design space of infographics. Based on the preliminary study, we built a proof-of-concept system that automatically converts statements about simple proportionrelated statistics to a set of infographics with pre-designed styles. Finally, we demonstrated the usability and usefulness of the system through sample results, exhibits, and expert reviews.",,,,,,,2019,2019,InfoVis,Ballroom C,Thursday,Infographics & Storytelling,2022-10-24,,
openaccessvis2019.csv,InfoVis,TVCG,Towards Automated Infographic Design: Deep Learning-based Auto-Generation of Extensible Timeline,,"Zhutian Chen, Yun Wang, Qianwen Wang, Yong Wang, Huamin Qu",https://arxiv.org/pdf/1907.13550.pdf,"Designers need to consider not only perceptual effectiveness but also visual styles when creating an infographic. This process can be difficult and time consuming for professional designers, not to mention non-expert users, leading to the demand for automated infographics design. As a first step, we focus on timeline infographics, which have been widely used for centuries. We contribute an end-to-end approach that automatically extracts an extensible timeline template from a bitmap image. Our approach adopts a deconstruction and reconstruction paradigm. At the deconstruction stage, we propose a multi-task deep neural network that simultaneously parses two kinds of information from a bitmap timeline: 1) the global information, i.e., the representation, scale, layout, and orientation of the timeline, and 2) the local information, i.e., the location, category, and pixels of each visual element on the timeline. At the reconstruction stage, we propose a pipeline with three techniques, i.e., Non-Maximum Merging, Redundancy Recover, and DL GrabCut, to extract an extensible template from the infographic, by utilizing the deconstruction results. To evaluate the effectiveness of our approach, we synthesize a timeline dataset (4296 images) and collect a real-world timeline dataset (393 images) from the Internet. We first report quantitative evaluation results of our approach over the two datasets. Then, we present examples of automatically extracted templates and timelines automatically generated based on these templates to qualitatively demonstrate the performance. The results confirm that our approach can effectively extract extensible templates from real-world timeline infographics.",,,,,,,2019,2019,InfoVis,Ballroom C,Thursday,Infographics & Storytelling,2022-10-24,,
openaccessvis2019.csv,VAST,TVCG,EmoCo: Visual Analysis of Emotion Coherence in Presentation Videos,,"Haipeng Zeng, Xingbo Wang, Aoyu Wu, Yong Wang, Quan Li, Alex Endert, Huamin Qu",https://arxiv.org/pdf/1907.12918.pdf,"Emotions play a key role in human communication and public presentations. Human emotions are usually expressed through multiple modalities. Therefore, exploring multimodal emotions and their coherence is of great value for understanding emotional expressions in presentations and improving presentation skills. However, manually watching and studying presentation videos is often tedious and time-consuming. There is a lack of tool support to help conduct an efficient and in-depth multi-level analysis. Thus, in this paper, we introduce EmoCo, an interactive visual analytics system to facilitate efficient analysis of emotion coherence across facial, text, and audio modalities in presentation videos. Our visualization system features a channel coherence view and a sentence clustering view that together enable users to obtain a quick overview of emotion coherence and its temporal evolution. In addition, a detail view and word view enable detailed exploration and comparison from the sentence level and word level, respectively. We thoroughly evaluate the proposed system and visualization techniques through two usage scenarios based on TED Talk videos and interviews with two domain experts. The results demonstrate the effectiveness of our system in gaining insights into emotion coherence in presentations.",,,,,vimeo 360154890,10.1109/TVCG.2019.2934656,2019,2019,VAST,Ballroom C,Thursday,Infographics & Storytelling,2022-10-24,,
openaccessvis2019.csv,TVCG,TVCG,Multimodal Analysis of Video Collections: Visual Exploration of Presentation Techniques in TED Talks,,"Aoyu Wu, Huamin Qu",,,,,,,vimeo 364568236,10.1109/TVCG.2018.2889081,,2019,VAST,Ballroom C,Thursday,Infographics & Storytelling,2022-10-24,,
openaccessvis2019.csv,TVCG,TVCG,Supporting Story Synthesis: Bridging the Gap between Visual Analytics and Storytelling,,"Siming Chen, Jie Li, Gennady Andrienko, Natalia Andrienko, Yun Wang, Phong H. Nguyen, Cagatay Turkay",http://openaccess.city.ac.uk/id/eprint/21217/1/tvcg19-storySynthesis.pdf,"Visual analytics usually deals with complex data and uses sophisticated algorithmic, visual, and interactive techniques supporting the analysis. Findings and results of the analysis often need to be communicated to an audience that lacks visual analytics expertise. This requires analysis outcomes to be presented in simpler ways than that are typically used in visual analytics systems. However, not only analytical visualizations may be too complex for target audiences but also the information that needs to be presented. Analysis results may consist of multiple components, which may involve multiple heterogeneous facets. Hence, there exists a gap on the path from obtaining analysis findings to communicating them, within which two main challenges lie: information complexity and display complexity. We address this problem by proposing a general framework where data analysis and result presentation are linked by story synthesis, in which the analyst creates and organises story contents. Unlike previous research, where analytic findings are represented by stored display states, we treat findings as data constructs. We focus on selecting, assembling and organizing findings for further presentation rather than on tracking analysis history and enabling dual (i.e., explorative and communicative) use of data displays. In story synthesis, findings are selected, assembled, and arranged in meaningful layouts that take into account the structure of information and inherent properties of its components. We propose a workflow for applying the proposed conceptual framework in designing visual analytics systems and demonstrate the generality of the approach by applying it to two diverse domains, social media and movement analysis.",,,,,vimeo 364568266,10.1109/TVCG.2018.2889054,,2019,VAST,Ballroom C,Thursday,Infographics & Storytelling,2022-10-24,,
openaccessvis2019.csv,InfoVis,TVCG,Illusion of Causality in Visualized Data,,"Cindy Xiong, Joel Shapiro, Jessica Hullman, Steven Franconeri",https://arxiv.org/pdf/1908.00215.pdf,"Students who eat breakfast more frequently tend to have a higher grade point average. From this data, many people might confidently state that a before-school breakfast program would lead to higher grades. This is a reasoning error, because correlation does not necessarily indicate causation ? X and Y can be correlated without one directly causing the other. While this error is pervasive, its prevalence might be amplified or mitigated by the way that the data is presented to a viewer. Across three crowdsourced experiments, we examined whether how simple data relations are presented would mitigate this reasoning error. The first experiment tested examples similar to the breakfast-GPA relation, varying in the plausibility of the causal link. We asked participants to rate their level of agreement that the relation was correlated, which they rated appropriately as high. However, participants also expressed high agreement with a causal interpretation of the data. Levels of support for the causal interpretation were not equally strong across visualization types: causality ratings were highest for text descriptions and bar graphs, but weaker for scatter plots. But is this effect driven by bar graphs aggregating data into two groups or by the visual encoding type? We isolated data aggregation versus visual encoding type and examined their individual effect on perceived causality. Overall, different visualization designs afford different cognitive reasoning affordances across the same data. High levels of data aggregation by graphs tend to be associated with higher perceived causality in data. Participants perceived line and dot visual encodings as more causal than bar encodings. Our results demonstrate how some visualization designs trigger stronger causal links while choosing others can help mitigate unwarranted perceptions of causality.",,,,,vimeo 360049821,10.1109/TVCG.2019.2934399,2019,2019,InfoVis,Ballroom B,Thursday,Interactive Machine Learning,2022-10-24,,
openaccessvis2019.csv,VAST,TVCG,"Ablate, Variate, and Contemplate:Visual Analytics for Discovering Neural Architectures",,"Dylan Cashman, Adam Perer, Remco Chang, Hendrik Strobelt",https://arxiv.org/pdf/1908.00387.pdf,"Deep learning models require the configuration of many layers and parameters in order to get good results. However, there are currently few systematic guidelines for how to configure a successful model. This means model builders often have to experiment with different configurations by manually programming different architectures (which is tedious and time consuming) or rely on purely automated approaches to generate and train the architectures (which is expensive). In this paper, we present Rapid Exploration of Model Architectures and Parameters, or REMAP, a visual analytics tool that allows a model builder to discover a deep learning model quickly via exploration and rapid experimentation of neural network architectures. In REMAP, the user explores the large and complex parameter space for neural network architectures using a combination of global inspection and local experimentation. Through a visual overview of a set of models, the user identifies interesting clusters of architectures. Based on their findings, the user can run ablation and variation experiments to identify the effects of adding, removing, or replacing layers in a given architecture and generate new models accordingly. They can also handcraft new models using a simple graphical interface. As a result, a model builder can build deep learning models quickly, efficiently, and without manual programming. We inform the design of REMAP through a design study with four deep learning model builders. Through a use case, we demonstrate that REMAP allows users to discover performant neural network architectures efficiently using visual exploration and user-defined semi-automated searches through the model space.",http://www.eecs.tufts.edu/~dcashm01/snacs/,,,,,,2019,2019,VAST,Ballroom B,Thursday,Interactive Machine Learning,2022-10-24,,
openaccessvis2019.csv,VAST,TVCG,VASSL: A Visual Analytics Toolkit for Social Spambot Labeling,,"Mosab Khayat, Morteza Karimzadeh, Jieqiong Zhao, David Ebert",https://arxiv.org/pdf/1907.13319.pdf,"Social media platforms are filled with social spambots. Detecting these malicious accounts is essential, yet challenging, as they continually evolve to evade detection techniques. In this article, we present VASSL, a visual analytics system that assists in the process of detecting and labeling spambots. Our tool enhances the performance and scalability of manual labeling by providing multiple connected views and utilizing dimensionality reduction, sentiment analysis and topic modeling, enabling insights for the identification of spambots. The system allows users to select and analyze groups of accounts in an interactive manner, which enables the detection of spambots that may not be identified when examined individually. We present a user study to objectively evaluate the performance of VASSL users, as well as capturing subjective opinions about the usefulness and the ease of use of the tool.",,,,,vimeo 360155523,10.1109/TVCG.2019.2934266,2019,2019,VAST,Ballroom B,Thursday,Interactive Machine Learning,2022-10-24,,
openaccessvis2019.csv,VAST,TVCG,Visual Interaction with Deep Learning Models through Collaborative Semantic Inference,,"Sebastian Gehrmann, Hendrik Strobelt, Robert Krger, Kathryn Hite, Hanspeter Pfister, Alexander M. Rush",https://arxiv.org/pdf/1907.10739.pdf,"Automation of tasks can have critical consequences when humans lose agency over decision processes. Deep learning models are particularly susceptible since current black-box approaches lack explainable reasoning. We argue that both the visual interface and model structure of deep learning systems need to take into account interaction design. We propose a framework of collaborative semantic inference (CSI) for the co-design of interactions and models to enable visual collaboration between humans and algorithms. The approach exposes the intermediate reasoning process of models which allows semantic interactions with the visual metaphors of a problem, which means that a user can both understand and control parts of the model reasoning process. We demonstrate the feasibility of CSI with a co-designed case study of a document summarization system.",,,,,vimeo 360155863,10.1109/TVCG.2019.2934595,2019,2019,VAST,Ballroom B,Thursday,Interactive Machine Learning,2022-10-24,,
openaccessvis2019.csv,VAST,VAST,ICE: An Interactive Configuration Explorer for High Dimensional Parameter Spaces,,"Anjul Tyagi, Klaus Mueller, Zhen Cao, Tyler Estro, Erez Zadok",https://arxiv.org/pdf/1907.12627.pdf,"There are many applications where users seek to explore the impact of the settings of several categorical variables with respect to one dependent numerical variable. For example, a computer systems analyst might want to study how the type of file system or storage device affects system performance. A usual choice is the method of Parallel Sets designed to visualize multivariate categorical variables. However, we found that the magnitude of the parameter impacts on the numerical variable cannot be easily observed here. We also attempted a dimension reduction approach based on Multiple Correspondence Analysis but found that the SVD-generated 2D layout resulted in a loss of information. We hence propose a novel approach, the Interactive Configuration Explorer (ICE), which directly addresses the need of analysts to learn how the dependent numerical variable is affected by the parameter settings given multiple optimization objectives. No information is lost as ICE shows the complete distribution and statistics of the dependent variable in context with each categorical variable. Analysts can interactively filter the variables to optimize for certain goals such as achieving a system with maximum performance, low variance, etc. Our system",,,,,,,,,VAST,,,,,,
openaccessvis2019.csv,,,,,,,,,,,,,,,,,,,,,,
openaccessvis2019.csv, a comparative user study," and two case studies.""",,,,,,vimeo 360156102,,2019,,Ballroom B,Interactive Machine Learning,,,,3:35 PM,,,,,
openaccessvis2019.csv,VAST,VAST,Interactive Correction of Mislabeled Training Data,,"Xi Ye, Shouxing Xiang, Jiazhi Xia, Jing Wu, Yang Chen, Shixia Lu",,,,,,,vimeo 360154277,,2019,2019,VAST,Ballroom B,Thursday,Interactive Machine Learning,2022-10-24,,
openaccessvis2019.csv,InfoVis,TVCG,OntoPlot: A Novel Visualisation for Non-hierarchical Associations in Large Ontologies,,"Ying Yang, Michael Wybrow, Yuan-Fang Li, Tobias Czauderna, Yongqun He",https://monash.figshare.com/articles/OntoPlot_A_Novel_Visualisation_for_Non-hierarchical_Associations_in_Large_Ontologies/9204449/2,"Biologists often use computer graphics to visualize structures, which due to physical limitations are not possible to image with a microscope. One example for such structures are microtubules, which are present in every eukaryotic cell. They are part of the cytoskeleton maintaining the shape of the cell and playing a key role in the cell division. In this paper, we propose a scientificallyaccurate multi-scale procedural model of microtubule dynamics as a novel application scenario for procedural animation, which can generate visualizations of their overall shape, molecular structure, as well as animations of the dynamic behaviour of their growth and disassembly. The model is spanning from tens of micrometers down to atomic resolution. All the aspects of the model are driven by scientific data. The advantage over a traditional, manual animation approach is that when the underlying data change, for instance due to new evidence, the model can be recreated immediately. The procedural animation concept is presented in its generic form, with several novel extensions, facilitating an easy translation to other domains with emergent multi-scale behavior.",,,,,vimeo 360050594,10.1109/TVCG.2019.2934557,2019,2019,InfoVis,Ballroom C,Thursday,Large Data and Dimensionality Reduction,2022-10-24,,
openaccessvis2019.csv,InfoVis,TVCG,P5: Portable Progressive Parallel Processing Pipeline for Interactive Data Analysis and Visualization,,"Kelvin Li, Kwan-Liu Ma",,,,,,,vimeo 360050527,,2019,2019,InfoVis,Ballroom C,Thursday,Large Data and Dimensionality Reduction,2022-10-24,,
openaccessvis2019.csv,InfoVis,TVCG,RSATree: Distribution-Aware Data Representation of Large-Scale Tabular Datasets for Flexible Visual Query,,"Honghui Mei, Yating Wei, Shuyue Zhou, Bingru Lin, Yuanzhe Hu, Ying Zhao, Jiazhi Xia, Wei Chen",https://arxiv.org/pdf/1908.02005.pdf,"Analysts commonly investigate the data distributions derived from statistical aggregations of data that are represented by charts, such as histograms and binned scatterplots, to visualize and analyze a large-scale dataset. Aggregate queries are implicitly executed through such a process. Datasets are constantly extremely large; thus, the response time should be accelerated by calculating predefined data cubes. However, the queries are limited to the predefined binning schema of preprocessed data cubes. Such limitation hinders analysts flexible adjustment of visual specifications to investigate the implicit patterns in the data effectively. Particularly, RSATree enables arbitrary queries and flexible binning strategies by leveraging three schemes, namely, an R-tree-based space partitioning scheme to catch the data distribution, a locality-sensitive hashing technique to achieve locality-preserving random access to data items, and a summed area table scheme to support interactive query of aggregated values with a linear computational complexity. This study presents and implements a web-based visual query system that supports visual specification, query, and exploration of large-scale tabular data with user-adjustable granularities. We demonstrate the efficiency and utility of our approach by performing various experiments on real-world datasets and analyzing time and space complexity.",,,,,vimeo 360049964,,2019,2019,InfoVis,Ballroom C,Thursday,Large Data and Dimensionality Reduction,2022-10-24,,
openaccessvis2019.csv,TVCG,TVCG,SolarView: Low Distortion Radial Embedding with a Focus,,"Thom Castermans, Kevin Verbeek, Bettina Speckmann, Michel A. Westenberg, Rob Koopman, Shenghui Wang, Hein van den Berg, Arianna Betti",,,,,,,vimeo 364568393,,,2019,InfoVis,Ballroom C,Thursday,Large Data and Dimensionality Reduction,2022-10-24,,
openaccessvis2019.csv,TVCG,TVCG,Scientific Visualization as a Microservice,,"Mohammad Raji, Alok Hota, Tanner Hobson, Jian Huang",,,,,,,vimeo 364569370,10.1109/TVCG.2018.2879672,,2019,SciVis,Ballroom C,Thursday,Large Data and Dimensionality Reduction,2022-10-24,,
openaccessvis2019.csv,VAST,TVCG,GPGPU Linear Complexity tSNE Optimization,,"Nicola Pezzotti, Julian Thijssen, Alexander Mordvintsev, Thomas H”llt, Baldur van Lew, Boudewijn P.F. Lelieveldt, Elmar Eisemann, Anna Vilanova",,,,,,,vimeo 360155729,,2019,2019,VAST,Ballroom C,Thursday,Large Data and Dimensionality Reduction,2022-10-24,,
openaccessvis2019.csv,InfoVis,TVCG,Pattern-Driven Navigation in 2D Multiscale Visualizations with Scalable Insets,,"Fritz Lekschas, Michael Behrisch, Benjamin Bach, Peter Kerpedjiev, Nils Gehlenborg, Hanspeter Pfister",https://www.biorxiv.org/content/biorxiv/early/2019/04/04/301036.full.pdf,"We present Scalable Insets, a technique for interactively exploring and navigating large numbers of annotated patterns in multiscale visual spaces such as gigapixel images, matrices, or maps. Exploration of many but sparselydistributed patterns in multiscale visual spaces is challenging as visual representations change across zoom levels, context and navigational cues get lost upon zooming, and navigation is time consuming. Our technique visualizes annotated patterns too small to be identifiable at certain zoom levels using insets, i.e., magnified thumbnail views of the annotated pattern. Insets support users in searching, comparing, and contextualizing patterns, while reducing the amount of navigation needed. They are dynamically placed either within the viewport or along the boundary of the viewport to offer a compromise between locality and context preservation. Annotated patterns are interactively clustered by location and type. They are visually represented as an aggregated inset to provide scalable exploration within a single viewport. A controlled user study with 18 participants found improved performance in visual search (up to 45% faster) and comparison of pattern types (up to 32 percentage points more accurate) compared to a baseline technique. A second study with 6 experts in the field of genomics showed that Scalable Insets are easy to learn and effective in a biological data exploration scenario",,,,,vimeo 360445699,,2019,2019,InfoVis,Ballroom A,Wednesday,Multiscale Visualization,2022-10-23,,
openaccessvis2019.csv,SciVis,TVCG,Multi-Scale Procedural Animations of Microtubule Dynamics Based on Measured Data,,"Tobias Klein, Ivan Viola, Eduard Gr”ller, Peter Mindek",,,,,,,vimeo 359999585,,2019,2019,SciVis,Ballroom A,Wednesday,Multiscale Visualization,2022-10-23,,
openaccessvis2019.csv,SciVis,TVCG,OpenSpace: A System for Astrographics,,"Alexander Bock, Emil Axelsson, Jonathas Costa, Gene Payne, Micah Acinapura, Vivian Trakinski, Carter B Emmart PhD, Claudio Silva, Charles Hansen, Anders Ynnerman",,,,,,,vimeo 359998824,10.1109/TVCG.2019.2934259,2019,2019,SciVis,Ballroom A,Wednesday,Multiscale Visualization,2022-10-23,,
openaccessvis2019.csv,SciVis,TVCG,Scale-Space Splatting: Reforming Spacetime for the Cross-Scale Exploration of Integral Measures in Molecular Dynamics,,"Juraj P lenik, Jan By?ka, Stefan Bruckner, Helwig Hauser",https://arxiv.org/pdf/1907.09939.pdf,"Understanding large amounts of spatiotemporal data from particle-based simulations, such as molecular dynamics, often relies on the computation and analysis of aggregate measures. These, however, by virtue of aggregation, hide structural information about the space/time localization of the studied phenomena. This leads to degenerate cases where the measures fail to capture distinct behaviour. In order to drill into these aggregate values, we propose a multi-scale visual exploration technique. Our novel representation, based on partial domain aggregation, enables the construction of a continuous scale-space for discrete datasets and the simultaneous exploration of scales in both space and time. We link these two scale-spaces in a scale-space space-time cube and model linked views as orthogonal slices through this cube, thus enabling the rapid identification of spatio-temporal patterns at multiple scales. To demonstrate the effectiveness of our approach, we showcase an advanced exploration of a protein?ligand simulation.",,,,,vimeo 359998771,,2019,2019,SciVis,Ballroom A,Wednesday,Multiscale Visualization,2022-10-23,,
openaccessvis2019.csv,SciVis,TVCG,ScaleTrotter: Illustrative Visual Travels Across Negative Scales,,"Sarkis Halladjian, Haichao Miao, David Kou?il, Eduard Gr”ller, Ivan Viola, Tobias Isenberg",https://arxiv.org/pdf/1907.12352.pdf,"We present ScaleTrotter, a conceptual framework for an interactive, multi-scale visualization of biological mesoscale data and, specifically, genome data. ScaleTrotter allows viewers to smoothly transition from the nucleus of a cell to the atomistic composition of the DNA, while bridging several orders of magnitude in scale. The challenges in creating an interactive visualization of genome data are fundamentally different in several ways from those in other domains like astronomy that require a multi-scale representation as well. First, genome data has intertwined scale levels?the DNA is an extremely long, connected molecule that manifests itself at all scale levels. Second, elements of the DNA do not disappear as one zooms out?instead the scale levels at which they are observed group these elements differently. Third, we have detailed information and thus geometry for the entire dataset and for all scale levels, posing a challenge for interactive visual exploration. Finally, the conceptual scale levels for genome data are close in scale space, requiring us to find ways to visually embed a smaller scale into a coarser one. We address these challenges by creating a new multi-scale visualization concept. We use a scale-dependent camera model that controls the visual embedding of the scales into their respective parents, the rendering of a subset of the scale hierarchy, and the location, size, and scope of the view. In traversing the scales, ScaleTrotter is roaming between 2D and 3D visual representations that are depicted in integrated visuals. We discuss, specifically, how this form of multi-scale visualization follows from the specific characteristics of the genome data and describe its implementation. Finally, we discuss the implications of our work to the general illustrative depiction of multi-scale data.",,,,,vimeo 359999391,10.1109/TVCG.2019.2934334,2019,2019,SciVis,Ballroom A,Wednesday,Multiscale Visualization,2022-10-23,,
openaccessvis2019.csv,TVCG,TVCG,Taxonomizer: A Visual Analytics Framework for Constructing Fully Labeled Hierarchies from Multivariate Data,,"Salman Mahmood, Klaus Mueller",,,,,,,vimeo 364568009,,,2019,VAST,Ballroom C,Wednesday,Multivariate & Multidimensional Data,2022-10-23,,
openaccessvis2019.csv,InfoVis,TVCG,An Incremental Dimensionality Reduction Method for Visualizing Streaming Multidimensional Data,,"Takanori Fujiwara, Jia-Kai Chou, Shilpika Shilpika, Panpan Xu, Liu Ren, Kwan-Liu Ma",https://arxiv.org/pdf/1905.04000.pdf,"Dimensionality reduction (DR) methods are commonly used for analyzing and visualizing multidimensional data. However, when data is a live streaming feed, conventional DR methods cannot be directly used because of their computational complexity and inability to preserve the projected data positions at previous time points. In addition, the problem becomes even more challenging when the dynamic data records have a varying number of dimensions as often found in real-world applications. This paper presents an incremental DR solution. We enhance an existing incremental PCA method in several ways to ensure its usability for visualizing streaming multidimensional data. First, we use geometric transformation and animation methods to help preserve a viewer?s mental map when visualizing the incremental results. Second, to handle data dimension variants, we use an optimization method to estimate the projected data positions, and also convey the resulting uncertainty in the visualization. We demonstrate the effectiveness of our design with two case studies using real-world datasets.",,,,,vimeo 360050443,,2019,2019,InfoVis,Ballroom C,Wednesday,Multivariate & Multidimensional Data,2022-10-23,,
openaccessvis2019.csv,TVCG,TVCG,Generalizing Iso-surfaces to Multi-variate Data,,"Jochen Jankowai, Ingrid Hotz",,,,,,,vimeo 364568992,,,2019,SciVis,Ballroom C,Wednesday,Multivariate & Multidimensional Data,2022-10-23,,
openaccessvis2019.csv,TVCG,TVCG,TTHRESH: Tensor Compression for Multidimensional Visual Data,,"Rafael Ballester-Ripoll, Peter Lindstrom, Renato Pajarola",https://arxiv.org/pdf/1806.05952.pdf,"Memory and network bandwidth are decisive bottlenecks when handling high-resolution multidimensional data sets in visualization applications, and they increasingly demand suitable data compression strategies. We introduce a novel lossy compression algorithm for multidimensional data over regular grids. It leverages the higher-order singular value decomposition (HOSVD), a generalization of the SVD to three dimensions and higher, together with bit-plane, run-length and arithmetic coding to compress the HOSVD transform coefficients. Our scheme degrades the data particularly smoothly and achieves lower mean squared error than other state-of-the-art algorithms at low-to-medium bit rates, as it is required in data archiving and management for visualization purposes. Further advantages of the proposed algorithm include very fine bit rate selection granularity and the ability to manipulate data at very small cost in the compression domain, for example to reconstruct filtered and/or subsampled versions of all (or selected parts) of the data set.",,,,,vimeo 364569449,10.1109/TVCG.2019.2904063,,2019,SciVis,Ballroom C,Wednesday,Multivariate & Multidimensional Data,2022-10-23,,
openaccessvis2019.csv,VAST,TVCG,Selection Bias Tracking and Detailed Subset Comparison for High-Dimensional Data,,"David Borland, Wenyuan Wang, Jonathan Zhang, Joshua Shrestha, David Gotz",https://arxiv.org/pdf/1906.07625.pdf,"The collection of large, complex datasets has become common across a wide variety of domains. Visual analytics tools increasingly play a key role in exploring and answering complex questions about these large datasets. However, many visualizations are not designed to concurrently visualize the large number of dimensions present in complex datasets (e.g. tens of thousands of distinct codes in an electronic health record system). This fact, combined with the ability of many visual analytics systems to enable rapid, ad-hoc specification of groups, or cohorts, of individuals based on a small subset of visualized dimensions, leads to the possibility of introducing selection bias?when the user creates a cohort based on a specified set of dimensions, differences across many other unseen dimensions may also be introduced. These unintended side effects may result in the cohort no longer being representative of the larger population intended to be studied, which can negatively affect the validity of subsequent analyses. We present techniques for selection bias tracking and visualization that can be incorporated into high-dimensional exploratory visual analytics systems, with a focus on medical data with existing data hierarchies. These techniques include: (1) tree-based cohort provenance and visualization, including a user-specified baseline cohort that all other cohorts are compared against, and visual encoding of cohort ?drift?, which indicates where selection bias may have occurred, and (2) a set of visualizations, including a novel icicle-plot based visualization, to compare in detail the per-dimension differences between the baseline and a user-specified focus cohort. These techniques are integrated into a medical temporal event sequence visual analytics tool. We present example use cases and report findings from domain expert user interviews.",,,,,vimeo 360154972,10.1109/TVCG.2019.2934209,2019,2019,VAST,Ballroom C,Wednesday,Multivariate & Multidimensional Data,2022-10-23,,
openaccessvis2019.csv,VAST,TVCG,Visual Analysis of High-Dimensional Event Sequence Data via Dynamic Hierarchical Aggregation,,"David Gotz, Jonathan Zhang, Wenyuan Wang, Joshua Shrestha, David Borland",https://arxiv.org/pdf/1906.07617.pdf,"Temporal event data are collected across a broad range of domains, and a variety of visual analytics techniques have been developed to empower analysts working with this form of data. These techniques generally display aggregate statistics computed over sets of event sequences that share common patterns. Such techniques are often hindered, however, by the high-dimensionality of many real-world event sequence datasets which can prevent effective aggregation. A common coping strategy for this challenge is to group event types together prior to visualization, as a pre-process, so that each group can be represented within an analysis as a single event type. However, computing these event groupings as a pre-process also places significant constraints on the analysis. This paper presents a new visual analytics approach for dynamic hierarchical dimension aggregation. The approach leverages a predefined hierarchy of dimensions to computationally quantify the informativeness, with respect to a measure of interest, of alternative levels of grouping within the hierarchy at runtime. This information is then interactively visualized, enabling users to dynamically explore the hierarchy to select the most appropriate level of grouping to use at any individual step within an analysis. Key contributions include an algorithm for interactively determining the most informative set of event groupings for a specific analysis context, and a scented scatter-plus-focus visualization design with an optimization-based layout algorithm that supports interactive hierarchical exploration of alternative event type groupings. We apply these techniques to high-dimensional event sequence data from the medical domain and report findings from domain expert interviews.",,,,,vimeo 360154915,10.1109/TVCG.2019.2934661,2019,2019,VAST,Ballroom C,Wednesday,Multivariate & Multidimensional Data,2022-10-23,,
openaccessvis2019.csv,VAST,TVCG,Interactive Learning for Identifying Relevant Tweets to Support Real-time Situational Awareness,,"Luke Snyder, Yi-Shan Lin, Morteza Karimzadeh, Dan Goldwasser, David Ebert",https://arxiv.org/pdf/1908.02588.pdf,"Various domain users are increasingly leveraging real-time social media data to gain rapid situational awareness. However, due to the high noise in the deluge of data, effectively determining semantically relevant information can be difficult, further complicated by the changing definition of relevancy by each end user for different events. The majority of existing methods for short text relevance classification fail to incorporate users? knowledge into the classification process. Existing methods that incorporate interactive user feedback focus on historical datasets. Therefore, classifiers cannot be interactively retrained for specific events or user-dependent needs in real-time. This limits real-time situational awareness, as streaming data that is incorrectly classified cannot be corrected immediately, permitting the possibility for important incoming data to be incorrectly classified as well. We present a novel interactive learning framework to improve the classification process in which the user iteratively corrects the relevancy of tweets in real-time to train the classification model on-the-fly for immediate predictive improvements. We computationally evaluate our classification model adapted to learn at interactive rates. Our results show that our approach outperforms state-of-the-art machine learning models. In addition, we integrate our framework with the extended Social Media Analytics and Reporting Toolkit (SMART) 2.0 system, allowing the use of our interactive learning framework within a visual analytics system tailored for real-time situational awareness. To demonstrate our framework?s effectiveness, we provide domain expert feedback from first responders who used the extended SMART 2.0 system.",,,,,vimeo 360154855,10.1109/TVCG.2019.2934614,2019,2019,VAST,Ballroom C,Wednesday,Planning and Situational Awareness,2022-10-23,,
openaccessvis2019.csv,TVCG,TVCG,A Systematic Review of Visualization in Building Information Modeling,,"Paulo Ivson, Andr‚ Moreira, Francisco Queiroz, Wallas Santos, Waldemar Celes",http://eprints.whiterose.ac.uk/146384/1/author_TVCG2907583.pdf,"Building Information Modeling (BIM) employs data-rich 3D CAD models for large-scale facility design, construction, and operation. These complex datasets contain a large amount and variety of information, ranging from design specifications to real-time sensor data. They are used by architects and engineers for various analysis and simulations throughout a facility?s life cycle. Many techniques from different visualization fields could be used to analyze these data. However, the BIM domain still remains largely unexplored by the visualization community. The goal of this article is to encourage visualization researchers to increase their involvement with BIM. To this end, we present the results of a systematic review of visualization in current BIM practice. We use a novel taxonomy to identify main application areas and analyze commonly employed techniques. From this domain characterization, we highlight future research opportunities brought forth by the unique features of BIM. For instance, exploring the synergies between scientific and information visualization to integrate spatial and non-spatial data. We hope this article raises awareness to interesting new challenges the BIM domain brings to the visualization community.",,,,,vimeo 364569766,10.1109/TVCG.2019.2907583,,2019,InfoVis,Ballroom C,Wednesday,Planning and Situational Awareness,2022-10-23,,
openaccessvis2019.csv,VAST,TVCG,"LightGuider: Guiding Interactive Lighting Design using Suggestions, Provenance, and Quality Visualization",,"Andreas Walch, Michael Schw„rzler, Christian Luksch, Elmar Eisemann, Theresia Gschwandtner",,,,,,,vimeo 360154391,10.1109/TVCG.2019.2934658,2019,2019,VAST,Ballroom C,Wednesday,Planning and Situational Awareness,2022-10-23,,
openaccessvis2019.csv,VAST,TVCG,PlanningVis: A Visual Analytics Approach to Production Planning in Smart Factories,,"Dong Sun, Renfei Huang, Yong Wang, Yuanzhe Chen, Jia Zeng, Mingxuan Yuan, Ting-Cheun Pong, Huamin Qu",https://arxiv.org/pdf/1907.12201.pdf,"Production planning in the manufacturing industry is crucial for fully utilizing factory resources (e.g., machines, raw materials and workers) and reducing costs. With the advent of industry 4.0, plenty of data recording the status of factory resources have been collected and further involved in production planning, which brings an unprecedented opportunity to understand, evaluate and adjust complex production plans through a data-driven approach. However, developing a systematic analytics approach for production planning is challenging due to the large volume of production data, the complex dependency between products, and unexpected changes in the market and the plant. Previous studies only provide summarized results and fail to show details for comparative analysis of production plans. Besides, the rapid adjustment to the plan in the case of an unanticipated incident is also not supported. In this paper, we propose PlanningVis, a visual analytics system to support the exploration and comparison of production plans with three levels of details: a plan overview presenting the overall difference between plans, a product view visualizing various properties of individual products, and a production detail view displaying the product dependency and the daily production details in related factories. By integrating an automatic planning algorithm with interactive visual explorations, PlanningVis can facilitate the efficient optimization of daily production planning as well as support a quick response to unanticipated incidents in manufacturing. Two case studies with real-world data and carefully designed interviews with domain experts demonstrate the effectiveness and usability of PlanningVis.",,,,,vimeo 360155601,10.1109/TVCG.2019.2934275,2019,2019,VAST,Ballroom C,Wednesday,Planning and Situational Awareness,2022-10-23,,
openaccessvis2019.csv,VAST,TVCG,Visual Analytics for Electromagnetic Situation Awareness in Radio Monitoring and Management,,"Ying Zhao, Xiaobo Luo, Xiaru Lin, Hairong Wang, Xiaoyan Kui, Fangfang Zhou, Jinsong Wang, Yi Chen, Wei Chen",,,,,,,vimeo 360154252,,2019,2019,VAST,Ballroom C,Wednesday,Planning and Situational Awareness,2022-10-23,,
openaccessvis2019.csv,VAST,TVCG,sPortfolio: Stratified Visual Analysis of Stock Portfolios,,"Xuanwu Yue, Jiaxin Bai, Qinhan Liu, Yiyang Tang, Abishek Puri, Ke Li, Huamin Qu",https://arxiv.org/pdf/1910.05536.pdf,"Quantitative Investment, built on the solid foundation of robust financial theories, is at the center stage in investment industry today. The essence of quantitative investment is the multi-factor model, which explains the relationship between the risk and return of equities. However, the multi-factor model generates enormous quantities of factor data, through which even experienced portfolio managers find it difficult to navigate. This has led to portfolio analysis and factor research being limited by a lack of intuitive visual analytics tools. Previous portfolio visualization systems have mainly focused on the relationship between the portfolio return and stock holdings, which is insufficient for making actionable insights or understanding market trends. In this paper, we present sPortfolio, which, to the best of our knowledge, is the first visualization that attempts to explore the factor investment area. In particular, sPortfolio provides a holistic overview of the factor data and aims to facilitate the analysis at three different levels: a Risk-Factor level, for a general market situation analysis; a Multiple-Portfolio level, for understanding the portfolio strategies; and a Single-Portfolio level, for investigating detailed operations. The system?s effectiveness and usability are demonstrated through three case studies. The system has passed its pilot study and is soon to be deployed in industry.",,,,,vimeo 360154484,,2019,2019,VAST,Ballroom C,Wednesday,Planning and Situational Awareness,2022-10-23,,
openaccessvis2019.csv,TVCG,TVCG,ScatterNet: A Deep Subjective Similarity Model for Visual Analysis of Scatterplots,,"Yuxin Ma, Anthony K. H. Tung, Wei Wang, Xiang Gao, Zhigeng Pan, Wei Chen",,,,,,,vimeo 364568078,10.1109/TVCG.2018.2875702,,2019,VAST,Ballroom A,Thursday,Scatterplots,2022-10-24,,
openaccessvis2019.csv,InfoVis,TVCG,A Recursive Subdivision Technique for Sampling Multi-class Scatterplots,,"Yunhai Wang, Xin Chen, Tong Ge, Jian Zhang, Ying Zhao, Chi-Wing Fu, Baoquan Chen, Oliver Deussen",,,,,,,vimeo 360050562,,2019,2019,InfoVis,Ballroom A,Thursday,Scatterplots,2022-10-24,,
openaccessvis2019.csv,InfoVis,TVCG,Data Sampling in Multi-view and Multi-class Scatterplots via Set Cover Optimization,,"Ruizhen Hu, Tingkai Sha, Oliver van Kaick, Oliver Deussen, Hui Huang",,,,,,,vimeo 360049945,10.1109/TVCG.2019.2934799,2019,2019,InfoVis,Ballroom A,Thursday,Scatterplots,2022-10-24,,
openaccessvis2019.csv,InfoVis,TVCG,Discriminability Tests for Visualization Effectiveness and Scalability,,"Rafael Veras, Christopher Collins",https://arxiv.org/pdf/1907.11358.pdf,"The scalability of a particular visualization approach is limited by the ability for people to discern differences between plots made with different datasets. Ideally, when the data changes, the visualization changes in perceptible ways. This relation breaks down when there is a mismatch between the encoding and the character of the dataset being viewed. Unfortunately, visualizations are often designed and evaluated without fully exploring how they will respond to a wide variety of datasets. We explore the use of an image similarity measure, the Multi-Scale Structural Similarity Index (MS-SSIM), for testing the discriminability of a data visualization across a variety of datasets. MS-SSIM is able to capture the similarity of two visualizations across multiple scales, including low level granular changes and high level patterns. Significant data changes that are not captured by the MS-SSIM indicate visualizations of low discriminability and effectiveness. The measure?s utility is demonstrated with two empirical studies. In the first, we compare human similarity judgments and MS-SSIM scores for a collection of scatterplots. In the second, we compute the discriminability values for a set of basic visualizations and compare them with empirical measurements of effectiveness. In both cases, the analyses show that the computational measure is able to approximate empirical results. Our approach can be used to rank competing encodings on their discriminability and to aid in selecting visualizations for a particular type of data distribution.",,,,,vimeo 360484488,,2019,2019,InfoVis,Ballroom A,Thursday,Scatterplots,2022-10-24,,
openaccessvis2019.csv,InfoVis,TVCG,Improving the Robustness of Scagnostics,,"Yunhai Wang, Zeyu Wang, Michael Correll, Zhanglin Cheng, Tingting Liu, Oliver Deussen, Michael Sedlmair",,,,,,,vimeo 360050165,10.1109/TVCG.2019.2934796,2019,2019,InfoVis,Ballroom A,Thursday,Scatterplots,2022-10-24,,
openaccessvis2019.csv,InfoVis,TVCG,Winglets: Visualizing Association with Uncertainty in Multi-class Scatterplots,,"Min Lu, Shuaiqi Wang, Joel Lanir, Noa Fish, Yang Yue, Daniel CohenOr, Hui Huang",,,,,,,vimeo 360050129,,2019,2019,InfoVis,Ballroom A,Thursday,Scatterplots,2022-10-24,,
openaccessvis2019.csv,InfoVis,TVCG,Searching the Visual Style and Structure of D3 Visualizations,,"Enamul Hoque, Maneesh Agrawala",,,,,,,vimeo 360050425,,2019,2019,InfoVis,Ballroom C,Friday,Searching & Querying,2022-10-25,,
openaccessvis2019.csv,InfoVis,TVCG,The Role of Latency in Predicting Visual Search Behavior,,"Leilani Battle, R. Jordan Crouser, Audace Nakeshimana, Ananda Montoly, Remco Chang, Michael Stonebraker",,,,,,,vimeo 360050582,,2019,2019,InfoVis,Ballroom C,Friday,Searching & Querying,2022-10-25,,
openaccessvis2019.csv,VAST,TVCG,A Natural-language-based Visual Query Approach of Uncertain Human Trajectories,,"Zhaosong Huang, Ye Zhao, Wei Chen, Shengjie Gao, Kejie Yu, Weixia Xu, Mingjie Tang, Minfeng Zhu, Mingliang Xu",https://arxiv.org/pdf/1908.00277.pdf,"Visual querying is essential for interactively exploring massive trajectory data. However, the data uncertainty imposes profound challenges to fulfill advanced analytics requirements. On the one hand, many underlying data does not contain accurate geographic coordinates, e.g., positions of a mobile phone only refer to the regions (i.e., mobile cell stations) in which it resides, instead of accurate GPS coordinates. On the other hand, domain experts and general users prefer a natural way, such as using a natural language sentence, to access and analyze massive movement data. In this paper, we propose a visual analytics approach that can extract spatial-temporal constraints from a textual sentence and support an effective query method over uncertain mobile trajectory data. It is built up on encoding massive, spatially uncertain trajectories by the semantic information of the POIs and regions covered by them, and then storing the trajectory documents in text database with an effective indexing scheme. The visual interface facilitates query condition specification, situation-aware visualization, and semantic exploration of large trajectory data. Usage scenarios on real-world human mobility datasets demonstrate the effectiveness of our approach.",,,,,vimeo 360154619,10.1109/TVCG.2019.2934671,2019,2019,VAST,Ballroom C,Friday,Searching & Querying,2022-10-25,,
openaccessvis2019.csv,VAST,TVCG,You can?t always sketch what you want: Understanding Sensemaking in Visual Query Systems,,"Doris Jung-Lin Lee, John Lee, Tarique Siddiqui, Jaewoo Kim, Aditya Parameswaran, Karrie Karahalios",https://arxiv.org/pdf/1710.00763.pdf,"Visual query systems (VQSs) empower users to interactively search for line charts with desired visual patterns, typically specified using intuitive sketch-based interfaces. Despite decades of past work on VQSs, these efforts have not translated to adoption in practice, possibly because VQSs are largely evaluated in unrealistic lab-based settings. To remedy this gap in adoption, we collaborated with experts from three diverse domains?astronomy, genetics, and material science?via a year-long user-centered design process to develop a VQS that supports their workflow and analytical needs, and evaluate how VQSs can be used in practice. Our study results reveal that ad-hoc sketch-only querying is not as commonly used as prior work suggests, since analysts are often unable to precisely express their patterns of interest. In addition, we characterize three essential sensemaking processes supported by our enhanced VQS. We discover that participants employ all three processes, but in different proportions, depending on the analytical needs in each domain. Our findings suggest that all three sensemaking processes must be integrated in order to make future VQSs useful for a wide range of analytical inquiries.",,,,,vimeo 360154505,,2019,2019,VAST,Ballroom C,Friday,Searching & Querying,2022-10-25,,
openaccessvis2019.csv,VAST,VAST,"Do What I Mean, Not What I Say! Design Considerations for Supporting Intent and Context in Analytical Conversation",,"Melanie Tory, Vidya Setlur",,,,,,,vimeo 360155144,,2019,2019,VAST,Ballroom C,Friday,Searching & Querying,2022-10-25,,
openaccessvis2019.csv,VAST,VAST,TopicSifter: Interactive Search Space Reduction Through Targeted Topic Modeling,,"Hannah Kim, Dongjin Choi, Barry Drake, Alex Endert, Haesun Park",https://arxiv.org/pdf/1907.12079.pdf,"Topic modeling is commonly used to analyze and understand large document collections. However, in practice, users want to focus on specific aspects or ?targets? rather than the entire corpus. For example, given a large collection of documents, users may want only a smaller subset which more closely aligns with their interests, tasks, and domains. In particular, our paper focuses on large-scale document retrieval with high recall where any missed relevant documents can be critical. A simple keyword matching search is generally not effective nor efficient as 1) it is difficult to find a list of keyword queries that can cover the documents of interest before exploring the dataset, 2) some documents may not contain the exact keywords of interest but may still be highly relevant, and 3) some words have multiple meanings, which would result in irrelevant documents included in the retrieved subset. In this paper, we present TopicSifter, a visual analytics system for interactive search space reduction. Our system utilizes targeted topic modeling based on nonnegative matrix factorization and allows users to give relevance feedback in order to refine their target and guide the topic modeling to the most relevant results.",,,,,vimeo 360154312,,2019,2019,VAST,Ballroom C,Friday,Searching & Querying,2022-10-25,,
openaccessvis2019.csv,VAST,TVCG,CloudDet: Interactive Visual Analysis of Anomalous Performances in Cloud Computing SystemsD,,"Ke Xu, Yun Wang, Leni Yang, Yifang Wang, Bo Qiao, Si Qin, Yong Xu, Haidong Zhang, Huamin Qu",https://arxiv.org/pdf/1907.13187.pdf,"Detecting and analyzing potential anomalous performances in cloud computing systems is essential for avoiding losses to customers and ensuring the efficient operation of the systems. To this end, a variety of automated techniques have been developed to identify anomalies in cloud computing performance. These techniques are usually adopted to track the performance metrics of the system (e.g., CPU, memory, and disk I/O), represented by a multivariate time series. However, given the complex characteristics of cloud computing data, the effectiveness of these automated methods is affected. Thus, substantial human judgment on the automated analysis results is required for anomaly interpretation. In this paper, we present a unified visual analytics system named CloudDet to interactively detect, inspect, and diagnose anomalies in cloud computing systems. A novel unsupervised anomaly detection algorithm is developed to identify anomalies based on the specific temporal patterns of the given metrics data (e.g., the periodic pattern), the results of which are visualized in our system to indicate the occurrences of anomalies. Rich visualization and interaction designs are used to help understand the anomalies in the spatial and temporal context. We demonstrate the effectiveness of CloudDet through a quantitative evaluation, two case studies with real-world data, and interviews with domain experts.",,,,,vimeo 360154740,,2019,2019,VAST,Ballroom B,Thursday,Vis for Software and Systems,2022-10-24,,
openaccessvis2019.csv,InfoVis,TVCG,Visualizing a Moving Target: A Design Study on Task Parallel Programs in the Presence of Evolving Data and Concerns,,"Kathryn P Williams, Alex Bigelow, Katherine Isaacs",https://arxiv.org/pdf/1905.13135.pdf,"Common pitfalls in visualization projects include lack of data availability and the domain users? needs and focus changing too rapidly for the design process to complete. While it is often prudent to avoid such projects, we argue it can be beneficial to engage them in some cases as the visualization process can help refine data collection, solving a ?chicken and egg? problem of having the data and tools to analyze it. We found this to be the case in the domain of task parallel computing where such data and tooling is an open area of research. Despite these hurdles, we conducted a design study. Through a tightly-coupled iterative design process, we built Atria, a multi-view execution graph visualization to support performance analysis. Atria simplifies the initial representation of the execution graph by aggregating nodes as related to their line of code. We deployed Atria on multiple platforms, some requiring design alteration. We describe how we adapted the design study methodology to the ?moving target? of both the data and the domain experts? concerns and how this movement kept both the visualization and programming project healthy. We reflect on our process and discuss what factors allow the project to be successful in the presence of changing data and user needs.",,,,,vimeo 360050356,10.1109/TVCG.2019.2934285,2019,2019,InfoVis,Ballroom B,Thursday,Vis for Software and Systems,2022-10-24,,
openaccessvis2019.csv,TVCG,TVCG,How People Visually Represent Discrete Constraint Problem,,"Xu Zhu, Miguel A. Nacenta, ™zgr Akgun, Peter Nightingale",,,,,,,vimeo 365291194,,,2019,InfoVis,Ballroom B,Thursday,Vis for Software and Systems,2022-10-24,,
openaccessvis2019.csv,TVCG,TVCG,Preserving Command Line Workflow for a Package Management,,"Katherine E. Isaacs, Todd Gamblin",,,,,,,,,,2019,InfoVis,Ballroom B,Thursday,Vis for Software and Systems,2022-10-24,,
openaccessvis2019.csv,TVCG,TVCG,Inviwo - A Visualization System with Usage Abstraction Levels,,"Daniel J”nsson, Peter Steneteg, Erik Sund‚n, Rickard Englund, Sathish Kottravel, Martin Falk, Ingrid Hotz, Anders Ynnerman, Timo Ropinski",https://arxiv.org/pdf/1811.12517.pdf,"The complexity of today?s visualization applications demands specific visualization systems tailored for the development of these applications. Frequently, such systems utilize levels of abstraction to improve the application development process, for instance by providing a data flow network editor. Unfortunately, these abstractions result in several issues, which need to be circumvented through an abstraction-centered system design. Often, a high level of abstraction hides low level details, which makes it difficult to directly access the underlying computing platform, which would be important to achieve an optimal performance. Therefore, we propose a layer structure developed for modern and sustainable visualization systems allowing developers to interact with all contained abstraction levels. We refer to this interaction capabilities as usage abstraction levels, since we target application developers with various levels of experience. We formulate the requirements for such a system, derive the desired architecture, and present how the concepts have been exemplary realized within the Inviwo visualization system. Furthermore, we address several specific challenges that arise during the realization of such a layered architecture, such as communication between different computing platforms, performance centered encapsulation, as well as layer-independent development by supporting cross layer documentation and debugging capabilities.",,,,,,10.1109/TVCG.2019.2920639,,2019,SciVis,Ballroom B,Thursday,Vis for Software and Systems,2022-10-24,,
openaccessvis2019.csv,VAST,TVCG,Exploranative Code Quality Documents,,"Haris Mumtaz, Shahid Latif, Fabian Beck, Daniel Weiskopf",https://arxiv.org/pdf/1907.11481.pdf,"Good code quality is a prerequisite for efficiently developing maintainable software. In this paper, we present a novel approach to generate exploranative (explanatory and exploratory) data-driven documents that report code quality in an interactive, exploratory environment. We employ a template-based natural language generation method to create textual explanations about the code quality, dependent on data from software metrics. The interactive document is enriched by different kinds of visualization, including parallel coordinates plots and scatterplots for data exploration and graphics embedded into text. We devise an interaction model that allows users to explore code quality with consistent linking between text and visualizations; through integrated explanatory text, users are taught background knowledge about code quality aspects. Our approach to interactive documents was developed in a design study process that included software engineering and visual analytics experts. Although the solution is specific to the software engineering scenario, we discuss how the concept could generalize to multivariate data and report lessons learned in a broader scope.",,,,,vimeo 360154571,,2019,2019,VAST,Ballroom B,Thursday,Vis for Software and Systems,2022-10-24,,
openaccessvis2019.csv,VAST,TVCG,GUIRO: User-Guided Matrix Reordering,,"Michael Behrisch, Tobias Schreck, Hanspeter Pfister",https://osf.io/x46gh/,"Matrix representations are one of the main established and empirically proven to be effective visualization techniques for relational (or network) data. However, matrices ?similar to node-link diagrams? are most effective if their layout reveals the underlying data topology. Given the many developed algorithms, a practical problem arises: <em>?Which matrix reordering algorithm should I choose for my dataset at hand??</em> To make matters worse, different reordering algorithms applied to the same dataset may let significantly different visual matrix patterns emerge. This leads to the question of trustworthiness and explainability of these fully automated, often heuristic, black-box processes. We present GUIRO, a Visual Analytics system that helps novices, network analysts, and algorithm designers to open the black-box. Users can investigate the usefulness and expressiveness of 70 accessible matrix reordering algorithms. For network analysts, we introduce a novel model space representation and two interaction techniques for a user-guided reordering of rows or columns, and especially groups thereof (submatrix reordering). These novel techniques contribute to the understanding of the global and local dataset topology. We support algorithm designers by giving them access to 16 reordering quality metrics and visual exploration means for comparing reordering implementations on a row/column permutation level. We evaluated GUIRO in a guided explorative user study with 12 subjects, a case study demonstrating its usefulness in a real-world scenario, and through an expert study gathering feedback on our design decisions. We found that our proposed methods help even inexperienced users to understand matrix patterns and allow a user-guided steering of reordering algorithms. GUIRO helps to increase the transparency of matrix reordering algorithms, thus helping a broad range of users to get a better insight into the complex reordering process, in turn supporting data and reordering algorithm insights.",,,,,youtube kJ74LK4jvLM,10.1109/TVCG.2019.2934300,2019,2019,VAST,Ballroom A,Tuesday,VIS Meets Machine Learning,2022-10-22,,
openaccessvis2019.csv,SciVis,TVCG,LassoNet: Deep Lasso-Selection of 3D Point Clouds,,"Zhutian Chen, Wei Zeng, ZhiGuang Yang, Lingyun Yu, Chi-Wing Fu, Huamin Qu",https://arxiv.org/pdf/1907.13538.pdf,"Selection is a fundamental task in exploratory analysis and visualization of 3D point clouds. Prior researches on selection methods were developed mainly based on heuristics such as local point density, thus limiting their applicability in general data. Specific challenges root in the great variabilities implied by point clouds (e.g., dense vs. sparse), viewpoint (e.g., occluded vs. non-occluded), and lasso (e.g., small vs. large). In this work, we introduce LassoNet, a new deep neural network for lasso selection of 3D point clouds, attempting to learn a latent mapping from viewpoint and lasso to point cloud regions. To achieve this, we couple user-target points with viewpoint and lasso information through 3D coordinate transform and naive selection, and improve the method scalability via an intention filtering and farthest point sampling. A hierarchical network is trained using a dataset with over 30K lasso-selection records on two different point cloud data. We conduct a formal user study to compare LassoNet with two state-of-the-art lasso-selection methods. The evaluations confirm that our approach improves the selection effectiveness and efficiency across different combinations of 3D point clouds, viewpoints, and lasso selections. Project Website: <a href=""https://lassonet.github.io"">https://lassonet.github.io</a>",,,,,vimeo 359999060,10.1109/TVCG.2019.2934332,2019,2019,SciVis,Ballroom A,Tuesday,VIS Meets Machine Learning,2022-10-22,,
openaccessvis2019.csv,SciVis,TVCG,TSR-TVD: Temporal Super-Resolution for Time-Varying Data Analysis and Visualization,,"Jun Han, Chaoli Wang",,,,,,,vimeo 359998660,10.1109/TVCG.2019.2934255,2019,2019,SciVis,Ballroom A,Tuesday,VIS Meets Machine Learning,2022-10-22,,
openaccessvis2019.csv,InfoVis,TVCG,GenerativeMap: Visualization and Exploration of Dynamic Density Maps via Generative Learning Model,,"Chen Chen, Changbo Wang, Xue Bai, Peiying Zhang, Chenhui Li",,,,,,,vimeo 360050049,10.1109/TVCG.2019.2934806,2019,2019,InfoVis,Ballroom A,Tuesday,VIS Meets Machine Learning,2022-10-22,,
openaccessvis2019.csv,VAST,TVCG,Facetto: Combining Unsupervised and Supervised Learning for Hierarchical Phenotype Analysis in Multi-Channel Image Data,,"Robert Krger, Johanna Beyer, Won-Dong Jang, Nam Wook Kim, Artem Sokolov, Peter Sorger, Hanspeter Pfister",https://www.biorxiv.org/content/biorxiv/early/2019/08/02/722918.full.pdf,"Facetto is a scalable visual analytics application that is used to discover single-cell phenotypes in high-dimensional multi-channel microscopy images of human tumors and tissues. Such images represent the cutting edge of digital histology and promise to revolutionize how diseases such as cancer are studied, diagnosed, and treated. Highly multiplexed tissue images are complex, comprising 10<sup>9</sup> or more pixels, 60-plus channels, and millions of individual cells. This makes manual analysis challenging and error-prone. Existing automated approaches are also inadequate, in large part, because they are unable to effectively exploit the deep knowledge of human tissue biology available to anatomic pathologists. To overcome these challenges, Facetto enables a semi-automated analysis of cell types and states. It integrates unsupervised and supervised learning into the image and feature exploration process and offers tools for analytical provenance. Experts can cluster the data to discover new types of cancer and immune cells and use clustering results to train a convolutional neural network that classifies new cells accordingly. Likewise, the output of classifiers can be clustered to discover aggregate patterns and phenotype subsets. We also introduce a new hierarchical approach to keep track of analysis steps and data subsets created by users; this assists in the identification of cell types. Users can build phenotype trees and interact with the resulting hierarchical structures of both high-dimensional feature and image spaces. We report on use-cases in which domain scientists explore various large-scale fluorescence imaging datasets. We demonstrate how Facetto assists users in steering the clustering and classification process, inspecting analysis results, and gaining new scientific insights into cancer biology.",,,,,vimeo 360156054,,2019,2019,VAST,Ballroom A,Tuesday,VIS Meets Machine Learning,2022-10-22,,
openaccessvis2019.csv,VAST,TVCG,Steering Deep Sequence Model with Prototypes,,"Yao Ming, Panpan Xu, Furui Cheng, Huamin Qu, Liu Ren",,,,,,,,,2019,2019,VAST,Ballroom A,Tuesday,VIS Meets Machine Learning,2022-10-22,,
openaccessvis2019.csv,InfoVis,TVCG,CerebroVis: Designing an Abstract yet Spatially Contextualized Cerebral Arteries Network Visualization,,"Aditeya Pandey, Harsh Shukla, Geoffrey S. Young, Lei Qin, Amir A. Zamani, Liangge Hsu, Raymond Huang, Cody Dunne, Michelle A. Borkin",https://osf.io/63y5c/,"Blood circulation in the human brain is supplied through a network of cerebral arteries. If a clinician suspects a patient has a stroke or other cerebrovascular condition, they order imaging tests. Neuroradiologists visually search the resulting scans for abnormalities. Their visual search tasks correspond to the abstract network analysis tasks of browsing and path following. To assist neuroradiologists in identifying cerebral artery abnormalities, we designed CerebroVis, a novel abstract?yet spatially contextualized?cerebral artery network visualization. In this design study, we contribute a novel framing and definition of the cerebral artery system in terms of network theory and characterize neuroradiologist domain goals as abstract visualization and network analysis tasks. Through an iterative, user-centered design process we developed an abstract network layout technique which incorporates cerebral artery spatial context. The abstract visualization enables increased domain task performance over 3D geometry representations, while including spatial context helps preserve the user?s mental map of the underlying geometry. We provide open source implementations of our network layout technique and prototype cerebral artery visualization tool. We demonstrate the robustness of our technique by successfully laying out 61 open source brain scans. We evaluate the effectiveness of our layout through a mixed methods study with three neuroradiologists. In a formative controlled experiment our study participants used CerebroVis and a conventional 3D visualization to examine real cerebral artery imaging data to identify a simulated intracranial artery stenosis. Participants were more accurate at identifying stenoses using CerebroVis (absolute risk difference 13%). A free copy of this paper, the evaluation stimuli and data, and source code are available at osf.io/e5sxt.",,,https://osf.io/2bv36/,,youtube E1-4p1V6uaw,,2019,2019,InfoVis,Ballroom A,Thursday,Visualization in Medicine,2022-10-24,,
openaccessvis2019.csv,SciVis,TVCG,Cohort-based T-SSIM Visual Computing for Radiation Therapy Prediction and Exploration,,"Andrew Wentzel, Peter Haula, Timothy Basil Luciani, Baher Elgohari, Hesham Elhalawani, Guadalupe Canahuate, David M. Vock, Clifton David Fuller, G. Elisabeta Marai",https://arxiv.org/pdf/1907.05919.pdf,"We describe a visual computing approach to radiation therapy (RT) planning, based on spatial similarity within a patient cohort. In radiotherapy for head and neck cancer treatment, dosage to organs at risk surrounding a tumor is a large cause of treatment toxicity. Along with the availability of patient repositories, this situation has lead to clinician interest in understanding and predicting RT outcomes based on previously treated similar patients. To enable this type of analysis, we introduce a novel topology-based spatial similarity measure, T-SSIM, and a predictive algorithm based on this similarity measure. We couple the algorithm with a visual steering interface that intertwines visual encodings for the spatial data and statistical results, including a novel parallel-marker encoding that is spatially aware. We report quantitative results on a cohort of 165 patients, as well as a qualitative evaluation with domain experts in radiation oncology, data management, biostatistics, and medical imaging, who are collaborating remotely.",,,,,vimeo 359999477,,2019,2019,SciVis,Ballroom A,Thursday,Visualization in Medicine,2022-10-24,,
openaccessvis2019.csv,SciVis,TVCG,DeepOrganNet: On-the-Fly Reconstruction and Visualization of 3D / 4D Lung Models from Single-View Projections by Deep Deformation Network,,"Yifan Wang, Zichun Zhong, Jing Hua",https://arxiv.org/pdf/1907.09375.pdf,"This paper introduces a deep neural network based method, i.e., DeepOrganNet, to generate and visualize fully high-fidelity 3D / 4D organ geometric models from single-view medical images with complicated background in real time. Traditional 3D / 4D medical image reconstruction requires near hundreds of projections, which cost insufferable computational time and deliver undesirable high imaging / radiation dose to human subjects. Moreover, it always needs further notorious processes to segment or extract the accurate 3D organ models subsequently. The computational time and imaging dose can be reduced by decreasing the number of projections, but the reconstructed image quality is degraded accordingly. To our knowledge, there is no method directly and explicitly reconstructing multiple 3D organ meshes from a single 2D medical grayscale image on the fly. Given single-view 2D medical images, e.g., 3D / 4D-CT projections or X-ray images, our end-to-end DeepOrganNet framework can efficiently and effectively reconstruct 3D / 4D lung models with a variety of geometric shapes by learning the smooth deformation fields from multiple templates based on a trivariate tensor-product deformation technique, leveraging an informative latent descriptor extracted from input 2D images. The proposed method can guarantee to generate high-quality and high-fidelity manifold meshes for 3D / 4D lung models; while, all current deep learning based approaches on the shape reconstruction from a single image cannot. The major contributions of this work are to accurately reconstruct the 3D organ shapes from 2D single-view projection, significantly improve the procedure time to allow on-the-fly visualization, and dramatically reduce the imaging dose for human subjects. Experimental results are evaluated and compared with the traditional reconstruction method and the state-of-the-art in deep learning, by using extensive 3D and 4D examples, including both synthetic phantom and real patient datasets. The efficiency of the proposed method shows that it only needs several milliseconds to generate organ meshes with 10K vertices, which has a great potential to be used in real-time image guided radiation therapy (IGRT).",,,,,vimeo 359999320,,2019,2019,SciVis,Ballroom A,Thursday,Visualization in Medicine,2022-10-24,,
openaccessvis2019.csv,SciVis,TVCG,Temporal Views of Flattened Mitral Valve Geometries,,"Pepe Eulzer, Sandy Engelhardt, Nils Lichtenberg, Raffaele de Simone, Kai Lawonn",,,,,,,vimeo 359999188,10.1109/TVCG.2019.2934337,2019,2019,SciVis,Ballroom A,Thursday,Visualization in Medicine,2022-10-24,,
openaccessvis2019.csv,VAST,TVCG,Motion Browser: Visualizing and Understanding Complex Upper Limb Movement Under Obstetrical Brachial Plexus Injuries,,"Gromit Yeuk-Yin Chan, Luis Gustavo Nonato, Alice Chu, Preeti Raghavan, Viswanath Aluru, Claudio Silva",https://arxiv.org/pdf/1907.09146.pdf,"The brachial plexus is a complex network of peripheral nerves that enables sensing from and control of the movements of the arms and hand. Nowadays, the coordination between the muscles to generate simple movements is still not well understood, hindering the knowledge of how to best treat patients with this type of peripheral nerve injury. To acquire enough information for medical data analysis, physicians conduct motion analysis assessments with patients to produce a rich dataset of electromyographic signals from multiple muscles recorded with joint movements during real-world tasks. However, tools for the analysis and visualization of the data in a succinct and interpretable manner are currently not available. Without the ability to integrate, compare, and compute multiple data sources in one platform, physicians can only compute simple statistical values to describe patient?s behavior vaguely, which limits the possibility to answer clinical questions and generate hypotheses for research. To address this challenge, we have developed MOTION BROWSER, an interactive visual analytics system which provides an efficient framework to extract and compare muscle activity patterns from the patient?s limbs and coordinated views to help users analyze muscle signals, motion data, and video information to address different tasks. The system was developed as a result of a collaborative endeavor between computer scientists and orthopedic surgery and rehabilitation physicians. We present case studies showing physicians can utilize the information displayed to understand how individuals coordinate their muscles to initiate appropriate treatment and generate new hypotheses for future research.",,,,,vimeo 360155635,,2019,2019,VAST,Ballroom A,Thursday,Visualization in Medicine,2022-10-24,,
openaccessvis2019.csv,SciVis,TVCG,Void-and-Cluster Sampling of Large Scattered Data and Trajectories,,"Tobias Rapp, Christoph Peters, Carsten Dachsbacher",https://arxiv.org/pdf/1907.05073.pdf,"We propose a data reduction technique for scattered data based on statistical sampling. Our void-and-cluster sampling technique finds a representative subset that is optimally distributed in the spatial domain with respect to the blue noise property. In addition, it can adapt to a given density function, which we use to sample regions of high complexity in the multivariate value domain more densely. Moreover, our sampling technique implicitly defines an ordering on the samples that enables progressive data loading and a continuous level-of-detail representation. We extend our technique to sample time-dependent trajectories, for example pathlines in a time interval, using an efficient and iterative approach. Furthermore, we introduce a local and continuous error measure to quantify how well a set of samples represents the original dataset. We apply this error measure during sampling to guide the number of samples that are taken. Finally, we use this error measure and other quantities to evaluate the quality, performance, and scalability of our algorithm.",,,,,vimeo 359999170,10.1109/TVCG.2019.2934335,2019,2019,SciVis,Ballroom B,Thursday,Volume Visualization,2022-10-24,,
openaccessvis2019.csv,TVCG,TVCG,FeatureLego: Volume Exploration Using Exhaustive Clustering of Super-Voxels,,"Shreeraj Jadhav, Saad Nadeem, Arie Kaufman",https://arxiv.org/pdf/1810.05220.pdf,"We present a volume exploration framework, FeatureLego, that uses a novel voxel clustering approach for efficient selection of semantic features. We partition the input volume into a set of compact super-voxels that represent the finest selection granularity. We then perform an exhaustive clustering of these super-voxels using a graph-based clustering method. Unlike the prevalent brute-force parameter sampling approaches, we propose an efficient algorithm to perform this exhaustive clustering. By computing an exhaustive set of clusters, we aim to capture as many boundaries as possible and ensure that the user has sufficient options for efficiently selecting semantically relevant features. Furthermore, we merge all the computed clusters into a single tree of meta-clusters that can be used for hierarchical exploration. We implement an intuitive user-interface to interactively explore volumes using our clustering approach. Finally, we show the effectiveness of our framework on multiple real-world datasets of different modalities.",,,,,vimeo 364568860,,,2019,SciVis,Ballroom B,Thursday,Volume Visualization,2022-10-24,,
openaccessvis2019.csv,TVCG,TVCG,Interactive Visualization and On-Demand Processing of Large Volume Data: A Fully GPU-Based Out-Of-Core Approach,,"Jonathan Sarton, Nicolas Courilleau, Yannick Remion, Laurent Lucas",https://hal.univ-reims.fr/hal-01705431/document,"In a wide range of scientific fields, 3D datasets production capabilities have widely evolved in recent years, especially with the rapid increase in their size. As a result, many large-scale applications, including visualization or processing, have become challenging to address. A solution to this issue lies in providing out-of-core algorithms specifically designed to handle datasets significantly larger than memory. In this article, we present a new approach that extends the broad interactive addressing principles already established in the field of out-of-core volume rendering on GPUs to allow on-demand processing during the visualization stage. We propose a pipeline designed to manage data as regular 3D grids regardless of the underlying application. It relies on a caching approach with a virtual memory addressing system coupled to an efficient parallel management on GPU to provide efficient access to data in interactive time. It allows any visualization or processing application to leverage the flexibility of its structure by managing multi-modality datasets. Furthermore, we show that our system delivers good performance on a single standard PC with low memory budget on the GPU.",,,,,vimeo 364569226,10.1109/TVCG.2019.2912752,,2019,SciVis,Ballroom B,Thursday,Volume Visualization,2022-10-24,,
openaccessvis2019.csv,TVCG,TVCG,"Scientific visualization, opacity optimization, Fourier approximation",,"Irene Baeza Rojo, Markus Gross, Tobias Gnther",,,,,,,,,,2019,SciVis,Ballroom B,Thursday,Volume Visualization,2022-10-24,,
openaccessvis2019.csv,TVCG,TVCG,Ray-based Exploration of Large Time-varying Volume Data Using Proxy Per-ray Distributions,,"Ko-Chih Wang, Tzu-Hsuan Wei, Shareef Naeem, Han-Wei Shen",,,,,,,vimeo 364569304,,,2019,SciVis,Ballroom B,Thursday,Volume Visualization,2022-10-24,,
openaccessvis2019.csv,InfoVis,TVCG,The Perceptual Proxies of Visual Comparison,,"Nicole Jardine, Brian David Ondov, Niklas Elmqvist, Steven Franconeri",https://osf.io/ykmt7,"Perceptual tasks in visualizations often involve comparisons. Of two sets of values depicted in two charts, which set had values that were the highest overall? Which had the widest range? Prior empirical work found that the performance on different visual comparison tasks (e.g., ?biggest delta?, ?biggest correlation?) varied widely across different combinations of marks and spatial arrangements. In this paper, we expand upon these combinations in an empirical evaluation of two new comparison tasks: the ?biggest mean? and ?biggest range? between two sets of values. We used a staircase procedure to titrate the difficulty of the data comparison to assess which arrangements produced the most precise comparisons for each task. We find visual comparisons of biggest mean and biggest range are supported by some chart arrangements more than others, and that this pattern is substantially different from the pattern for other tasks. To synthesize these dissonant findings, we argue that we must understand which features of a visualization are actually used by the human visual system to solve a given task. We call these perceptual proxies. For example, when comparing the means of two bar charts, the visual system might use a ?Mean length? proxy that isolates the actual lengths of the bars and then constructs a true average across these lengths. Alternatively, it might use a ?Hull Area? proxy that perceives an implied hull bounded by the bars of each chart and then compares the areas of these hulls. We propose a series of potential proxies across different tasks, marks, and spatial arrangements. Simple models of these proxies can be empirically evaluated for their explanatory power by matching their performance to human performance across these marks, arrangements, and tasks. We use this process to highlight candidates for perceptual proxies that might scale more broadly to explain performance in visual comparison.",,,https://osf.io/uenzd,,vimeo 360050277,10.1109/TVCG.2019.2934786,2019,2019,InfoVis,Ballroom C,Thursday,What's the Difference?,2022-10-24,,
openaccessvis2019.csv,InfoVis,TVCG,BarcodeTree: Scalable Comparison of Multiple Hierarchies,,"Guozheng Li, Yu Zhang, Yu Dong, Jie Liang, Jinson Zhang, Jinsong Wang, Michael McGuffin, Xiaoru Yuan",,,,,,,vimeo 360050493,,2019,2019,InfoVis,Ballroom C,Thursday,What's the Difference?,2022-10-24,,
openaccessvis2019.csv,InfoVis,TVCG,Comparison of Radial and Linear charts for Visualizing Daily Patterns,,"Manuela Waldner, Alexandra Diehl, Denis Gracanin, Rainer Splechtna, Claudio Delrieux, Kresimir Matkovic",,,,,,,vimeo 360050294,,2019,2019,InfoVis,Ballroom C,Thursday,What's the Difference?,2022-10-24,,
openaccessvis2019.csv,InfoVis,TVCG,Separating the wheat from the chaff: Comparative visual cues for reliable diagnostics of competing models,,"Aritra Dasgupta, Hong Wang, Nancy D O'Brien, Susannah Marie Burrows",,,,,,,,,2019,2019,InfoVis,Ballroom C,Thursday,What's the Difference?,2022-10-24,,
openaccessvis2019.csv,TVCG,TVCG,Aggregated Dendrograms for Visual Comparison Between Many Phylogenetic Trees,,"Zipeng Liu, Shing Hei Zhan, Tamara Munzner",,,,,,,vimeo 364568553,10.1109/TVCG.2019.2898186,,2019,InfoVis,Ballroom C,Thursday,What's the Difference?,2022-10-24,,
openaccessvis2019.csv,VAST,TVCG,STBins: Visual Tracking and Comparison of Multiple Data Sequences using Temporal Binning,,"Ji Qi, Vincent Bloemen, Shihan Wang, Jarke van Wijk, Huub van de Wetering",,,,,,,vimeo 360155660,,2019,2019,VAST,Ballroom C,Thursday,What's the Difference?,2022-10-24,,
openaccessvis2019.csv,TVCG,TVCG,LDA Ensembles for Interactive Exploration and Categorization of Behaviors,,"Siming Chen, Natalia Andrienko, Gennady Andrienko, Linara Adilova, Jeremie Barlet, Joerg Kindermann, Phong H. Nguyen, Olivier Thonnard, Cagatay Turkay",http://openaccess.city.ac.uk/id/eprint/21875/1/LDA_Ensembles_for_Interactive_Exploration_and_Categorization_of_Behaviors.pdf,"We define <strong>behavior</strong> as a set of <strong>actions</strong> performed by some actor during a period of time. We consider the problem of analyzing a large collection of behaviors by multiple actors, more specifically, identifying typical behaviors and spotting anomalous behaviors. We propose an approach leveraging topic modeling techniques ? LDA (Latent Dirichlet Allocation) Ensembles ? to represent categories of typical behaviors by topics that are obtained through topic modeling a behavior collection. When such methods are applied to text in natural languages, the quality of the extracted topics are usually judged based on the semantic relatedness of the terms pertinent to the topics. This criterion, however, is not necessarily applicable to topics extracted from non-textual data, such as action sets, since relationships between actions may not be obvious. We have developed a suite of visual and interactive techniques supporting the construction of an appropriate combination of topics based on other criteria, such as distinctiveness and coverage of the behavior set. Two case studies on analyzing operation behaviors in the security management system and visiting behaviors in an amusement park, and the expert evaluation of the first case study demonstrate the effectiveness of our approach.",,,,,vimeo 364568366,10.1109/TVCG.2019.2904069,,2019,VAST,Ballroom B,Thursday,Words & Documents,2022-10-24,,
openaccessvis2019.csv,InfoVis,TVCG,ShapeWordle: Tailoring Wordles using Shape-aware Archimedean Spirals,,"Yunhai Wang, Xiaowei Chu, Kaiyi Zhang, Chen Bao, Xiaotong Li, Jian Zhang, Christophe Hurter, Chi-Wing Fu, Oliver Deussen",,,,,,,vimeo 360050251,,2019,2019,InfoVis,Ballroom B,Thursday,Words & Documents,2022-10-24,,
openaccessvis2019.csv,VAST,TVCG,Semantic Concept Spaces: Guided Topic Model Refinement using Word-Embedding Projections,,"Mennatallah El-Assady, Rebecca Kehlbeck, Christopher Collins, Daniel Keim, Oliver Deussen",https://arxiv.org/pdf/1908.00475.pdf,"We present a framework that allows users to incorporate the semantics of their domain knowledge for topic model refinement while remaining model-agnostic. Our approach enables users to (1) understand the semantic space of the model, (2) identify regions of potential conflicts and problems, and (3) readjust the semantic relation of concepts based on their understanding, directly influencing the topic modeling. These tasks are supported by an interactive visual analytics workspace that uses word-embedding projections to define concept regions which can then be refined. The user-refined concepts are independent of a particular document collection and can be transferred to related corpora. All user interactions within the concept space directly affect the semantic relations of the underlying vector space model, which, in turn, change the topic modeling. In addition to direct manipulation, our system guides the users? decisionmaking process through recommended interactions that point out potential improvements. This targeted refinement aims at minimizing the feedback required for an efficient human-in-the-loop process. We confirm the improvements achieved through our approach in two user studies that show topic model quality improvements through our visual knowledge externalization and learning process.",,,,,vimeo 360154204,10.1109/TVCG.2019.2934654,2019,2019,VAST,Ballroom B,Thursday,Words & Documents,2022-10-24,,
openaccessvis2019.csv,VAST,VAST,VIANA: Visual Interactive Annotation of Argumentation,,"Fabian Sperrle, Rita Sevastjanova, Rebecca Kehlbeck, Mennatallah El-Assady",https://arxiv.org/pdf/1907.12413.pdf,"Argumentation Mining addresses the challenging tasks of identifying boundaries of argumentative text fragments and extracting their relationships. Fully automated solutions do not reach satisfactory accuracy due to their insufficient incorporation of semantics and domain knowledge. Therefore, experts currently rely on time-consuming manual annotations. In this paper, we present a visual analytics system that augments the manual annotation process by automatically suggesting which text fragments to annotate next. The accuracy of those suggestions is improved over time by incorporating linguistic knowledge and language modeling to learn a measure of argument similarity from user interactions. Based on a long-term collaboration with domain experts, we identify and model five high-level analysis tasks. We enable close reading and note-taking, annotation of arguments, argument reconstruction, extraction of argument relations, and exploration of argument graphs. To avoid context switches, we transition between all views through seamless morphing, visually anchoring all text- and graph-based layers. We evaluate our system with a two-stage expert user study based on a corpus of presidential debates. The results show that experts prefer our system over existing solutions due to the speedup provided by the automatic suggestions and the tight integration between text and graph views.",https://viana.lingvis.io/,,,,vimeo 360154233,,2019,2019,VAST,Ballroom B,Thursday,Words & Documents,2022-10-24,,
openaccessvis2019.csv,TVCG,TVCG,Topic-based Exploration and Embedded Visualizations for Research Idea Generation,,"Hua Guo, David H. Laidlaw",,,,,,,vimeo 364568027,10.1109/TVCG.2018.2873011,,2019,VAST,Ballroom B,Thursday,Words & Documents,2022-10-24,,
openaccessvis2019.csv,TVCG,TVCG,An Evaluation of Semantically Grouped Word Cloud Designs,,"Marti A. Hearst, Emily Pedersen, Lekha Patil, Elsie Lee, Paul Laskowski, Steven Franconeri",https://osf.io/3eutf/,"Word clouds continue to be a popular tool for summarizing textual information, despite their well-documented deficiencies for analytic tasks. Much of their popularity rests on their playful visual appeal. In this paper, we present the results of a series of controlled experiments that show that layouts in which words are arranged into semantically and visually distinct zones are more effective for understanding the underlying topics than standard word cloud layouts. White space separators and/or spatially grouped color coding led to significantly stronger understanding of the underlying topics compared to a standard Wordle layout, while simultaneously scoring higher on measures of aesthetic appeal. This work is an advance on prior research on semantic layouts for word clouds because that prior work has either not ensured that the different semantic groupings are visually or semantically distinct, or has not performed usability studies. An additional contribution of this work is the development of a dataset for a semantic category identification task that can be used for replication of these results or future evaluations of word cloud designs.",,,,,vimeo 364568578,10.1109/TVCG.2019.2904683,,2019,InfoVis,Ballroom B,Thursday,Words & Documents,2022-10-24,,
openaccessvis2019.csv,VAST,TVCG,explAIner: A Visual Analytics Framework for Interactive and Explainable Machine Learning,,"Thilo Spinner, Udo Schlegel, Hanna Schaefer, Mennatallah El-Assady",https://arxiv.org/pdf/1908.00087.pdf,"We propose a framework for interactive and explainable machine learning that enables users to (1) understand machine learning models; (2) diagnose model limitations using different explainable AI methods; as well as (3) refine and optimize the models. Our framework combines an iterative XAI pipeline with eight global monitoring and steering mechanisms, including quality monitoring, provenance tracking, model comparison, and trust building. To operationalize the framework, we present explAIner, a visual analytics system for interactive and explainable machine learning that instantiates all phases of the suggested pipeline within the commonly used TensorBoard environment. We performed a user-study with nine participants across different expertise levels to examine their perception of our workflow and to collect suggestions to fill the gap between our system and framework. The evaluation confirms that our tightly integrated system leads to an informed machine learning process while disclosing opportunities for further extensions.",https://explainer.ai/,,,,vimeo 360154764,,2019,2019,VAST,Ballroom A,Thursday,XAI and Fairness,2022-10-24,,
openaccessvis2019.csv,VAST,TVCG,Explaining Vulnerabilities to Adversarial Machine Learning through Visual Analytics,,"Yuxin Ma, Tiankai Xie, Jundong Li, Ross Maciejewski",https://arxiv.org/pdf/1907.07296.pdf,"Machine learning models are currently being deployed in a variety of real-world applications where model predictions are used to make decisions about healthcare, bank loans, and numerous other critical tasks. As the deployment of artificial intelligence technologies becomes ubiquitous, it is unsurprising that adversaries have begun developing methods to manipulate machine learning models to their advantage. While the visual analytics community has developed methods for opening the black box of machine learning models, little work has focused on helping the user understand their model vulnerabilities in the context of adversarial attacks. In this paper, we present a visual analytics framework for explaining and exploring model vulnerabilities to adversarial attacks. Our framework employs a multi-faceted visualization scheme designed to support the analysis of data poisoning attacks from the perspective of models, data instances, features, and local structures. We demonstrate our framework through two case studies on binary classifiers and illustrate model vulnerabilities with respect to varying attack strategies.",,,,,vimeo 360154813,,2019,2019,VAST,Ballroom A,Thursday,XAI and Fairness,2022-10-24,,
openaccessvis2019.csv,VAST,TVCG,FairSight: Visual Analytics for Fairness in Decision Making,,"Yongsu Ahn, Yu-Ru Lin",https://arxiv.org/pdf/1908.00176.pdf,"Data-driven decision making related to individuals has become increasingly pervasive, but the issue concerning the potential discrimination has been raised by recent studies. In response, researchers have made efforts to propose and implement fairness measures and algorithms, but those efforts have not been translated to the real-world practice of data-driven decision making. As such, there is still an urgent need to create a viable tool to facilitate fair decision making. We propose FairSight, a visual analytic system to address this need; it is designed to achieve different notions of fairness in ranking decisions through identifying the required actions ? understanding, measuring, diagnosing and mitigating biases ? that together lead to fairer decision making. Through a case study and user study, we demonstrate that the proposed visual analytic and diagnostic modules in the system are effective in understanding the fairness-aware decision pipeline and obtaining more fair outcomes.",,,,,vimeo 360155342,10.1109/TVCG.2019.2934262,2019,2019,VAST,Ballroom A,Thursday,XAI and Fairness,2022-10-24,,
openaccessvis2019.csv,VAST,TVCG,Summit: Scaling Deep Learning Interpretability by Visualizing Activation and Attribution Summarizations,,"Fred Hohman, Haekyu Park, Caleb Robinson, Duen Horng Chau",https://arxiv.org/pdf/1904.02323.pdf,"Deep learning is increasingly used in decision-making tasks. However, understanding how neural networks produce final predictions remains a fundamental challenge. Existing work on interpreting neural network predictions for images often focuses on explaining predictions for single images or neurons. As predictions are often computed from millions of weights that are optimized over millions of images, such explanations can easily miss a bigger picture. We present SUMMIT, an interactive system that scalably and systematically summarizes and visualizes what features a deep learning model has learned and how those features interact to make predictions. SUMMIT introduces two new scalable summarization techniques: (1) activation aggregation discovers important neurons, and (2) neuron-influence aggregation identifies relationships among such neurons. SUMMIT combines these techniques to create the novel attribution graph that reveals and summarizes crucial neuron associations and substructures that contribute to a model?s outcomes. SUMMIT scales to large data, such as the ImageNet dataset with 1.2M images, and leverages neural network feature visualization and dataset examples to help users distill large, complex neural network models into compact, interactive visualizations. We present neural network exploration scenarios where SUMMIT helps us discover multiple surprising insights into a prevalent, large-scale image classifier?s learned representations and informs future neural network architecture design. The SUMMIT visualization runs in modern web browsers and is open-sourced.",http://fredhohman.com/summit,,,,vimeo 360154453,10.1109/TVCG.2019.2934659,2019,2019,VAST,Ballroom A,Thursday,XAI and Fairness,2022-10-24,,
openaccessvis2019.csv,VAST,VAST,FairVis: Visual Analytics for Discovering Intersectional Bias in Machine Learning,,"?ngel Alexander Cabrera, Will Epperson, Fred Hohman, Minsuk Kahng, Jamie Morgenstern, Duen Horng Chau",https://arxiv.org/pdf/1904.05419.pdf,"The growing capability and accessibility of machine learning has led to its application to many real-world domains and data about people. Despite the benefits algorithmic systems may bring, models can reflect, inject, or exacerbate implicit and explicit societal biases into their outputs, disadvantaging certain demographic subgroups. Discovering which biases a machine learning model has introduced is a great challenge, due to the numerous definitions of fairness and the large number of potentially impacted subgroups. We present FAIRVIS, a mixed-initiative visual analytics system that integrates a novel subgroup discovery technique for users to audit the fairness of machine learning models. Through FAIRVIS, users can apply domain knowledge to generate and investigate known subgroups, and explore suggested and similar subgroups. FAIRVIS?s coordinated views enable users to explore a high-level overview of subgroup performance and subsequently drill down into detailed investigation of specific subgroups. We show how FAIRVIS helps to discover biases in two real datasets used in predicting income and recidivism. As a visual analytics system devoted to discovering bias in machine learning, FAIRVIS demonstrates how interactive visualization may help data scientists and the general public understand and create more equitable algorithmic systems.",https://poloclub.github.io/FairVis/,,,,vimeo 360155233,,2019,2019,VAST,Ballroom A,Thursday,XAI and Fairness,2022-10-24,,
openaccessvis2019.csv,TVCG,TVCG,Visual Genealogy of Deep Neural Networks,,"Qianwen Wang, Jun Yuan, Shuxin Chen, Hang Su, Huamin Qu, Shixia Liu",,,,,,,vimeo 364568338,10.1109/TVCG.2019.2921323,,2019,VAST,Ballroom A,Thursday,XAI and Fairness,2022-10-24,,
openaccessvis2019.csv,CG&A,CG&A,A Walk Among the Data: Exploration and Anthropomorphism in Immersive Unit Visualizations,,"Alexander Ivanov, Kurtis Danyluk, Christian Jacob, Wesley Willett",,,,,,,vimeo 359999645,,,2019,CG&A,Room 8+15,Wednesday,CG&A Session 1,2022-10-23,,
openaccessvis2019.csv,CG&A,CG&A,Immersive Analytics Lessons from the Electronic Visualization Laboratory: a 25 Year Perspective,,"G. Elisabeta Marai, Jason Leigh, Andrew Johnson",,,,,,,vimeo 359999721,,,2019,CG&A,Room 8+15,Wednesday,CG&A Session 1,2022-10-23,,
openaccessvis2019.csv,CG&A,CG&A,Comfortable Immersive Analytics with the VirtualDesk Metaphor,,"Jorge A. Wagner Filho, Carla M. D. S. Freitas, Luciana Nedel",,,,,,,vimeo 359999785,,,2019,CG&A,Room 8+15,Wednesday,CG&A Session 1,2022-10-23,,
openaccessvis2019.csv,CG&A,CG&A,Augmented Reality Graph Visualizations - Investigation of Visual Styles in 3D Node-Link Diagrams,,"Wolfgang Bschel, Stefan Vogt, Raimund Dachselt",,,,,,,vimeo 359999817,,,2019,CG&A,Room 8+15,Wednesday,CG&A Session 1,2022-10-23,,
openaccessvis2019.csv,CG&A,CG&A,Visualization and the Digital Humanities:,,"Adam James Bradley, Mennatallah El-Assady, Katharine Coles, Eric Alexander, Min Chen, Christopher Collins, Stefan J„nicke, David Joseph Wrisley",https://ora.ox.ac.uk/objects/uuid:d89c5ef6-84f3-4b6d-9064-0c6e419e1a35/download_file?file_format=pdf&safe_filename=%255BVIS4DH%255D%2BCG%2526A_Revisions_Aug_1_2018.pdf&type_of_work=Journal+article,"For the past two years, researchers from the visualization community and the digital humanities have come together at the IEEE VIS conference to discuss how both disciplines can work together to push research goals in their respective disciplines. This process has been both fruitful and challenging, bringing to light how different knowledge is created in the sciences and the humanities, but also how methodological differences can be traversed to produce truly interdisciplinary work. In this paper, we present our experiences as a group and our individual experiences as humanists and computer scientists. While we explore a broad spectrum of ideas, our goals are strikingly similar: to understand the processes and motivations of each other?s work better as a way of increasing self-reflection on our own.",,,,,,,,2019,CG&A,Room 8+15,Wednesday,CG&A Session 1,2022-10-23,,
openaccessvis2019.csv,CG&A,CG&A,Graphoto: Aesthetically Pleasing Charts for Casual Information Visualization,,"Ji Hwan Park, Arie Kaufman, Klaus Mueller",,,,,,,vimeo 359999850,,,2019,CG&A,Room 8+15,Wednesday,CG&A Session 1,2022-10-23,,
openaccessvis2019.csv,CG&A,CG&A,VitalVizor: A Visual Analytics System for Studying Urban Vitality,,"Wei Zeng, Yu Ye",,,,,,,vimeo 359999892,,,2019,CG&A,Room 2+3,Thursday,CG&A Session 2,2022-10-24,,
openaccessvis2019.csv,CG&A,CG&A,Designing Effective Visual Interactive Systems despite Sparse Availability of Domain Information,,"Benjamin Karer, Alina Freund, Michael Horst, Inga Scheler, Thomas Kossurok, Franz-Josef Brandt",,,,,,,vimeo 359999909,,,2019,CG&A,Room 2+3,Thursday,CG&A Session 2,2022-10-24,,
openaccessvis2019.csv,CG&A,CG&A,Mapping and Visualizing Deep-Learning Urban Beautification,,"Tobias Kauer, Sagar Joglekar, Miriam Redi, Luca Maria Aiello, Daniele Quercia",,,,,,,vimeo 359999969,,,2019,CG&A,Room 2+3,Thursday,CG&A Session 2,2022-10-24,,
openaccessvis2019.csv,CG&A,CG&A,RNNbow: Visualizing Learning Via Backpropagation Gradients in RNNs,,"Dylan Cashman, GeneviŠve Patterson, Abigail Mosca, Nathan Watts, Shannon Robinson, Remco Chang",,,,,,,vimeo 359999999,,,2019,CG&A,Room 2+3,Thursday,CG&A Session 2,2022-10-24,,
openaccessvis2019.csv,CG&A,CG&A,PUMA-V: Optimizing Parallel Code Performance Through Interactive Visualization,,"Eric Papenhausen, M. Harper Langston, Benoit Meister, Richard A. Lethin, Klaus Mueller",,,,,,,vimeo 360000013,,,2019,CG&A,Room 2+3,Thursday,CG&A Session 2,2022-10-24,,
openaccessvis2019.csv,CG&A,CG&A,Cross-Platform Ubiquitous Volume Rendering Using Programmable Shaders in VTK for Scientific and Medical Visualization,,"Aashish Chaudhary, Sankhesh J. Jhaveri, Alvaro Sanchez, Lisa S. Avila, Kenneth M. Martin, Allison Vacanti, Marcus D. Hanwell, Will Schroeder",,,,,,,vimeo 360000042,,,2019,CG&A,Room 2+3,Thursday,CG&A Session 2,2022-10-24,,
openaccessvis2019.csv,Short,Short,Graph-assisted Visualization of Microvascular Networks,,"Pavel Govyadinov, Tasha Womack, Jason Eriksen, David Mayerich, Guoning Chen",,,,,,,vimeo 363452229,,,2019,Short,Room 1,Tuesday,Short Papers: Novel Interfaces,2022-10-22,,
openaccessvis2019.csv,Short,Short,Learning Vis Tools: Teaching Data Visualization Tutorials,,"Leo Yu-Ho Lo, Yao Ming, Huamin Qu",https://arxiv.org/pdf/1907.08796.pdf,"Teaching and advocating data visualization are among the most important activities in the visualization community. With growing interest in data analysis from business and science professionals, data visualization courses attract students across different disciplines. However, comprehensive visualization training requires students to have a certain level of proficiency in programming, a requirement that imposes challenges on both teachers and students. With recent developments in visualization tools, we have managed to overcome these obstacles by teaching a wide range of visualization and supporting tools. Starting with GUI-based visualization tools and data analysis with Python, students put visualization knowledge into practice with increasing amounts of programming. At the end of the course, students can design and implement visualizations with D3 and other programming-based visualization tools. Throughout the course, we continuously collect student feedback and refine the teaching materials. This paper documents our teaching methods and considerations when designing the teaching materials.",https://github.com/leoyuholo/learning-vis-tools,,,,vimeo 363041257,,,2019,Short,Room 1,Tuesday,Short Papers: Novel Interfaces,2022-10-22,,
openaccessvis2019.csv,Short,Short,Sociotechnical Considerations for Accessible Visualization Design,,"Alan Lundgard, Crystal Lee, Arvind Satyanarayan",https://arxiv.org/ftp/arxiv/papers/1909/1909.05118.pdf,"Accessibility?the process of designing for people with disabilities (PWD)?is an important but under-explored challenge in the visualization research community. Without careful attention, and if PWD are not included as equal participants throughout the process, there is a danger of perpetuating a vision-first approach to accessible design that marginalizes the lived experience of disability (e.g., by creating overly simplistic ?sensory translations? that map visual to non-visual modalities in a one-to-one fashion). In this paper, we present a set of sociotechnical considerations for research in accessible visualization design, drawing on literature in disability studies, tactile information systems, and participatory methods. We identify that using state-of-the-art technologies may introduce more barriers to access than they remove, and that expectations of research novelty may not produce outcomes well-aligned with the needs of disability communities. Instead, to promote a more inclusive design process, we emphasize the importance of clearly communicating goals, following existing accessibility guidelines, and treating PWD as equal participants who are compensated for their specialized skills. To illustrate how these considerations can be applied in practice, we discuss a case study of an inclusive design workshop held in collaboration with the Perkins School for the Blind.",,,,,vimeo 363041501,,,2019,Short,Room 1,Tuesday,Short Papers: Novel Interfaces,2022-10-22,,
openaccessvis2019.csv,Short,Short,How Expensive is the Wine?Toward Interface Defaults for Vague Modifiers in Natural Language Interfaces for Visual Analysis,,"Marti Hearst, Melanie Tory, Vidya Setlur",,,,,,,,,,2019,Short,Room 1,Tuesday,Short Papers: Novel Interfaces,2022-10-22,,
openaccessvis2019.csv,Short,Short,VisWall: Visual Data Exploration using Direct Combination on Large Touch Displays,,"Mallika Agarwal, Arjun Srinivasan, John Stasko",,,,,,,vimeo 363042417,,,2019,Short,Room 1,Tuesday,Short Papers: Novel Interfaces,2022-10-22,,
openaccessvis2019.csv,Short,Short,EasyPZ.js: Interaction Binding For Pan and Zoom Visualizations,,"Michail Schwab, James Tompkin, Jeff Huang, Michelle A. Borkin",,,,,,,vimeo 363041807,,,2019,Short,Room 1,Tuesday,Short Papers: Novel Interfaces,2022-10-22,,
openaccessvis2019.csv,Short,Short,Would You Like A Chart With That? Incorporating Visualizations into Conversational Interfaces,,"Marti Hearst, Melanie Tory",,,,,,,vimeo 363042343,,,2019,Short,Room 1,Tuesday,Short Papers: Novel Interfaces,2022-10-22,,
openaccessvis2019.csv,Short,Short,Visualization Assessment: A Machine Learning Approach,,"Xin Fu, Yun Wang, Haoyu Dong, Weiwei Cui, Haidong Zhang",,,,,,,vimeo 363041569,,,2019,Short,Room 1,Wednesday,VIS Meets Machine Learning (Short),2022-10-23,,
openaccessvis2019.csv,Short,Short,A Deep Learning Approach to Selecting Representative Time Steps for Time-Varying Multivariate Data,,"William P. Porter, Yunhao Xing, Blaise R von Ohlen, Jun Han, Chaoli Wang",,,,,,,vimeo 363040865,,,2019,Short,Room 1,Wednesday,VIS Meets Machine Learning (Short),2022-10-23,,
openaccessvis2019.csv,Short,Short,Disentangled Representation of Data Distributions in Scatterplots,,"Jaemin Jo, Jinwook Seo",,,,,,,vimeo 363042207,,,2019,Short,Room 1,Wednesday,VIS Meets Machine Learning (Short),2022-10-23,,
openaccessvis2019.csv,Short,Short,Toward Perception-based Evaluation of Clustering Techniques for Visual Analytics,,"Micha‰l Aupetit, Michael Sedlmair, Mostafa M. Abbas, Halima Bensmail",,  ,,,,,vimeo 363452065,,,2019,Short,Room 1,Wednesday,VIS Meets Machine Learning (Short),2022-10-23,,
openaccessvis2019.csv,Short,Short,SANVis: Visual Analytics for Understanding Self Attention Networks,,"Cheonbok Park, Inyoup Na, Yongjang Jo, Sungbok Shin, Yoo Jaehyo, Bum Chul Kwon, Jian Zhao, Hyungjong Noh, Yeonsoo Lee, Jaegul Choo",https://arxiv.org/pdf/1909.09595.pdf,"Attention networks, a deep neural network architecture inspired by humans? attention mechanism, have seen significant success in image captioning, machine translation, and many other applications. Recently, they have been further evolved into an advanced approach called multi-head self-attention networks, which can encode a set of input vectors, e.g., word vectors in a sentence, into another set of vectors. Such encoding aims at simultaneously capturing diverse syntactic and semantic features within a set, each of which corresponds to a particular attention head, forming altogether multi-head attention. Meanwhile, the increased model complexity prevents users from easily understanding and manipulating the inner workings of models. To tackle the challenges, we present a visual analytics system called SANVis, which helps users understand the behaviors and the characteristics of multi-head self-attention networks. Using a state-of-the-art self-attention model called Transformer, we demonstrate usage scenarios of SANVis in machine translation tasks. Our system is available at http://short.sanvis.org.",http://short.sanvis.org/,,,,vimeo 363452350,,,2019,Short,Room 1,Wednesday,VIS Meets Machine Learning (Short),2022-10-23,,
openaccessvis2019.csv,Short,Short,TeleGam: Combining Visualization and Verbalization for Interpretable Machine Learning,,"Fred Hohman, Arjun Srinivasan, Steven Drucker",https://osf.io/p3wnm/,"While machine learning (ML) continues to find success in solving previously-thought hard problems, interpreting and exploring ML models remains challenging. Recent work has shown that visualizations are a powerful tool to aid debugging, analyzing, and interpreting ML models. However, depending on the complexity of the model (e.g., number of features), interpreting these visualizations can be difficult and may require additional expertise. Alternatively, textual descriptions, or verbalizations, can be a simple, yet effective way to communicate or summarize key aspects about a model, such as the overall trend in a model?s predictions or comparisons between pairs of data instances. With the potential benefits of visualizations and verbalizations in mind, we explore how the two can be combined to aid ML interpretability. Specifically, we present a prototype system, TeleGam, that demonstrates how visualizations and verbalizations can collectively support interactive exploration of ML models, for example, generalized additive models (GAMs). We describe TeleGam?s interface and underlying heuristics to generate the verbalizations. We conclude by discussing how TeleGam can serve as a platform to conduct future studies for understanding user expectations and designing novel interfaces for interpretable ML.",,,,,vimeo 363042141,,,2019,Short,Room 1,Wednesday,VIS Meets Machine Learning (Short),2022-10-23,,
openaccessvis2019.csv,Short,Short,Visualizing RNN States with Predictive Semantic Encodings,,"Lindsey Sawatzky, Steven Bergner, Fred Popowich",https://arxiv.org/pdf/1908.00588.pdf,"Recurrent Neural Networks are an effective and prevalent tool used to model sequential data such as natural language text. However, their deep nature and massive number of parameters pose a challenge for those intending to study precisely how they work. We present a visual technique that gives a high level intuition behind the semantics of the hidden states within Recurrent Neural Networks. This semantic encoding allows for hidden states to be compared throughout the model independent of their internal details. The proposed technique is displayed in a proof of concept visualization tool which is demonstrated to visualize the natural language processing task of language modelling.",,,,,vimeo 363951597,,,2019,Short,Room 1,Wednesday,VIS Meets Machine Learning (Short),2022-10-23,,
openaccessvis2019.csv,Short,Short,FeatureExplorer: Interactive Feature Selection and Exploration of Regression Models for Hyperspectral Images,,"Jieqiong Zhao, Morteza Karimzadeh, Ali Masjedi, Taojun Wang, Xiwen Zhang, Melba Crawford, David Ebert",https://arxiv.org/pdf/1908.00671.pdf,"Feature selection is used in machine learning to improve predictions, decrease computation time, reduce noise, and tune models based on limited sample data. In this article, we present FeatureExplorer, a visual analytics system that supports the dynamic evaluation of regression models and importance of feature subsets through the interactive selection of features in high-dimensional feature spaces typical of hyperspectral images. The interactive system allows users to iteratively refine and diagnose the model by selecting features based on their domain knowledge, interchangeable (correlated) features, feature importance, and the resulting model performance.",,,,,vimeo 363456411,,,2019,Short,Room 1,Wednesday,VIS Meets Machine Learning (Short),2022-10-23,,
openaccessvis2019.csv,Short,Short,A Markov Model of Users' Interactive Behavior in Scatterplots,,"Emily Wall, Arup Arcalgud, Kuhu Gupta, Andrew Jo",,,,,,,vimeo 363954377,,,2019,Short,Room 1,Wednesday,"Perception, Cognition, and Visualization Design",2022-10-23,,
openaccessvis2019.csv,Short,Short,Slope-Dependent Rendering of Parallel Coordinates to Reduce Density Distortion and Ghost Clusters,,"David Pomerenke, Frederik L. Dennig, Daniel Keim, Johannes Fuchs, Michael Blumenschein",https://arxiv.org/pdf/1908.00500.pdf,"Parallel coordinates are a popular technique to visualize multidimensional data. However, they face a significant problem influencing the perception and interpretation of patterns. The distance between two parallel lines differs based on their slope. Vertical lines are rendered longer and closer to each other than horizontal lines. This problem is inherent in the technique and has two main consequences: (1) clusters which have a steep slope between two axes are visually more prominent than horizontal clusters. (2) Noise and clutter can be perceived as clusters, as a few parallel vertical lines visually emerge as a ghost cluster. Our paper makes two contributions: First, we formalize the problem and show its impact. Second, we present a novel technique to reduce the effects by rendering the polylines of the parallel coordinates based on their slope: horizontal lines are rendered with the default width, lines with a steep slope with a thinner line. Our technique avoids density distortions of clusters, can be computed in linear time, and can be added on top of most parallel coordinate variations. To demonstrate the usefulness, we show examples and compare them to the classical rendering.",,,,,vimeo 363951887,,,2019,Short,Room 1,Wednesday,"Perception, Cognition, and Visualization Design",2022-10-23,,
openaccessvis2019.csv,Short,Short,Evaluating Ordering Strategies of Star Glyph Axes,,"Matthias Miller, Xuan Zhang, Johannes Fuchs, Michael Blumenschein",https://arxiv.org/pdf/1908.00576.pdf,"Star glyphs are a well-researched visualization technique to represent multi-dimensional data. They are often used in small multiple settings for a visual comparison of many data points. However, their overall visual appearance is strongly influenced by the ordering of dimensions. To this end, two orthogonal categories of layout strategies are proposed in the literature: order dimensions by similarity to get homogeneously shaped glyphs vs. order by dissimilarity to emphasize spikes and salient shapes. While there is evidence that salient shapes support clustering tasks, evaluation, and direct comparison of data-driven ordering strategies has not received much research attention. We contribute an empirical user study to evaluate the efficiency, effectiveness, and user confidence in visual clustering tasks using star glyphs. In comparison to similarity-based ordering, our results indicate that dissimilarity-based star glyph layouts support users better in clustering tasks, especially when clutter is present.",,,https://osf.io/bje89/,,vimeo 363452113,,,2019,Short,Room 1,Wednesday,"Perception, Cognition, and Visualization Design",2022-10-23,,
openaccessvis2019.csv,Short,Short,Interactive Visualisation of Hierarchical Quantitative Data: an Evaluation,,"Linda Woodburn, Yalong Yang, Kim Marriott",https://arxiv.org/pdf/1908.01277.pdf,"We have compared three common visualisations for hierarchical quantitative data, treemaps, icicle plots and sunburst charts as well as a semicircular variant of sunburst charts we call the sundown chart. In a pilot study, we found that the sunburst chart was least preferred. In a controlled study with 12 participants, we compared treemaps, icicle plots and sundown charts. Treemap was the least preferred and had a slower performance on a basic navigation task and slower performance and accuracy in hierarchy understanding tasks. The icicle plot and sundown chart had similar performance with slight user preference for the icicle plot.",,,,,vimeo 363040988,,,2019,Short,Room 1,Wednesday,"Perception, Cognition, and Visualization Design",2022-10-23,,
openaccessvis2019.csv,Short,Short,Evidence for Area as the Primary Visual Cue in Pie Charts,,Robert Kosara,https://osf.io/fcna4,"The long-standing assumption of angle as the primary visual cueused to read pie charts has recently been called into question. Weconducted a controlled, preregistered study using parallel-projected3D pie charts. Angle, area, and arc length differ dramatically whenprojected and change over a large range of values. Modeling thesechanges and comparing them to study participants? estimates allowsus to rank the different visual cues by model fit. Area emerges asthe most likely cue used to read pie charts",,,https://osf.io/ra5tb/,https://osf.io/3a5tq,vimeo 363041944,,,2019,Short,Room 1,Wednesday,"Perception, Cognition, and Visualization Design",2022-10-23,,
openaccessvis2019.csv,Short,Short,Visual cues in estimation of part-to-whole comparison,,Stephen Redmond,https://arxiv.org/ftp/arxiv/papers/1908/1908.00630.pdf,"Pie charts were first published in 1801 by William Playfair and have caused some controversy since. Despite the suggestions of many experts against their use, several empirical studies have shown that pie charts are at least as good as alternatives. From Brinton to Few on one side and Eells to Kosara on the other, there appears to have been a hundred-year war waged on the humble pie. In this paper a set of experiments are reported that compare the performance of pie charts and horizontal bar charts with various visual cues. Amazon?s Mechanical Turk service was employed to perform the tasks of estimating segments in various part-to-whole charts. The results lead to recommendations for data visualization professionals in developing dashboards.",,,,,vimeo 363042298,,,2019,Short,Room 1,Wednesday,"Perception, Cognition, and Visualization Design",2022-10-23,,
openaccessvis2019.csv,Short,Short,Towards a Design Space for Mitigating Cognitive Bias in Visual Analytics,,"Emily Wall, John Stasko, Alex Endert",,,,,,,vimeo 363451921,,,2019,Short,Room 1,Wednesday,"Perception, Cognition, and Visualization Design",2022-10-23,,
openaccessvis2019.csv,Short,Short,Thumbnails for Data Stories: Survey of Current Practice,,"Hwiyeon Kim, Juyoung Oh, Yunha Han, Sungahn Ko, Matthew Brehmer, Bum Chul Kwon",https://arxiv.org/abs/1908.06922,"When people browse online news, small thumbnail images accompanying links to articles attract their attention and help them to decide which articles to read. As an increasing proportion of online news can be construed as data journalism, we have witnessed a corresponding increase in the incorporation of visualization in article thumbnails. However, there is little research to support alternative design choices for visualization thumbnails, which include resizing, cropping, simplifying, and embellishing charts appearing within the body of the associated article. We therefore sought to better understand these design choices and determine what makes a visualization thumbnail inviting and interpretable. This paper presents our findings from a survey of visualization thumbnails collected online and from conversations with data journalists and news graphics designers. Our study reveals that there exists an uncharted design space, one that is in need of further empirical study. Our work can thus be seen as a first step toward providing structured guidance on how to design thumbnails for data stories",,,,,,,,2019,Short,Room 1,Wednesday,"Perception, Cognition, and Visualization Design",2022-10-23,,
openaccessvis2019.csv,Short,Short,Towards Quantifying multiple view layouts in visualisation as seen from research publications,,"Hayder Mahdi Al-maneea, Jonathan C Roberts",,,,,,,vimeo 363453583,,,2019,Short,Room 1,Wednesday,"Perception, Cognition, and Visualization Design",2022-10-23,,
openaccessvis2019.csv,Short,Short,Data-Driven Colormap Optimization for 2D Scalar Field Visualization,,"Qiong Zeng, Yinqiao Wang, Ivan Viola, Wenting Zhang, Jian Zhang, Changhe Tu, Yunhai Wang",,,,,,,vimeo 363042086,,,2019,Short,Room 1,Friday,"Scalar, vector, and tensor fields",2022-10-25,,
openaccessvis2019.csv,Short,Short,Evaluating Gradient Perception in Color-coded Scalar Fields,,"Khairi Reda, Michael E. Papka",https://osf.io/2msfd,"Color mapping is a commonly used technique for visualizing scalar fields. While there exists advice for choosing effective colormaps, it is unclear if current guidelines apply equally across task types. We study the perception of gradients and evaluate the effectiveness of three colormaps at depicting gradient magnitudes. In a crowdsourced experiment, we determine the just-noticeable differences (JNDs) at which participants can reliably compare and judge variations in gradient between two scalar fields. We find that participants exhibited lower JNDs with a diverging (cool-warm) or a spectral (rainbow) scheme, as compared with a monotonic-luminance colormap (viridis). The results support a hypothesis that apparent discontinuities in the color ramp may help viewers discern subtle structural differences in gradient. We discuss these findings and highlight future research directions for colormap evaluation.",,,https://osf.io/ew638/,https://osf.io/ng9qw,vimeo 363042264,,,2019,Short,Room 1,Friday,"Scalar, vector, and tensor fields",2022-10-25,,
openaccessvis2019.csv,Short,Short,GalStamps: Analyzing Real and Simulated Galaxy Observations,,"Nina McCurdy, Miriah Meyer",,,,,,,vimeo 363040619,,,2019,Short,Room 1,Friday,"Scalar, vector, and tensor fields",2022-10-25,,
openaccessvis2019.csv,Short,Short,Point Movement in a DSL for Higher-Order FEM Visualization,,"Teodoro Collin, Charisee Chiw, L. Ridgway Scott, John Reppy, Gordon L Kindlmann",,,,,,,vimeo 363040730,,,2019,Short,Room 1,Friday,"Scalar, vector, and tensor fields",2022-10-25,,
openaccessvis2019.csv,Short,Short,Unsteady Flow Visualization via Physics based Pathline Exploration,,"Duong Nguyen, Lei Zhang, Robert S. Laramee, David Thompson, Rodolfo Ostilla Monico, Guoning Chen",,,,,,,vimeo 363042555,,,2019,Short,Room 1,Friday,"Scalar, vector, and tensor fields",2022-10-25,,
openaccessvis2019.csv,Short,Short,Visualization of Symmetries in Fourth-Order Stiffness Tensors,,"Chiara Hergl, Thomas Nagel, Olaf Kolditz, Gerik Scheuermann",,,,,,,vimeo 363042029,,,2019,Short,Room 1,Friday,"Scalar, vector, and tensor fields",2022-10-25,,
openaccessvis2019.csv,Short,Short,Hybrid Grids for Sparse Volume Rendering,,"Stefan Zellmann, Deborah Meurer, Ulrich Lang",,,,,,,vimeo 363954158,,,2019,Short,Room 1,Friday,"Scalar, vector, and tensor fields",2022-10-25,,
openaccessvis2019.csv,Short,Short,Efficient Space Skipping and Adaptive Sampling of Unstructured Volumes using Hardware Accelerated Ray Tracing,,"Nate Morrical, Will Usher, Ingo Wald, Valerio Pascucci",https://arxiv.org/pdf/1908.01906.pdf,"Sample based ray marching is an effective method for direct volume rendering of unstructured meshes. However, sampling such meshes remains expensive, and strategies to reduce the number of samples taken have received relatively little attention. In this paper, we introduce a method for rendering unstructured meshes using a combination of a coarse spatial acceleration structure and hardware-accelerated ray tracing. Our approach enables efficient empty space skipping and adaptive sampling of unstructured meshes, and outperforms a reference ray marcher by up to 7?.",,,,,vimeo 363452086,,,2019,Short,Room 1,Friday,"Scalar, vector, and tensor fields",2022-10-25,,
openaccessvis2019.csv,Short,Short,scenery - Flexible Virtual Reality Visualization on the Java VM,,"Ulrik Gnther, Tobias Pietzsch, Aryaman Gupta, Kyle Harrington, Stefan Gumhold, Pavel Tomancak, Ivo F. Sbalzarini",https://arxiv.org/pdf/1906.06726.pdf,"Life science today involves computational analysis of a large amount and variety of data, such as volumetric data acquired by state-of-the-art microscopes, or mesh data from analysis of such data or simulations. Visualization is often the first step in making sense of data, and a crucial part of building and debugging analysis pipelines. It is therefore important that visualizations can be quickly prototyped, as well as developed or embedded into full applications. In order to better judge spatiotemporal relationships, immersive hardware, such as Virtual or Augmented Reality (VR/AR) headsets and associated controllers are becoming invaluable tools. In this work we introduce scenery, a flexible VR/AR visualization framework for the Java VM that can handle mesh and large volumetric data, containing multiple views, timepoints, and color channels. scenery is free and open-source software, works on all major platforms, and uses the Vulkan or OpenGL rendering APIs. We introduce scenery?s main features and example applications, such as its use in VR for microscopy, in the biomedical image analysis software Fiji, or for visualising agent-based simulations.",,,,,,,,2019,Short,Room 1,Thursday,"Biology, Chemistry, and Medicine",2022-10-24,,
openaccessvis2019.csv,Short,Short,Interactive Dendritic Spine Analysis Based on 3D Morphological Features,,"JunYoung Choi, Sang-Eun Lee, Eunji Cho, Yutaro Kashiwagi, Shigeo Okabe, Sunghoe Chang, Won-Ki Jeong",,,,,,,vimeo 364567245,,,2019,Short,Room 1,Thursday,"Biology, Chemistry, and Medicine",2022-10-24,,
openaccessvis2019.csv,Short,Short,High Fidelity Visualization of Large Scale Digitally Reconstructed Brain Circuitry with Signed Distance Functions,,"Jonas Karlsson, Marwan Abdellah, Sebastien Speierer, Alessandro Enrico Foni, Samuel Lapere, Felix Schurmann",,,,,,,vimeo 363452920,,,2019,Short,Room 1,Thursday,"Biology, Chemistry, and Medicine",2022-10-24,,
openaccessvis2019.csv,Short,Short,Visual Inspection of DBS Efficacy,,"Brad Eric Hollister, Chris Butson, Gordon Duffley, Chris R. Johnson, Paul Rosen",,,,,,,vimeo 364569960,,,2019,Short,Room 1,Thursday,"Biology, Chemistry, and Medicine",2022-10-24,,
openaccessvis2019.csv,Short,Short,TempoCave: Visualizing Dynamic Connectome Datasets to Support Cognitive Behavioral Therapy,,"Ran Xu, Manu Mathew Thomas, Alex Leow, Olusola A. Ajilore, Angus G. Forbes",https://arxiv.org/pdf/1906.07837.pdf,"We introduce TempoCave, a novel visualization application for analyzing dynamic brain networks, or connectomes. TempoCave provides a range of functionality to explore metrics related to the activity patterns and modular affiliations of different regions in the brain. These patterns are calculated by processing raw data retrieved functional magnetic resonance imaging (fMRI) scans, which creates a network of weighted edges between each brain region, where the weight indicates how likely these regions are to activate synchronously. In particular, we support the analysis needs of clinical psychologists, who examine these modular affiliations and weighted edges and their temporal dynamics, utilizing them to understand relationships between neurological disorders and brain activity, which could have significant impact on the way in which patients are diagnosed and treated. We summarize the core functionality of TempoCave, which supports a range of comparative tasks, and runs both in a desktop mode and in an immersive mode. Furthermore, we present a real world use case that analyzes pre- and post-treatment connectome datasets from 27 subjects in a clinical study investigating the use of cognitive behavior therapy to treat major depression disorder, indicating that TempoCave can provide new insight into the dynamic behavior of the human brain.",,,,,vimeo 363456447,,,2019,Short,Room 1,Thursday,"Biology, Chemistry, and Medicine",2022-10-24,,
openaccessvis2019.csv,Short,Short,RuleVis: Constructing Patterns and Rules for Rule-based Models,,"David Abramov, Jasmine Tan Otto, Mahika Dubey, Cassia Artanegara, Pierre Boutillier, Walter Fontana, Angus G. Forbes",,,,,,,vimeo 363456476,,,2019,Short,Room 1,Thursday,"Biology, Chemistry, and Medicine",2022-10-24,,
openaccessvis2019.csv,Short,Short,ElectroLens: Understanding atomistic simulations through spatially-resolved visualization of high-dimensional features,,"Xiangyun Lei, Fred Hohman, Duen Horng Chau, Andrew J Medford",https://arxiv.org/pdf/1908.08381.pdf,"In recent years, machine learning (ML) has gained significant popularity in the field of chemical informatics and electronic structure theory. These techniques often require researchers to engineer abstract ?features? that encode chemical concepts into a mathematical form compatible with the input to machine-learning models. However, there is no existing tool to connect these abstract features back to the actual chemical system, making it difficult to diagnose failures and to build intuition about the meaning of the features. We present ElectroLens, a new visualization tool for high-dimensional spatially-resolved features to tackle this problem. The tool visualizes high-dimensional data sets for atomistic and electron environment features by a series of linked 3D views and 2D plots. The tool is able to connect different derived features and their corresponding regions in 3D via interactive selection. It is built to be scalable, and integrate with existing infrastructure.",,,,,vimeo 363453632,,,2019,Short,Room 1,Thursday,"Biology, Chemistry, and Medicine",2022-10-24,,
openaccessvis2019.csv,Short,Short,Analyzing Time Attributes in Event Sequences,,"Jessica Magallanes, Lindsey van Gemeren, Steven Wood, Maria-Cruz Villa-Uriol",https://arxiv.org/pdf/1908.00903.pdf,"Event data is present in a variety of domains such as electronic health records, daily living activities and web clickstream records. Current visualization methods to explore event data focus on discovering sequential patterns but present limitations when studying time attributes in event sequences. Time attributes are especially important when studying waiting times or lengths of visit in patient flow analysis. We propose a visual analytics methodology that allows the identification of trends and outliers in respect of duration and time of occurrence in event sequences. The proposed method presents event data using a single Sequential and Time Patterns overview. User-driven alignment by multiple events, sorting by sequence similarity and a novel visual encoding of events allows the comparison of time trends across and within sequences. The proposed visualization allows the derivation of findings that otherwise could not be obtained using traditional visualizations. The proposed methodology has been applied to a real-world dataset provided by Sheffield Teaching Hospitals NHS Foundation Trust, for which four classes of conclusions were derived.",,,,,,,,2019,Short,Room 1,Thursday,"Biology, Chemistry, and Medicine",2022-10-24,,
openaccessvis2019.csv,Short,Short,Evaluating Alignment Approaches in Superimposed Time-series and Temporal Event-sequence Visualizations,,"Yixuan Zhang, Sara Di Bartolomeo, Fangfang Sheng, Holly Jimison, Cody Dunne",https://arxiv.org/pdf/1908.07316.pdf,"Composite temporal event sequence visualizations have included sentinel event alignment techniques to cope with data volume and variety. Prior work has demonstrated the utility of using singleevent alignment for understanding the precursor, co-occurring, and aftereffect events surrounding a sentinel event. However, the usefulness of single-event alignment has not been sufficiently evaluated in composite visualizations. Furthermore, recently proposed dualevent alignment techniques have not been empirically evaluated. In this work, we designed tasks around temporal event sequence and timing analysis and conducted a controlled experiment on Amazon Mechanical Turk to examine four sentinel event alignment approaches: no sentinel event alignment (NoAlign), single-event alignment (SingleAlign), dual-event alignment with left justification (DualLeft), and dual-event alignment with stretch justification (DualStretch). Differences between approaches were most pronounced with more rows of data. For understanding intermediate events between two sentinel events, dual-event alignment was the clear winner for correctness?71% vs. 18% for NoAlign and SingleAlign. For understanding the duration between two sentinel events, NoAlign was the clear winner: correctness?88% vs. 36% for DualStretch? completion time?55 seconds vs. 101 seconds for DualLeft?and error?1.5% vs. 8.4% for DualStretch. For understanding precursor and aftereffect events, there was no significant difference among approaches. A free copy of this paper, the evaluation stimuli and data, and source code are available at osf.io/78fs5",,,https://osf.io/78fs5/,,vimeo 363452044,,,2019,Short,Room 1,Thursday,"Biology, Chemistry, and Medicine",2022-10-24,,
openaccessvis2019.csv,Short,Short,Designing Visual Guides for Casual Listeners of Live Orchestral Music,,"Catherine Solis, Fahimeh Rajabiyazdi, Fanny Chevalier",,,,,,,vimeo 364567296,,,2019,Short,Room 1,Tuesday,Systems and Design Studies,2022-10-22,,
openaccessvis2019.csv,Short,Short,Uncovering Data Landscapes through Data Reconnaissance and Task Wrangling,,"Anamaria Crisan, Tamara Munzner",,,,,,,vimeo 363042588,,,2019,Short,Room 1,Tuesday,Systems and Design Studies,2022-10-22,,
openaccessvis2019.csv,Short,Short,Sabrina: Modeling and Visualization of Economy Data with Incremental Domain Knowledge,,"Alessio Arleo, Johannes Sorger, Chao Jia, Christos Tsigkanos, Roger A. Leite, Ilir Murturi, Manfred Klaffenboeck, Silvia Miksch, Shahram Dustdar, Michael Wimmer",https://arxiv.org/pdf/1908.07479.pdf,"Investment planning requires knowledge of the financial landscape on a large scale, both in terms of geo-spatial and industry sector distribution. There is plenty of data available, but it is scattered across heterogeneous sources (newspapers, open data, etc.), which makes it difficult for financial analysts to understand the big picture. In this paper, we present Sabrina, a financial data analysis and visualization approach that incorporates a pipeline for the generation of firm-to-firm financial transaction networks. The pipeline is capable of fusing the ground truth on individual firms in a region with (incremental) domain knowledge on general macroscopic aspects of the economy. Sabrina unites these heterogeneous data sources within a uniform visual interface that enables the visual analysis process. In a user study with three domain experts, we illustrate the usefulness of Sabrina, which eases their analysis process.",,,,,vimeo 363040561,,,2019,Short,Room 1,Tuesday,Systems and Design Studies,2022-10-22,,
openaccessvis2019.csv,Short,Short,Visual Analysis of the Time Management of Learning Multiple Courses in Online Learning Environment,,"Huan He, Bo Dong, Qinghua Zheng, Dehai Di, Yating Lin",,,,,,,vimeo 363452286,,,2019,Short,Room 1,Tuesday,Systems and Design Studies,2022-10-22,,
openaccessvis2019.csv,Short,Short,H-Matrix: Hierarchical Matrix for Visual Analysis of Cross-Linguistic Features in Large Learner Corpora,,"Mariana Shimabukuro, Jessica Zipf, Mennatallah El-Assady, Christopher Collins",,,,,,,vimeo 363042512,,,2019,Short,Room 1,Tuesday,Systems and Design Studies,2022-10-22,,
openaccessvis2019.csv,Short,Short,OCTVis: Ontology-based Comparison of Topic Models,,"Amon Ge, Hyeju Jang, Giuseppe Carenini, Kendall Ho, Young Ji Lee",,,,,,,vimeo 363452963,,,2019,Short,Room 1,Tuesday,Systems and Design Studies,2022-10-22,,
openaccessvis2019.csv,Short,Short,MissBi: Visual Analysis of Missing Links in Bipartite Networks,,"Jian Zhao, Maoyuan Sun, Francine Chen, Patrick Chiu",,,,,,,,,,2019,Short,Room 1,Tuesday,Systems and Design Studies,2022-10-22,,
openaccessvis2019.csv,Short,Short,FacIt: Factorizing Tensors into Interpretable and Scrutinizable Patterns,,"Xidao Wen, Yu-Ru Lin, Yongsu Ahn, Konstantinos Pelechrinis, Xi Liu, Nan Cao",,,,,,,vimeo 363453555,,,2019,Short,Room 1,Tuesday,Systems and Design Studies,2022-10-22,,
openaccessvis2019.csv,Short,Short,Interpreting Distortions in Dimensionality Reduction by Superimposing Neighbourhood Graphs,,"BenoŒt Colange, Laurent Vuillon, Sylvain Lespinats, Denys Dutykh",https://arxiv.org/abs/1909.12902,"To perform visual data exploration, many dimensionality reduction methods have been developed. These tools allow data analysts to represent multidimensional data in a 2D or 3D space, while preserving as much relevant information as possible. Yet, they cannot preserve all structures simultaneously and they induce some unavoidable distortions. Hence, many criteria have been introduced to evaluate a map?s overall quality, mostly based on the preservation of neighbourhoods. Such global indicators are currently used to compare several maps, which helps to choose the most appropriate mapping method and its hyperparameters. However, those aggregated indicators tend to hide the local repartition of distortions. Thereby, they need to be supplemented by local evaluation to ensure correct interpretation of maps. In this paper, we describe a new method, called MING, for ?Map Interpretation using Neighbourhood Graphs?. It offers a graphical interpretation of pairs of map quality indicators, as well as local evaluation of the distortions. This is done by displaying on the map the nearest neighbours graphs computed in the data space and in the embedding. Shared and unshared edges exhibit reliable and unreliable neighbourhood information conveyed by the mapping. By this mean, analysts may determine whether proximity (or remoteness) of points on the map faithfully represents similarity (or dissimilarity) of original data, within the meaning of a chosen map quality criteria. We apply this approach to two pairs of widespread indicators: precision/recall and trustworthiness/continuity, chosen for their wide use in the community, which will allow an easy handling by users.",,,,,vimeo 363451896,,,2019,Short,Room 1,Thursday,"Multi-Dimensional Data, Time Series, Graphs, and Trees",2022-10-24,,
openaccessvis2019.csv,Short,Short,Hi-D Maps: An Interactive Visualization Technique for Multi-dimensional Categorical Data.,,"Radi Muhammad Reza, Benjamin Watson",https://osf.io/ufzgd/,"In this paper, we presentHi-D maps, a novel method for the visual-ization of multi-dimensional categorical data. Our work addressesthe scarcity of techniques for visualizing a large number of data-dimensions in an effective and space-efficient manner. We havemapped the full data-space onto a 2D regular polygonal region. Thepolygon is cut hierarchically with lines parallel to a user-controlled,ordered sequence of sides, each representing a dimension. We haveused multiple visual cues such as orientation, thickness, color, count-able glyphs, and text to depict cross-dimensional information. Wehave added interactivity and hierarchical browsing to facilitate flex-ible exploration of the display: small areas can be scrutinized fordetails. Thus, our method is also easily extendable to visualize hierarchical information. Our glyph animations add an engagingaesthetic during interaction. Like many visualizations, Hi-D mapsbecome less effective when a large number of dimensions stressesperceptual limits, but Hi-D maps may add clarity before those limitsare reached.",,,,,,,,2019,Short,Room 1,Thursday,"Multi-Dimensional Data, Time Series, Graphs, and Trees",2022-10-24,,
openaccessvis2019.csv,Short,Short,Conditional Parallel Coordinates,,Daniel Weidele,https://arxiv.org/pdf/1906.07716.pdf,"Parallel Coordinates [11, 12] are a popular data visualization technique for multivariate data. Dating back to as early as 1880 [8] PC are nearly as old as John Snow?s famous cholera outbreak map [18] of 1855, which is frequently regarded as a historic landmark for modern data visualization. Numerous extensions have been proposed to address integrity, scalability and readability. We make a new case to employ PC on conditional data, where additional dimensions are only unfolded if certain criteria are met in an observation. Compared to standard PC which operate on a flat set of dimensions the ontology of our input to Conditional Parallel Coordinates is of hierarchical nature. We therefore briefly review related work around hierarchical PC using aggregation or nesting techniques. Our contribution is a visualization to seamlessly adapt PC for conditional data under preservation of intuitive interaction patterns to select or highlight polylines. We conclude with intuitions on how to operate CPC on two data sets: an AutoML hyperparameter search log, and session results from a conversational agent.",,,,,vimeo 363040925,,,2019,Short,Room 1,Thursday,"Multi-Dimensional Data, Time Series, Graphs, and Trees",2022-10-24,,
openaccessvis2019.csv,Short,Short,Towards Enhancing RadViz Analysis and Interpretation,,"Marco Angelini, Graziano Blasilli, Simone Lenti, Alessia Palleschi, Giuseppe Santucci",,,,,,,vimeo 363453287,,,2019,Short,Room 1,Thursday,"Multi-Dimensional Data, Time Series, Graphs, and Trees",2022-10-24,,
openaccessvis2019.csv,Short,Short,Time Varying Predominance Tag Maps,,"Martin Reckziegel, Stefan J„nicke",,,,,,,vimeo 363041739,,,2019,Short,Room 1,Thursday,"Multi-Dimensional Data, Time Series, Graphs, and Trees",2022-10-24,,
openaccessvis2019.csv,Short,Short,SAX Navigator: Time Series Exploration Through Hierarchical Clustering,,"Nicholas Ruta, Naoko Sawada, Katy McKeough, Michael Behrisch, Johanna Beyer",https://arxiv.org/pdf/1908.05505.pdf,"Comparing many long time series is challenging to do by hand. Clustering time series enables data analysts to discover relevance between and anomalies among multiple time series. However, even after reasonable clustering, analysts have to scrutinize correlations between clusters or similarities within a cluster. We developed SAX Navigator, an interactive visualization tool, that allows users to hierarchically explore global patterns as well as individual observations across large collections of time series data. Our visualization provides a unique way to navigate time series that involves a ?vocabulary of patterns? developed by using a dimensionality reduction technique, Symbolic Aggregate approXimation (SAX). With SAX, the time series data clusters efficiently and is quicker to query at scale. We demonstrate the ability of SAX Navigator to analyze patterns in large time series data based on three case studies for an astronomy data set. We verify the usability of our system through a think-aloud study with an astronomy domain scientist.",,,,,vimeo 364567202,,,2019,Short,Room 1,Thursday,"Multi-Dimensional Data, Time Series, Graphs, and Trees",2022-10-24,,
openaccessvis2019.csv,Short,Short,Nonuniform Timeslicing of Dynamic Graphs Based on Visual Complexity,,"Yong Wang, Daniel Archambault, Hammad Haleem, Torsten Moeller, Yanhong Wu, Huamin Qu",https://arxiv.org/pdf/1907.12015.pdf,"Uniform timeslicing of dynamic graphs has been used due to its convenience and uniformity across the time dimension. However, uniform timeslicing does not take the data set into account, which can generate cluttered timeslices with edge bursts and empty timeslices with few interactions. The graph mining filed has explored nonuniform timeslicing methods specifically designed to preserve graph features for mining tasks. In this paper, we propose a nonuniform timeslicing approach for dynamic graph visualization. Our goal is to create timeslices of equal visual complexity. To this end, we adapt histogram equalization to create timeslices with a similar number of events, balancing the visual complexity across timeslices and conveying more important details of timeslices with bursting edges. A case study has been conducted, in comparison with uniform timeslicing, to demonstrate the effectiveness of our approach.",,,,,vimeo 363040656,,,2019,Short,Room 1,Thursday,"Multi-Dimensional Data, Time Series, Graphs, and Trees",2022-10-24,,
openaccessvis2019.csv,Short,Short,Interactive Bicluster Aggregation in Bipartite Graphs,,"Maoyuan Sun, David Koop, Jian Zhao, Chris North, Naren Ramakrishnan",,,,,,,vimeo 363040807,,,2019,Short,Room 1,Thursday,"Multi-Dimensional Data, Time Series, Graphs, and Trees",2022-10-24,,
openaccessvis2019.csv,Short,Short,Overlap-Free Drawing of Generalized Pythagoras Trees for Hierarchy Visualization,,"Tanja Munz, Michael Burch, Toon van Benthem, Yoeri Poels, Fabian Beck, Daniel Weiskopf",https://arxiv.org/pdf/1907.12845.pdf,"Generalized Pythagoras trees were developed for visualizing hierarchical data, producing organic, fractal-like representations. However, the drawback of the original layout algorithm is visual overlap of tree branches. To avoid such overlap, we introduce an adapted drawing algorithm using ellipses instead of circles to recursively place tree nodes representing the subhierarchies. Our technique is demonstrated by resolving overlap in diverse real-world and generated datasets, while comparing the results to the original approach.",,,,,vimeo 363452307,,,2019,Short,Room 1,Thursday,"Multi-Dimensional Data, Time Series, Graphs, and Trees",2022-10-24,,
